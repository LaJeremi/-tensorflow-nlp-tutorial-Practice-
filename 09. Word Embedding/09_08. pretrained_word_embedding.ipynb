{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02e6f968",
   "metadata": {},
   "source": [
    "# 09-08 사전 훈련된 워드 임베딩(Pre-trained Word Embedding)\n",
    "\n",
    "출처: https://wikidocs.net/33793\n",
    "\n",
    "이번에는 케라스의 임베딩 층(embedding layer) 과 사전 훈련된 워드 임베딩(pre-trained word embedding) 을 가져와서 사용하는 것을 비교\n",
    "\n",
    "* 1. 케라스 임베딩 층(Keras Embedding layer)\n",
    "\n",
    "## 1) 임베딩 층은 룩업 테이블이다.\n",
    "\n",
    "임베딩 층의 입력으로 사용하기 위해서 입력 시퀀스의 각 단어들은 모두 정수 인코딩이 되어있어야 합니다.\n",
    "\n",
    "어떤 단어 → 단어에 부여된 고유한 정수값 → 임베딩 층 통과 → 밀집 벡터\n",
    "\n",
    "임베딩 층은 입력 정수에 대해 밀집 벡터(dense vector)로 맵핑하고 이 밀집 벡터는 인공 신경망의 학습 과정에서 가중치가 학습되는 것과 같은 방식으로 훈련됩니다. 훈련 과정에서 단어는 모델이 풀고자하는 작업에 맞는 값으로 업데이트 됩니다. 그리고 이 밀집 벡터를 임베딩 벡터라고 부릅니다.\n",
    "\n",
    "정수를 밀집 벡터 또는 임베딩 벡터로 맵핑한다는 것은 어떤 의미일까요? 특정 단어와 맵핑되는 정수를 인덱스로 가지는 테이블로부터 임베딩 벡터 값을 가져오는 룩업 테이블이라고 볼 수 있습니다. 그리고 이 테이블은 단어 집합의 크기만큼의 행을 가지므로 모든 단어는 고유한 임베딩 벡터를 가집니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f0dcba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1cf9f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(\"image/09-08 Pre-trained Word Embedding.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08608f0",
   "metadata": {},
   "source": [
    "위의 그림은 단어 great이 정수 인코딩 된 후 테이블로부터 해당 인덱스에 위치한 임베딩 벡터를 꺼내오는 모습을 보여줍니다. 위의 그림에서는 임베딩 벡터의 차원이 4로 설정되어져 있습니다. 그리고 단어 great은 정수 인코딩 과정에서 1,918의 정수로 인코딩이 되었고 그에 따라 단어 집합의 크기만큼의 행을 가지는 테이블에서 인덱스 1,918번에 위치한 행을 단어 great의 임베딩 벡터로 사용합니다. 이 임베딩 벡터는 모델의 입력이 되고, 역전파 과정에서 단어 great의 임베딩 벡터값이 학습됩니다.\n",
    "\n",
    "룩업 테이블의 개념을 이론적으로 우선 접하고, 처음 케라스를 배울 때 어떤 분들은 임베딩 층의 입력이 원-핫 벡터가 아니어도 동작한다는 점에 헷갈려 합니다. 앞서 NNLM이나 Word2Vec을 설명할 때 룩업 테이블을 언급하면서 입력을 원-핫 벡터로 가정하고 설명드렸기 때문인데, 케라스는 단어를 정수 인덱스로 바꾸고 원-핫 벡터로 변환 후 임베딩 층의 입력으로 사용하는 것이 아니라, 단어를 정수 인코딩까지만 진행 후 임베딩 층의 입력으로 사용하여 룩업 테이블 결과인 임베딩 벡터를 리턴합니다.\n",
    "\n",
    "vocab_size = 20000\n",
    "output_dim = 128\n",
    "input_length = 500\n",
    "\n",
    "v = Embedding(vocab_size, output_dim, input_length=input_length)\n",
    "\n",
    "임베딩 층은 다음과 같은 세 개의 인자를 받습니다.\n",
    "\n",
    "vocab_size = 텍스트 데이터의 전체 단어 집합의 크기입니다.\n",
    "output_dim = 워드 임베딩 후의 임베딩 벡터의 차원입니다.\n",
    "input_length = 입력 시퀀스의 길이입니다. 만약 갖고있는 각 샘플의 길이가 500개이라면 이 값은 500입니다.\n",
    "\n",
    "\n",
    "## 2) 임베딩 층 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da28a20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd6154c",
   "metadata": {},
   "source": [
    "출처: https://wikidocs.net/33930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98647e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cd0dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences = ['nice great best amazing', 'stop lies', 'pitiful nerd', 'excellent work', 'supreme quality', 'bad', 'highly respectable']\n",
    "y_train = [1, 0, 0, 1, 1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8de05ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합 : 16\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "vocab_size = len(tokenizer.word_index) + 1 # 패딩을 고려하여 +1\n",
    "print('단어 집합 :',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1851b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13], [14, 15]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_encoded = tokenizer.texts_to_sequences(sentences)\n",
    "print(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46f12c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 결과 : [[1, 2, 3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13], [14, 15]]\n"
     ]
    }
   ],
   "source": [
    "X_encoded = tokenizer.texts_to_sequences(sentences)\n",
    "print('정수 인코딩 결과 :',X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98d6832f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 길이 : 4\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(l) for l in X_encoded)\n",
    "print('최대 길이 :',max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6db63e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패딩 결과 :\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  0  0]\n",
      " [ 7  8  0  0]\n",
      " [ 9 10  0  0]\n",
      " [11 12  0  0]\n",
      " [13  0  0  0]\n",
      " [14 15  0  0]]\n"
     ]
    }
   ],
   "source": [
    "X_train = pad_sequences(X_encoded, maxlen=max_len, padding='post')\n",
    "y_train = np.array(y_train)\n",
    "print('패딩 결과 :')\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "252bc8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 - 0s - loss: 0.7013 - acc: 0.2857 - 404ms/epoch - 404ms/step\n",
      "Epoch 2/100\n",
      "1/1 - 0s - loss: 0.6995 - acc: 0.2857 - 2ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "1/1 - 0s - loss: 0.6978 - acc: 0.2857 - 2ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "1/1 - 0s - loss: 0.6961 - acc: 0.2857 - 2ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "1/1 - 0s - loss: 0.6944 - acc: 0.4286 - 3ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "1/1 - 0s - loss: 0.6927 - acc: 0.4286 - 3ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "1/1 - 0s - loss: 0.6910 - acc: 0.4286 - 3ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "1/1 - 0s - loss: 0.6893 - acc: 0.4286 - 2ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "1/1 - 0s - loss: 0.6876 - acc: 0.7143 - 3ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "1/1 - 0s - loss: 0.6860 - acc: 0.7143 - 2ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "1/1 - 0s - loss: 0.6843 - acc: 0.7143 - 3ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "1/1 - 0s - loss: 0.6827 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "1/1 - 0s - loss: 0.6810 - acc: 0.8571 - 3ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "1/1 - 0s - loss: 0.6794 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "1/1 - 0s - loss: 0.6778 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "1/1 - 0s - loss: 0.6761 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "1/1 - 0s - loss: 0.6745 - acc: 0.8571 - 3ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "1/1 - 0s - loss: 0.6729 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "1/1 - 0s - loss: 0.6712 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "1/1 - 0s - loss: 0.6696 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "1/1 - 0s - loss: 0.6680 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "1/1 - 0s - loss: 0.6664 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "1/1 - 0s - loss: 0.6647 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "1/1 - 0s - loss: 0.6631 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "1/1 - 0s - loss: 0.6615 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "1/1 - 0s - loss: 0.6598 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "1/1 - 0s - loss: 0.6582 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "1/1 - 0s - loss: 0.6565 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "1/1 - 0s - loss: 0.6548 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "1/1 - 0s - loss: 0.6532 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "1/1 - 0s - loss: 0.6515 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "1/1 - 0s - loss: 0.6498 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "1/1 - 0s - loss: 0.6481 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "1/1 - 0s - loss: 0.6465 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "1/1 - 0s - loss: 0.6448 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "1/1 - 0s - loss: 0.6430 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "1/1 - 0s - loss: 0.6413 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "1/1 - 0s - loss: 0.6396 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "1/1 - 0s - loss: 0.6379 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "1/1 - 0s - loss: 0.6361 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "1/1 - 0s - loss: 0.6344 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "1/1 - 0s - loss: 0.6326 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "1/1 - 0s - loss: 0.6309 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "1/1 - 0s - loss: 0.6291 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "1/1 - 0s - loss: 0.6273 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "1/1 - 0s - loss: 0.6255 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "1/1 - 0s - loss: 0.6237 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "1/1 - 0s - loss: 0.6219 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "1/1 - 0s - loss: 0.6200 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "1/1 - 0s - loss: 0.6182 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "1/1 - 0s - loss: 0.6164 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "1/1 - 0s - loss: 0.6145 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "1/1 - 0s - loss: 0.6127 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "1/1 - 0s - loss: 0.6108 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "1/1 - 0s - loss: 0.6089 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "1/1 - 0s - loss: 0.6070 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "1/1 - 0s - loss: 0.6051 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "1/1 - 0s - loss: 0.6032 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "1/1 - 0s - loss: 0.6013 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "1/1 - 0s - loss: 0.5994 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "1/1 - 0s - loss: 0.5974 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "1/1 - 0s - loss: 0.5955 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "1/1 - 0s - loss: 0.5935 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "1/1 - 0s - loss: 0.5916 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "1/1 - 0s - loss: 0.5896 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "1/1 - 0s - loss: 0.5876 - acc: 1.0000 - 997us/epoch - 997us/step\n",
      "Epoch 67/100\n",
      "1/1 - 0s - loss: 0.5857 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "1/1 - 0s - loss: 0.5837 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "1/1 - 0s - loss: 0.5817 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "1/1 - 0s - loss: 0.5797 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "1/1 - 0s - loss: 0.5776 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "1/1 - 0s - loss: 0.5756 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "1/1 - 0s - loss: 0.5736 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "1/1 - 0s - loss: 0.5716 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "1/1 - 0s - loss: 0.5695 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "1/1 - 0s - loss: 0.5675 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "1/1 - 0s - loss: 0.5654 - acc: 1.0000 - 997us/epoch - 997us/step\n",
      "Epoch 78/100\n",
      "1/1 - 0s - loss: 0.5633 - acc: 1.0000 - 997us/epoch - 997us/step\n",
      "Epoch 79/100\n",
      "1/1 - 0s - loss: 0.5613 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "1/1 - 0s - loss: 0.5592 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "1/1 - 0s - loss: 0.5571 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "1/1 - 0s - loss: 0.5550 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "1/1 - 0s - loss: 0.5529 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "1/1 - 0s - loss: 0.5508 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "1/1 - 0s - loss: 0.5487 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "1/1 - 0s - loss: 0.5466 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "1/1 - 0s - loss: 0.5444 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "1/1 - 0s - loss: 0.5423 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "1/1 - 0s - loss: 0.5402 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "1/1 - 0s - loss: 0.5380 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "1/1 - 0s - loss: 0.5359 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "1/1 - 0s - loss: 0.5338 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "1/1 - 0s - loss: 0.5316 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "1/1 - 0s - loss: 0.5294 - acc: 1.0000 - 998us/epoch - 998us/step\n",
      "Epoch 95/100\n",
      "1/1 - 0s - loss: 0.5273 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "1/1 - 0s - loss: 0.5251 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "1/1 - 0s - loss: 0.5229 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "1/1 - 0s - loss: 0.5208 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "1/1 - 0s - loss: 0.5186 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "1/1 - 0s - loss: 0.5164 - acc: 1.0000 - 2ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26c9fcd1790>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
    "\n",
    "embedding_dim = 4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.fit(X_train, y_train, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa34fcc3",
   "metadata": {},
   "source": [
    "# 2. 사전 훈련된 워드 임베딩(Pre-Trained Word Embedding) 사용하기\n",
    "\n",
    "때로는 이미 훈련되어져 있는 워드 임베딩을 가져와서 이를 임베딩 벡터\n",
    "\n",
    "훈련 데이터가 적은 상황이라면 케라스의 Embedding()으로 해당 문제를 풀기에 최적화 된 임베딩 벡터값을 얻는 것이 쉽지 않습니다. 이 경우 해당 문제에 특화된 것은 아니지만 보다 많은 훈련 데이터로 이미 Word2Vec이나 GloVe 등으로 학습되어져 있는 임베딩 벡터들을 사용하는 것이 성능의 개선을 가져올 수 있습니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ad2c169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  0  0]\n",
      " [ 7  8  0  0]\n",
      " [ 9 10  0  0]\n",
      " [11 12  0  0]\n",
      " [13  0  0  0]\n",
      " [14 15  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8efcb305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7035ae9",
   "metadata": {},
   "source": [
    "# 1) 사전 훈련된 GloVe 사용하기\n",
    "\n",
    "glove.6B.zip를 다운로드하고 압축을 풀면 다수의 파일이 존재하는데 여기서는 glove.6B.100d.txt 파일을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74f2ef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve, urlopen\n",
    "import gzip\n",
    "import zipfile\n",
    "\n",
    "urlretrieve(\"http://nlp.stanford.edu/data/glove.6B.zip\", filename=\"glove.6B.zip\")\n",
    "zf = zipfile.ZipFile('glove.6B.zip')\n",
    "zf.extractall() \n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39137a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000개의 Embedding vector가 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# glove.6B.100d.txt에 있는 모든 임베딩 벡터들을 불러옵니다. \n",
    "# 파이썬의 자료구조 딕셔너리(dictionary)를 사용하며, 로드한 임베딩 벡터의 개수를 확인합니다.\n",
    "\n",
    "embedding_dict = dict()\n",
    "\n",
    "f = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in f:\n",
    "    word_vector = line.split()\n",
    "    word = word_vector[0]\n",
    "\n",
    "    # 100개의 값을 가지는 array로 변환\n",
    "    word_vector_arr = np.asarray(word_vector[1:], dtype='float32')\n",
    "    embedding_dict[word] = word_vector_arr\n",
    "f.close()\n",
    "\n",
    "print('%s개의 Embedding vector가 있습니다.' % len(embedding_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cc780cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.049773   0.19903    0.10585    0.1391    -0.32395    0.44053\n",
      "  0.3947    -0.22805   -0.25793    0.49768    0.15384   -0.08831\n",
      "  0.0782    -0.8299    -0.037788   0.16772   -0.45197   -0.17085\n",
      "  0.74756    0.98256    0.81872    0.28507    0.16178   -0.48626\n",
      " -0.006265  -0.92469   -0.30625   -0.067318  -0.046762  -0.76291\n",
      " -0.0025264 -0.018795   0.12882   -0.52457    0.3586     0.43119\n",
      " -0.89477   -0.057421  -0.53724    0.25587    0.55195    0.44698\n",
      " -0.24252    0.29946    0.25776   -0.8717     0.68426   -0.05688\n",
      " -0.1848    -0.59352   -0.11227   -0.57692   -0.013593   0.18488\n",
      " -0.32507   -0.90171    0.17672    0.075601   0.54896   -0.21488\n",
      " -0.54018   -0.45882   -0.79536    0.26331    0.18879   -0.16363\n",
      "  0.3975     0.1099     0.1164    -0.083499   0.50159    0.35802\n",
      "  0.25677    0.088546   0.42108    0.28674   -0.71285   -0.82915\n",
      "  0.15297   -0.82712    0.022112   1.067     -0.31776    0.1211\n",
      " -0.069755  -0.61327    0.27308   -0.42638   -0.085084  -0.17694\n",
      " -0.0090944  0.1109     0.62543   -0.23682   -0.44928   -0.3667\n",
      " -0.21616   -0.19187   -0.032502   0.38025  ]\n",
      "벡터의 차원 수 : 100\n"
     ]
    }
   ],
   "source": [
    "print(embedding_dict['respectable'])\n",
    "print('벡터의 차원 수 :',len(embedding_dict['respectable']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4e80aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 단어 집합 크기의 행과 100개의 열을 가지는 행렬 생성. 값은 전부 0으로 채워진다.\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "np.shape(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3e2644d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('nice', 1), ('great', 2), ('best', 3), ('amazing', 4), ('stop', 5), ('lies', 6), ('pitiful', 7), ('nerd', 8), ('excellent', 9), ('work', 10), ('supreme', 11), ('quality', 12), ('bad', 13), ('highly', 14), ('respectable', 15)])\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index.items())\n",
    "\n",
    "# 기존 데이터의 각 단어와 맵핑된 정수값을 확인해봅시다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45457b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['great']\n",
    "\n",
    "# 단어 'great'의 맵핑된 정수는 2입니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84d63ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.013786   0.38216    0.53236    0.15261   -0.29694   -0.20558\n",
      " -0.41846   -0.58437   -0.77355   -0.87866   -0.37858   -0.18516\n",
      " -0.128     -0.20584   -0.22925   -0.42599    0.3725     0.26077\n",
      " -1.0702     0.62916   -0.091469   0.70348   -0.4973    -0.77691\n",
      "  0.66045    0.09465   -0.44893    0.018917   0.33146   -0.35022\n",
      " -0.35789    0.030313   0.22253   -0.23236   -0.19719   -0.0053125\n",
      " -0.25848    0.58081   -0.10705   -0.17845   -0.16206    0.087086\n",
      "  0.63029   -0.76649    0.51619    0.14073    1.019     -0.43136\n",
      "  0.46138   -0.43585   -0.47568    0.19226    0.36065    0.78987\n",
      "  0.088945  -2.7814    -0.15366    0.01015    1.1798     0.15168\n",
      " -0.050112   1.2626    -0.77527    0.36031    0.95761   -0.11385\n",
      "  0.28035   -0.02591    0.31246   -0.15424    0.3778    -0.13599\n",
      "  0.2946    -0.31579    0.42943    0.086969   0.019169  -0.27242\n",
      " -0.31696    0.37327    0.61997    0.13889    0.17188    0.30363\n",
      " -1.2776     0.044423  -0.52736   -0.88536   -0.19428   -0.61947\n",
      " -0.10146   -0.26301   -0.061707   0.36627   -0.95223   -0.39346\n",
      " -0.69183   -1.0426     0.28855    0.63056  ]\n"
     ]
    }
   ],
   "source": [
    "print(embedding_dict['great'])\n",
    "\n",
    "# 사전 훈련된 GloVe에서 'great'의 벡터값을 확인합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d04e757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 집합의 모든 단어에 대해서 사전 훈련된 GloVe의 임베딩 벡터들을 맵핑한 후 \n",
    "# 'great'의 벡터값이 의도한 인덱스의 위치에 삽입되었는지 확인해보겠습니다.\n",
    "\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    # 단어와 맵핑되는 사전 훈련된 임베딩 벡터값\n",
    "    vector_value = embedding_dict.get(word)\n",
    "    if vector_value is not None:\n",
    "        embedding_matrix[index] = vector_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9cfb8a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.013786  ,  0.38216001,  0.53236002,  0.15261   , -0.29694   ,\n",
       "       -0.20558   , -0.41846001, -0.58437002, -0.77354997, -0.87866002,\n",
       "       -0.37858   , -0.18516   , -0.12800001, -0.20584001, -0.22925   ,\n",
       "       -0.42598999,  0.3725    ,  0.26076999, -1.07019997,  0.62915999,\n",
       "       -0.091469  ,  0.70348001, -0.4973    , -0.77691001,  0.66044998,\n",
       "        0.09465   , -0.44893   ,  0.018917  ,  0.33146   , -0.35021999,\n",
       "       -0.35789001,  0.030313  ,  0.22253001, -0.23236001, -0.19719   ,\n",
       "       -0.0053125 , -0.25848001,  0.58081001, -0.10705   , -0.17845   ,\n",
       "       -0.16205999,  0.087086  ,  0.63028997, -0.76648998,  0.51618999,\n",
       "        0.14072999,  1.01900005, -0.43136001,  0.46138   , -0.43584999,\n",
       "       -0.47567999,  0.19226   ,  0.36065   ,  0.78987002,  0.088945  ,\n",
       "       -2.78139997, -0.15366   ,  0.01015   ,  1.17980003,  0.15167999,\n",
       "       -0.050112  ,  1.26259995, -0.77526999,  0.36030999,  0.95761001,\n",
       "       -0.11385   ,  0.28035   , -0.02591   ,  0.31246001, -0.15424   ,\n",
       "        0.37779999, -0.13598999,  0.29460001, -0.31579   ,  0.42943001,\n",
       "        0.086969  ,  0.019169  , -0.27241999, -0.31696001,  0.37327   ,\n",
       "        0.61997002,  0.13889   ,  0.17188001,  0.30362999, -1.27760005,\n",
       "        0.044423  , -0.52736002, -0.88536   , -0.19428   , -0.61947   ,\n",
       "       -0.10146   , -0.26301   , -0.061707  ,  0.36627001, -0.95222998,\n",
       "       -0.39346001, -0.69182998, -1.04260004,  0.28854999,  0.63055998])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[2]\n",
    "\n",
    "# embedding_matrix의 인덱스 2에서의 값을 확인합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed855e9c",
   "metadata": {},
   "source": [
    "이전에 확인한 사전에 훈련된 GloVe에서의 'great'의 벡터값과 일치합니다. \n",
    "\n",
    "이제 Embedding layer에 embedding_matrix를 초기값으로 설정합니다. \n",
    "\n",
    "현재 실습에서 사전 훈련된 워드 임베딩을 100차원의 값인 것으로 사용하고 있기 때문에 임베딩 층의 output_dim의 인자값으로 100을 주어야 합니다. \n",
    "\n",
    "그리고 사전 훈련된 워드 임베딩을 그대로 사용할 경우 추가 훈련을 하지 않는다는 의미에서 trainable의 인자값을 False로 선택할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2a1bd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 - 0s - loss: 0.6687 - acc: 0.4286 - 380ms/epoch - 380ms/step\n",
      "Epoch 2/100\n",
      "1/1 - 0s - loss: 0.6514 - acc: 0.4286 - 2ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "1/1 - 0s - loss: 0.6347 - acc: 0.5714 - 2ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "1/1 - 0s - loss: 0.6185 - acc: 0.5714 - 2ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "1/1 - 0s - loss: 0.6027 - acc: 0.5714 - 2ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "1/1 - 0s - loss: 0.5874 - acc: 0.5714 - 3ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "1/1 - 0s - loss: 0.5726 - acc: 0.7143 - 3ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "1/1 - 0s - loss: 0.5582 - acc: 0.7143 - 2ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "1/1 - 0s - loss: 0.5442 - acc: 0.7143 - 3ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "1/1 - 0s - loss: 0.5306 - acc: 0.7143 - 2ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "1/1 - 0s - loss: 0.5175 - acc: 0.7143 - 2ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "1/1 - 0s - loss: 0.5047 - acc: 0.7143 - 2ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "1/1 - 0s - loss: 0.4923 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "1/1 - 0s - loss: 0.4802 - acc: 0.8571 - 3ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "1/1 - 0s - loss: 0.4685 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "1/1 - 0s - loss: 0.4572 - acc: 0.8571 - 3ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "1/1 - 0s - loss: 0.4461 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "1/1 - 0s - loss: 0.4354 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "1/1 - 0s - loss: 0.4250 - acc: 0.8571 - 3ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "1/1 - 0s - loss: 0.4148 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "1/1 - 0s - loss: 0.4050 - acc: 0.8571 - 997us/epoch - 997us/step\n",
      "Epoch 22/100\n",
      "1/1 - 0s - loss: 0.3954 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "1/1 - 0s - loss: 0.3861 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "1/1 - 0s - loss: 0.3771 - acc: 0.8571 - 3ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "1/1 - 0s - loss: 0.3683 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "1/1 - 0s - loss: 0.3598 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "1/1 - 0s - loss: 0.3515 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "1/1 - 0s - loss: 0.3434 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "1/1 - 0s - loss: 0.3356 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "1/1 - 0s - loss: 0.3280 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "1/1 - 0s - loss: 0.3206 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "1/1 - 0s - loss: 0.3134 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "1/1 - 0s - loss: 0.3065 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "1/1 - 0s - loss: 0.2997 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "1/1 - 0s - loss: 0.2931 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "1/1 - 0s - loss: 0.2867 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "1/1 - 0s - loss: 0.2805 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "1/1 - 0s - loss: 0.2745 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "1/1 - 0s - loss: 0.2687 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "1/1 - 0s - loss: 0.2630 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "1/1 - 0s - loss: 0.2574 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "1/1 - 0s - loss: 0.2521 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "1/1 - 0s - loss: 0.2469 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "1/1 - 0s - loss: 0.2418 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "1/1 - 0s - loss: 0.2369 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "1/1 - 0s - loss: 0.2321 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "1/1 - 0s - loss: 0.2275 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "1/1 - 0s - loss: 0.2230 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "1/1 - 0s - loss: 0.2186 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "1/1 - 0s - loss: 0.2143 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "1/1 - 0s - loss: 0.2102 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "1/1 - 0s - loss: 0.2061 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "1/1 - 0s - loss: 0.2022 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "1/1 - 0s - loss: 0.1984 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "1/1 - 0s - loss: 0.1947 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "1/1 - 0s - loss: 0.1911 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "1/1 - 0s - loss: 0.1876 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "1/1 - 0s - loss: 0.1842 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "1/1 - 0s - loss: 0.1809 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "1/1 - 0s - loss: 0.1777 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "1/1 - 0s - loss: 0.1745 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "1/1 - 0s - loss: 0.1715 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "1/1 - 0s - loss: 0.1685 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "1/1 - 0s - loss: 0.1656 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "1/1 - 0s - loss: 0.1627 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "1/1 - 0s - loss: 0.1600 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "1/1 - 0s - loss: 0.1573 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "1/1 - 0s - loss: 0.1547 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "1/1 - 0s - loss: 0.1521 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "1/1 - 0s - loss: 0.1497 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "1/1 - 0s - loss: 0.1472 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "1/1 - 0s - loss: 0.1449 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "1/1 - 0s - loss: 0.1426 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "1/1 - 0s - loss: 0.1403 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "1/1 - 0s - loss: 0.1381 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "1/1 - 0s - loss: 0.1360 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "1/1 - 0s - loss: 0.1339 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "1/1 - 0s - loss: 0.1319 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "1/1 - 0s - loss: 0.1299 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "1/1 - 0s - loss: 0.1279 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "1/1 - 0s - loss: 0.1260 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "1/1 - 0s - loss: 0.1242 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "1/1 - 0s - loss: 0.1224 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "1/1 - 0s - loss: 0.1206 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "1/1 - 0s - loss: 0.1189 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "1/1 - 0s - loss: 0.1172 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "1/1 - 0s - loss: 0.1155 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "1/1 - 0s - loss: 0.1139 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "1/1 - 0s - loss: 0.1124 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "1/1 - 0s - loss: 0.1108 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "1/1 - 0s - loss: 0.1093 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "1/1 - 0s - loss: 0.1078 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "1/1 - 0s - loss: 0.1064 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "1/1 - 0s - loss: 0.1050 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "1/1 - 0s - loss: 0.1036 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "1/1 - 0s - loss: 0.1022 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "1/1 - 0s - loss: 0.1009 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "1/1 - 0s - loss: 0.0996 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "1/1 - 0s - loss: 0.0983 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "1/1 - 0s - loss: 0.0971 - acc: 1.0000 - 3ms/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26ca76b1760>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
    "\n",
    "output_dim = 100\n",
    "\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, output_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.fit(X_train, y_train, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9c57d4",
   "metadata": {},
   "source": [
    "## 2) 사전 훈련된 Word2Vec 사용하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cafa56fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "843e5364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import re\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a40d2a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27bf9724",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in c:\\users\\user\\anaconda3\\envs\\la1\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\user\\anaconda3\\envs\\la1\\lib\\site-packages (from konlpy) (1.23.5)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\users\\user\\anaconda3\\envs\\la1\\lib\\site-packages (from konlpy) (1.4.1)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\user\\anaconda3\\envs\\la1\\lib\\site-packages (from konlpy) (4.9.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\envs\\la1\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (23.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ab64037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from lxml import etree\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94f0a1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\user\\anaconda3\\envs\\la1\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\envs\\la1\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\envs\\la1\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\anaconda3\\envs\\la1\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\envs\\la1\\lib\\site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\la1\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d45072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a01ea3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\envs\\la1\\lib\\site-packages (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\la1\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5eeb2fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c5ce9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import urllib.request\n",
    "\n",
    "# 구글의 사전 훈련된 Word2Vec 모델을 로드.\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4db90d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 크기(shape) : (3000000, 300)\n"
     ]
    }
   ],
   "source": [
    "print('모델의 크기(shape) :',word2vec_model.vectors.shape) # 모델의 크기 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e2b06c",
   "metadata": {},
   "source": [
    "300의 차원을 가진 Word2Vec 벡터가 3,000,000개 있습니다. 모든 값이 0으로 채워진 임베딩 행렬을 만들어줍니다. 풀고자 하는 문제의 단어 집합 크기의 행과 300개의 열을 가지는 행렬 생성합니다. 이 행렬의 값은 전부 0으로 채웁니다. 이 행렬에 사전 훈련된 임베딩 값을 넣어줄 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e16f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 집합 크기의 행과 300개의 열을 가지는 행렬 생성. 값은 전부 0으로 채워진다.\n",
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "np.shape(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf9d51e",
   "metadata": {},
   "source": [
    "word2vec_model에서 특정 단어를 입력하면 해당 단어의 임베딩 벡터를 리턴받을텐데, 만약 word2vec_model에 특정 단어의 임베딩 벡터가 없다면 None을 리턴하도록 하는 함수 get_vector()를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cac5b3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_vector(word):\n",
    "    if word in word2vec_model:\n",
    "        return word2vec_model[word]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b97693",
   "metadata": {},
   "source": [
    "단어 집합으로부터 단어를 1개씩 호출하여 word2vec_model에 해당 단어의 임베딩 벡터값이 존재하는지 확인합니다. 만약 None이 아니라면 존재한다는 의미이므로 임베딩 행렬에 해당 단어의 인덱스 위치의 행에 임베딩 벡터의 값을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e15abd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    # 단어와 맵핑되는 사전 훈련된 임베딩 벡터값\n",
    "    vector_value = get_vector(word)\n",
    "    if vector_value is not None:\n",
    "        embedding_matrix[index] = vector_value\n",
    "        \n",
    "# 현재 풀고자하는 문제의 16개의 단어와 맵핑되는 임베딩 행렬이 완성됩니다. 제대로 맵핑이 됐는지 확인해볼까요? \n",
    "# 기존에 word2vec_model에 저장되어 있던 단어 'nice'의 임베딩 벡터값을 확인해봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8192cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.15820312  0.10595703 -0.18945312  0.38671875  0.08349609 -0.26757812\n",
      "  0.08349609  0.11328125 -0.10400391  0.17871094 -0.12353516 -0.22265625\n",
      " -0.01806641 -0.25390625  0.13183594  0.0859375   0.16113281  0.11083984\n",
      " -0.11083984 -0.0859375   0.0267334   0.34570312  0.15136719 -0.00415039\n",
      "  0.10498047  0.04907227 -0.06982422  0.08642578  0.03198242 -0.02844238\n",
      " -0.15722656  0.11865234  0.36132812  0.00173187  0.05297852 -0.234375\n",
      "  0.11767578  0.08642578 -0.01123047  0.25976562  0.28515625 -0.11669922\n",
      "  0.38476562  0.07275391  0.01147461  0.03466797  0.18164062 -0.03955078\n",
      "  0.04199219  0.01013184 -0.06054688  0.09765625  0.06689453  0.14648438\n",
      " -0.12011719  0.08447266 -0.06152344  0.06347656  0.3046875  -0.35546875\n",
      " -0.2890625   0.19628906 -0.33203125 -0.07128906  0.12792969  0.09619141\n",
      " -0.12158203 -0.08691406 -0.12890625  0.27734375  0.265625    0.1796875\n",
      "  0.12695312  0.06298828 -0.34375    -0.05908203  0.0456543   0.171875\n",
      "  0.08935547  0.14648438 -0.04638672 -0.00842285 -0.0279541   0.234375\n",
      " -0.07470703 -0.13574219  0.00378418  0.19433594  0.05664062 -0.05419922\n",
      "  0.06176758  0.14160156 -0.24121094  0.02539062 -0.15917969 -0.10595703\n",
      "  0.11865234  0.24707031 -0.13574219 -0.20410156 -0.30078125  0.07910156\n",
      " -0.04394531  0.02026367 -0.05786133  0.2109375   0.13574219  0.08349609\n",
      " -0.0098877  -0.10546875 -0.08105469  0.03735352 -0.10351562 -0.10205078\n",
      "  0.23925781 -0.21875     0.05151367  0.06738281  0.07617188  0.04638672\n",
      "  0.03198242 -0.07275391  0.14550781  0.04858398 -0.05664062 -0.07470703\n",
      " -0.0030365  -0.09277344 -0.11083984 -0.03320312 -0.15234375 -0.12207031\n",
      "  0.09814453  0.375       0.00454712 -0.10009766  0.02734375  0.30078125\n",
      " -0.0390625   0.30078125 -0.04541016 -0.00424194  0.13671875 -0.18945312\n",
      " -0.21777344  0.12695312 -0.02746582 -0.18164062  0.08984375 -0.23339844\n",
      "  0.203125    0.2734375  -0.26953125  0.15332031 -0.20703125 -0.01153564\n",
      "  0.12451172  0.05395508 -0.23535156 -0.01409912 -0.09765625  0.20800781\n",
      "  0.19335938  0.14746094  0.28710938 -0.23046875  0.01965332 -0.09619141\n",
      " -0.0703125  -0.04174805 -0.17578125  0.0007019   0.10546875  0.10351562\n",
      "  0.02478027  0.35742188  0.17382812 -0.09570312 -0.18359375  0.23242188\n",
      " -0.14453125 -0.20410156 -0.01867676  0.06640625 -0.2265625  -0.00582886\n",
      " -0.08642578  0.02416992 -0.07324219 -0.29882812 -0.15625     0.07666016\n",
      "  0.19628906 -0.20410156  0.09863281 -0.01672363 -0.18652344 -0.12353516\n",
      " -0.16015625 -0.10058594  0.21777344  0.09375    -0.10058594 -0.03637695\n",
      "  0.15136719 -0.02526855 -0.23730469  0.03417969 -0.00604248  0.15625\n",
      " -0.14257812  0.18066406 -0.35351562  0.25        0.13085938 -0.04296875\n",
      "  0.17089844  0.20507812  0.00680542 -0.08251953 -0.06738281  0.22167969\n",
      " -0.16308594 -0.16699219 -0.02087402  0.11035156  0.06054688 -0.04223633\n",
      " -0.17285156  0.05029297 -0.19824219  0.01495361  0.06542969  0.03271484\n",
      "  0.14453125 -0.08691406 -0.11035156 -0.1484375   0.09667969  0.22363281\n",
      "  0.23535156  0.08398438  0.18164062 -0.10595703 -0.04296875  0.11572266\n",
      " -0.00153351  0.0534668  -0.1328125  -0.33203125 -0.08251953  0.30664062\n",
      "  0.22363281  0.27929688  0.09082031 -0.18066406 -0.00613403 -0.09423828\n",
      " -0.21289062  0.01965332 -0.08105469 -0.06689453 -0.31835938 -0.08447266\n",
      "  0.13574219  0.0625      0.07080078 -0.14257812 -0.11279297  0.01452637\n",
      " -0.06689453  0.03881836  0.19433594  0.09521484  0.11376953 -0.12451172\n",
      "  0.13769531 -0.18847656 -0.05224609  0.15820312  0.09863281 -0.04370117\n",
      " -0.06054688  0.21679688  0.04077148 -0.14648438 -0.18945312 -0.25195312\n",
      " -0.16894531 -0.08642578 -0.08544922  0.18945312 -0.14648438  0.13476562\n",
      " -0.04077148  0.03271484  0.08935547 -0.26757812  0.00836182 -0.21386719]\n"
     ]
    }
   ],
   "source": [
    "print(word2vec_model['nice'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86b86939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.17773438e-02  2.08007812e-01 -2.84423828e-02  1.78710938e-01\n",
      "  1.32812500e-01 -9.96093750e-02  9.61914062e-02 -1.16699219e-01\n",
      " -8.54492188e-03  1.48437500e-01 -3.34472656e-02 -1.85546875e-01\n",
      "  4.10156250e-02 -8.98437500e-02  2.17285156e-02  6.93359375e-02\n",
      "  1.80664062e-01  2.22656250e-01 -1.00585938e-01 -6.93359375e-02\n",
      "  1.04427338e-04  1.60156250e-01  4.07714844e-02  7.37304688e-02\n",
      "  1.53320312e-01  6.78710938e-02 -1.03027344e-01  4.17480469e-02\n",
      "  4.27246094e-02 -1.10351562e-01 -6.68945312e-02  4.19921875e-02\n",
      "  2.50000000e-01  2.12890625e-01  1.59179688e-01  1.44653320e-02\n",
      " -4.88281250e-02  1.39770508e-02  3.55529785e-03  2.09960938e-01\n",
      "  1.52343750e-01 -7.32421875e-02  2.16796875e-01 -5.76171875e-02\n",
      " -2.84423828e-02 -3.60107422e-03  1.52343750e-01 -2.63671875e-02\n",
      "  2.13623047e-02 -1.51367188e-01  1.04003906e-01  3.18359375e-01\n",
      " -1.85546875e-01  3.68652344e-02 -1.10839844e-01 -3.17382812e-02\n",
      " -1.01562500e-01 -1.21093750e-01  3.22265625e-01 -7.32421875e-02\n",
      " -1.52343750e-01  2.67578125e-01 -1.50390625e-01 -1.23046875e-01\n",
      "  1.07910156e-01  6.68945312e-02 -2.13623047e-02 -1.00585938e-01\n",
      " -2.05078125e-01  1.17675781e-01  6.15234375e-02  6.78710938e-02\n",
      "  1.06933594e-01 -7.71484375e-02 -1.52343750e-01 -4.24194336e-03\n",
      " -1.45507812e-01  2.53906250e-01  4.80957031e-02  9.71679688e-02\n",
      " -8.36181641e-03  1.12792969e-01  5.34667969e-02  1.79443359e-02\n",
      " -5.63964844e-02 -3.30078125e-01 -9.76562500e-02  1.42578125e-01\n",
      " -1.37695312e-01  2.20947266e-02  1.00097656e-01 -5.71289062e-02\n",
      " -1.56250000e-01 -6.37817383e-03 -9.37500000e-02 -4.68750000e-02\n",
      "  8.59375000e-02  3.06640625e-01 -1.11328125e-01 -1.94335938e-01\n",
      " -2.08007812e-01  8.10546875e-02 -4.19921875e-02 -8.30078125e-02\n",
      " -1.04003906e-01  2.92968750e-01  2.39257812e-02 -3.85742188e-02\n",
      "  3.56445312e-02 -1.04980469e-01 -6.54296875e-02  2.79296875e-01\n",
      " -1.16210938e-01 -1.45874023e-02  3.84765625e-01 -7.81250000e-02\n",
      " -2.92968750e-02 -1.35742188e-01 -5.39550781e-02 -5.49316406e-02\n",
      " -8.10546875e-02 -2.88085938e-02  8.34960938e-02  2.73437500e-01\n",
      " -6.20117188e-02 -4.78515625e-02 -1.09252930e-02 -1.13769531e-01\n",
      " -1.09863281e-01  2.02148438e-01 -1.28906250e-01 -6.68945312e-02\n",
      " -2.67578125e-01  9.61914062e-02  1.04003906e-01 -1.69921875e-01\n",
      "  5.56640625e-02  1.54296875e-01  8.05664062e-02  2.19726562e-01\n",
      " -2.27539062e-01  1.10351562e-01 -8.11767578e-03 -5.63964844e-02\n",
      " -9.03320312e-02 -7.76367188e-02 -3.61328125e-02  3.61328125e-02\n",
      "  1.58203125e-01 -1.56250000e-01  2.26562500e-01  2.85156250e-01\n",
      " -5.51757812e-02  3.53515625e-01 -1.20605469e-01  1.05957031e-01\n",
      "  3.11279297e-02 -1.91406250e-01 -2.31445312e-01 -1.11816406e-01\n",
      "  2.38037109e-03  7.51953125e-02 -1.28784180e-02  1.00585938e-01\n",
      "  4.45312500e-01 -2.77343750e-01  6.68945312e-02 -8.10546875e-02\n",
      "  6.39648438e-02  1.85546875e-02 -1.11328125e-01  9.76562500e-02\n",
      "  2.06054688e-01 -1.30859375e-01  2.39257812e-02  1.10839844e-01\n",
      "  8.05664062e-02 -1.52343750e-01  4.85229492e-03  1.84326172e-02\n",
      " -9.17968750e-02 -2.41210938e-01  8.39843750e-02 -1.00585938e-01\n",
      " -1.54296875e-01  2.75878906e-02 -1.64062500e-01 -1.01562500e-01\n",
      " -6.07299805e-03  1.33514404e-03 -2.53906250e-01  3.14453125e-01\n",
      "  1.31835938e-01 -1.31835938e-01  2.17285156e-02 -1.56250000e-01\n",
      " -1.46484375e-01 -5.12695312e-02 -1.20605469e-01 -2.15820312e-01\n",
      "  3.10058594e-02  1.30859375e-01  9.71679688e-02  5.67626953e-03\n",
      "  2.20947266e-02  1.26953125e-01 -1.24511719e-02  6.15234375e-02\n",
      " -2.23388672e-02  2.50000000e-01 -7.17773438e-02  1.58203125e-01\n",
      " -7.27539062e-02  1.97753906e-02  8.85009766e-03 -9.08203125e-02\n",
      "  3.63281250e-01 -9.03320312e-02  2.41699219e-02 -1.39770508e-02\n",
      " -5.10253906e-02  2.40478516e-02  5.88989258e-03 -1.02050781e-01\n",
      " -8.85009766e-03  3.05175781e-02 -7.81250000e-02 -1.27929688e-01\n",
      "  3.85742188e-02  2.86865234e-02 -2.28515625e-01 -1.25122070e-02\n",
      "  1.54296875e-01  9.13085938e-02  1.05468750e-01 -6.44531250e-02\n",
      " -1.28906250e-01 -1.02050781e-01 -2.16064453e-02 -3.29589844e-02\n",
      "  7.47070312e-02  3.78417969e-02  7.42187500e-02 -1.23901367e-02\n",
      " -4.68750000e-02  4.88281250e-03  1.03515625e-01 -8.69140625e-02\n",
      " -2.26562500e-01 -2.53906250e-01  3.58886719e-02  4.45312500e-01\n",
      "  5.56640625e-02  1.59179688e-01  2.71484375e-01 -1.08398438e-01\n",
      "  6.25000000e-02 -5.59082031e-02 -2.50000000e-01 -1.55273438e-01\n",
      " -6.83593750e-02 -1.39648438e-01 -1.59179688e-01 -1.79443359e-02\n",
      "  2.12402344e-02  7.37304688e-02  1.30859375e-01 -8.05664062e-02\n",
      "  2.99072266e-02  1.55639648e-02 -1.66015625e-01  1.50390625e-01\n",
      " -6.77490234e-03  1.01318359e-02  1.14746094e-01 -1.48437500e-01\n",
      " -4.58984375e-02 -1.39648438e-01 -1.73828125e-01 -4.27246094e-02\n",
      " -5.81054688e-02  5.22460938e-02 -1.11328125e-01  8.44726562e-02\n",
      " -2.55126953e-02  1.40625000e-01 -1.81640625e-01  1.72119141e-02\n",
      " -1.37695312e-01 -1.47705078e-02 -1.14746094e-02  6.44531250e-02\n",
      " -2.89062500e-01 -4.80957031e-02 -1.99218750e-01 -7.12890625e-02\n",
      "  6.44531250e-02 -1.67968750e-01 -2.08740234e-02 -1.42578125e-01]\n"
     ]
    }
   ],
   "source": [
    "print(word2vec_model['great'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "363760f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.15820312  0.10595703 -0.18945312  0.38671875  0.08349609 -0.26757812\n",
      "  0.08349609  0.11328125 -0.10400391  0.17871094 -0.12353516 -0.22265625\n",
      " -0.01806641 -0.25390625  0.13183594  0.0859375   0.16113281  0.11083984\n",
      " -0.11083984 -0.0859375   0.0267334   0.34570312  0.15136719 -0.00415039\n",
      "  0.10498047  0.04907227 -0.06982422  0.08642578  0.03198242 -0.02844238\n",
      " -0.15722656  0.11865234  0.36132812  0.00173187  0.05297852 -0.234375\n",
      "  0.11767578  0.08642578 -0.01123047  0.25976562  0.28515625 -0.11669922\n",
      "  0.38476562  0.07275391  0.01147461  0.03466797  0.18164062 -0.03955078\n",
      "  0.04199219  0.01013184 -0.06054688  0.09765625  0.06689453  0.14648438\n",
      " -0.12011719  0.08447266 -0.06152344  0.06347656  0.3046875  -0.35546875\n",
      " -0.2890625   0.19628906 -0.33203125 -0.07128906  0.12792969  0.09619141\n",
      " -0.12158203 -0.08691406 -0.12890625  0.27734375  0.265625    0.1796875\n",
      "  0.12695312  0.06298828 -0.34375    -0.05908203  0.0456543   0.171875\n",
      "  0.08935547  0.14648438 -0.04638672 -0.00842285 -0.0279541   0.234375\n",
      " -0.07470703 -0.13574219  0.00378418  0.19433594  0.05664062 -0.05419922\n",
      "  0.06176758  0.14160156 -0.24121094  0.02539062 -0.15917969 -0.10595703\n",
      "  0.11865234  0.24707031 -0.13574219 -0.20410156 -0.30078125  0.07910156\n",
      " -0.04394531  0.02026367 -0.05786133  0.2109375   0.13574219  0.08349609\n",
      " -0.0098877  -0.10546875 -0.08105469  0.03735352 -0.10351562 -0.10205078\n",
      "  0.23925781 -0.21875     0.05151367  0.06738281  0.07617188  0.04638672\n",
      "  0.03198242 -0.07275391  0.14550781  0.04858398 -0.05664062 -0.07470703\n",
      " -0.0030365  -0.09277344 -0.11083984 -0.03320312 -0.15234375 -0.12207031\n",
      "  0.09814453  0.375       0.00454712 -0.10009766  0.02734375  0.30078125\n",
      " -0.0390625   0.30078125 -0.04541016 -0.00424194  0.13671875 -0.18945312\n",
      " -0.21777344  0.12695312 -0.02746582 -0.18164062  0.08984375 -0.23339844\n",
      "  0.203125    0.2734375  -0.26953125  0.15332031 -0.20703125 -0.01153564\n",
      "  0.12451172  0.05395508 -0.23535156 -0.01409912 -0.09765625  0.20800781\n",
      "  0.19335938  0.14746094  0.28710938 -0.23046875  0.01965332 -0.09619141\n",
      " -0.0703125  -0.04174805 -0.17578125  0.0007019   0.10546875  0.10351562\n",
      "  0.02478027  0.35742188  0.17382812 -0.09570312 -0.18359375  0.23242188\n",
      " -0.14453125 -0.20410156 -0.01867676  0.06640625 -0.2265625  -0.00582886\n",
      " -0.08642578  0.02416992 -0.07324219 -0.29882812 -0.15625     0.07666016\n",
      "  0.19628906 -0.20410156  0.09863281 -0.01672363 -0.18652344 -0.12353516\n",
      " -0.16015625 -0.10058594  0.21777344  0.09375    -0.10058594 -0.03637695\n",
      "  0.15136719 -0.02526855 -0.23730469  0.03417969 -0.00604248  0.15625\n",
      " -0.14257812  0.18066406 -0.35351562  0.25        0.13085938 -0.04296875\n",
      "  0.17089844  0.20507812  0.00680542 -0.08251953 -0.06738281  0.22167969\n",
      " -0.16308594 -0.16699219 -0.02087402  0.11035156  0.06054688 -0.04223633\n",
      " -0.17285156  0.05029297 -0.19824219  0.01495361  0.06542969  0.03271484\n",
      "  0.14453125 -0.08691406 -0.11035156 -0.1484375   0.09667969  0.22363281\n",
      "  0.23535156  0.08398438  0.18164062 -0.10595703 -0.04296875  0.11572266\n",
      " -0.00153351  0.0534668  -0.1328125  -0.33203125 -0.08251953  0.30664062\n",
      "  0.22363281  0.27929688  0.09082031 -0.18066406 -0.00613403 -0.09423828\n",
      " -0.21289062  0.01965332 -0.08105469 -0.06689453 -0.31835938 -0.08447266\n",
      "  0.13574219  0.0625      0.07080078 -0.14257812 -0.11279297  0.01452637\n",
      " -0.06689453  0.03881836  0.19433594  0.09521484  0.11376953 -0.12451172\n",
      "  0.13769531 -0.18847656 -0.05224609  0.15820312  0.09863281 -0.04370117\n",
      " -0.06054688  0.21679688  0.04077148 -0.14648438 -0.18945312 -0.25195312\n",
      " -0.16894531 -0.08642578 -0.08544922  0.18945312 -0.14648438  0.13476562\n",
      " -0.04077148  0.03271484  0.08935547 -0.26757812  0.00836182 -0.21386719]\n"
     ]
    }
   ],
   "source": [
    "print(word2vec_model['nice'])\n",
    "\n",
    "# 단어 nice의 맵핑된 정수 : 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "504cef76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 nice의 맵핑된 정수 : 1\n"
     ]
    }
   ],
   "source": [
    "print('단어 nice의 맵핑된 정수 :', tokenizer.word_index['nice'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "424684be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.15820312  0.10595703 -0.18945312  0.38671875  0.08349609 -0.26757812\n",
      "  0.08349609  0.11328125 -0.10400391  0.17871094 -0.12353516 -0.22265625\n",
      " -0.01806641 -0.25390625  0.13183594  0.0859375   0.16113281  0.11083984\n",
      " -0.11083984 -0.0859375   0.0267334   0.34570312  0.15136719 -0.00415039\n",
      "  0.10498047  0.04907227 -0.06982422  0.08642578  0.03198242 -0.02844238\n",
      " -0.15722656  0.11865234  0.36132812  0.00173187  0.05297852 -0.234375\n",
      "  0.11767578  0.08642578 -0.01123047  0.25976562  0.28515625 -0.11669922\n",
      "  0.38476562  0.07275391  0.01147461  0.03466797  0.18164062 -0.03955078\n",
      "  0.04199219  0.01013184 -0.06054688  0.09765625  0.06689453  0.14648438\n",
      " -0.12011719  0.08447266 -0.06152344  0.06347656  0.3046875  -0.35546875\n",
      " -0.2890625   0.19628906 -0.33203125 -0.07128906  0.12792969  0.09619141\n",
      " -0.12158203 -0.08691406 -0.12890625  0.27734375  0.265625    0.1796875\n",
      "  0.12695312  0.06298828 -0.34375    -0.05908203  0.0456543   0.171875\n",
      "  0.08935547  0.14648438 -0.04638672 -0.00842285 -0.0279541   0.234375\n",
      " -0.07470703 -0.13574219  0.00378418  0.19433594  0.05664062 -0.05419922\n",
      "  0.06176758  0.14160156 -0.24121094  0.02539062 -0.15917969 -0.10595703\n",
      "  0.11865234  0.24707031 -0.13574219 -0.20410156 -0.30078125  0.07910156\n",
      " -0.04394531  0.02026367 -0.05786133  0.2109375   0.13574219  0.08349609\n",
      " -0.0098877  -0.10546875 -0.08105469  0.03735352 -0.10351562 -0.10205078\n",
      "  0.23925781 -0.21875     0.05151367  0.06738281  0.07617188  0.04638672\n",
      "  0.03198242 -0.07275391  0.14550781  0.04858398 -0.05664062 -0.07470703\n",
      " -0.0030365  -0.09277344 -0.11083984 -0.03320312 -0.15234375 -0.12207031\n",
      "  0.09814453  0.375       0.00454712 -0.10009766  0.02734375  0.30078125\n",
      " -0.0390625   0.30078125 -0.04541016 -0.00424194  0.13671875 -0.18945312\n",
      " -0.21777344  0.12695312 -0.02746582 -0.18164062  0.08984375 -0.23339844\n",
      "  0.203125    0.2734375  -0.26953125  0.15332031 -0.20703125 -0.01153564\n",
      "  0.12451172  0.05395508 -0.23535156 -0.01409912 -0.09765625  0.20800781\n",
      "  0.19335938  0.14746094  0.28710938 -0.23046875  0.01965332 -0.09619141\n",
      " -0.0703125  -0.04174805 -0.17578125  0.0007019   0.10546875  0.10351562\n",
      "  0.02478027  0.35742188  0.17382812 -0.09570312 -0.18359375  0.23242188\n",
      " -0.14453125 -0.20410156 -0.01867676  0.06640625 -0.2265625  -0.00582886\n",
      " -0.08642578  0.02416992 -0.07324219 -0.29882812 -0.15625     0.07666016\n",
      "  0.19628906 -0.20410156  0.09863281 -0.01672363 -0.18652344 -0.12353516\n",
      " -0.16015625 -0.10058594  0.21777344  0.09375    -0.10058594 -0.03637695\n",
      "  0.15136719 -0.02526855 -0.23730469  0.03417969 -0.00604248  0.15625\n",
      " -0.14257812  0.18066406 -0.35351562  0.25        0.13085938 -0.04296875\n",
      "  0.17089844  0.20507812  0.00680542 -0.08251953 -0.06738281  0.22167969\n",
      " -0.16308594 -0.16699219 -0.02087402  0.11035156  0.06054688 -0.04223633\n",
      " -0.17285156  0.05029297 -0.19824219  0.01495361  0.06542969  0.03271484\n",
      "  0.14453125 -0.08691406 -0.11035156 -0.1484375   0.09667969  0.22363281\n",
      "  0.23535156  0.08398438  0.18164062 -0.10595703 -0.04296875  0.11572266\n",
      " -0.00153351  0.0534668  -0.1328125  -0.33203125 -0.08251953  0.30664062\n",
      "  0.22363281  0.27929688  0.09082031 -0.18066406 -0.00613403 -0.09423828\n",
      " -0.21289062  0.01965332 -0.08105469 -0.06689453 -0.31835938 -0.08447266\n",
      "  0.13574219  0.0625      0.07080078 -0.14257812 -0.11279297  0.01452637\n",
      " -0.06689453  0.03881836  0.19433594  0.09521484  0.11376953 -0.12451172\n",
      "  0.13769531 -0.18847656 -0.05224609  0.15820312  0.09863281 -0.04370117\n",
      " -0.06054688  0.21679688  0.04077148 -0.14648438 -0.18945312 -0.25195312\n",
      " -0.16894531 -0.08642578 -0.08544922  0.18945312 -0.14648438  0.13476562\n",
      " -0.04077148  0.03271484  0.08935547 -0.26757812  0.00836182 -0.21386719]\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8318f351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 - 0s - loss: 0.6868 - acc: 0.5714 - 397ms/epoch - 397ms/step\n",
      "Epoch 2/100\n",
      "1/1 - 0s - loss: 0.6690 - acc: 0.5714 - 3ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "1/1 - 0s - loss: 0.6518 - acc: 0.7143 - 2ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "1/1 - 0s - loss: 0.6351 - acc: 0.7143 - 2ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "1/1 - 0s - loss: 0.6189 - acc: 0.8571 - 3ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "1/1 - 0s - loss: 0.6032 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "1/1 - 0s - loss: 0.5880 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "1/1 - 0s - loss: 0.5733 - acc: 0.8571 - 3ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "1/1 - 0s - loss: 0.5591 - acc: 0.8571 - 3ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "1/1 - 0s - loss: 0.5453 - acc: 0.8571 - 1ms/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "1/1 - 0s - loss: 0.5320 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "1/1 - 0s - loss: 0.5191 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "1/1 - 0s - loss: 0.5067 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "1/1 - 0s - loss: 0.4946 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "1/1 - 0s - loss: 0.4829 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "1/1 - 0s - loss: 0.4716 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "1/1 - 0s - loss: 0.4607 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "1/1 - 0s - loss: 0.4501 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "1/1 - 0s - loss: 0.4398 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "1/1 - 0s - loss: 0.4299 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "1/1 - 0s - loss: 0.4202 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "1/1 - 0s - loss: 0.4109 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "1/1 - 0s - loss: 0.4018 - acc: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "1/1 - 0s - loss: 0.3930 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "1/1 - 0s - loss: 0.3845 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "1/1 - 0s - loss: 0.3762 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "1/1 - 0s - loss: 0.3681 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "1/1 - 0s - loss: 0.3603 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "1/1 - 0s - loss: 0.3527 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "1/1 - 0s - loss: 0.3454 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "1/1 - 0s - loss: 0.3382 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "1/1 - 0s - loss: 0.3313 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "1/1 - 0s - loss: 0.3245 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "1/1 - 0s - loss: 0.3179 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "1/1 - 0s - loss: 0.3116 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "1/1 - 0s - loss: 0.3054 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "1/1 - 0s - loss: 0.2993 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "1/1 - 0s - loss: 0.2935 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "1/1 - 0s - loss: 0.2878 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "1/1 - 0s - loss: 0.2822 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "1/1 - 0s - loss: 0.2768 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "1/1 - 0s - loss: 0.2716 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "1/1 - 0s - loss: 0.2665 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "1/1 - 0s - loss: 0.2615 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "1/1 - 0s - loss: 0.2567 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "1/1 - 0s - loss: 0.2520 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "1/1 - 0s - loss: 0.2474 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "1/1 - 0s - loss: 0.2430 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "1/1 - 0s - loss: 0.2386 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "1/1 - 0s - loss: 0.2344 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "1/1 - 0s - loss: 0.2303 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "1/1 - 0s - loss: 0.2263 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "1/1 - 0s - loss: 0.2224 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "1/1 - 0s - loss: 0.2186 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "1/1 - 0s - loss: 0.2148 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "1/1 - 0s - loss: 0.2112 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "1/1 - 0s - loss: 0.2077 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "1/1 - 0s - loss: 0.2043 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "1/1 - 0s - loss: 0.2009 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "1/1 - 0s - loss: 0.1976 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "1/1 - 0s - loss: 0.1944 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "1/1 - 0s - loss: 0.1913 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "1/1 - 0s - loss: 0.1883 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "1/1 - 0s - loss: 0.1853 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "1/1 - 0s - loss: 0.1824 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "1/1 - 0s - loss: 0.1796 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "1/1 - 0s - loss: 0.1768 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "1/1 - 0s - loss: 0.1741 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "1/1 - 0s - loss: 0.1715 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "1/1 - 0s - loss: 0.1689 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "1/1 - 0s - loss: 0.1664 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "1/1 - 0s - loss: 0.1639 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "1/1 - 0s - loss: 0.1615 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "1/1 - 0s - loss: 0.1592 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "1/1 - 0s - loss: 0.1569 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "1/1 - 0s - loss: 0.1546 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "1/1 - 0s - loss: 0.1524 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "1/1 - 0s - loss: 0.1503 - acc: 1.0000 - 998us/epoch - 998us/step\n",
      "Epoch 79/100\n",
      "1/1 - 0s - loss: 0.1482 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "1/1 - 0s - loss: 0.1461 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "1/1 - 0s - loss: 0.1441 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "1/1 - 0s - loss: 0.1421 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "1/1 - 0s - loss: 0.1402 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "1/1 - 0s - loss: 0.1383 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "1/1 - 0s - loss: 0.1365 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "1/1 - 0s - loss: 0.1347 - acc: 1.0000 - 997us/epoch - 997us/step\n",
      "Epoch 87/100\n",
      "1/1 - 0s - loss: 0.1329 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "1/1 - 0s - loss: 0.1311 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "1/1 - 0s - loss: 0.1294 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "1/1 - 0s - loss: 0.1278 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "1/1 - 0s - loss: 0.1261 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "1/1 - 0s - loss: 0.1245 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "1/1 - 0s - loss: 0.1230 - acc: 1.0000 - 998us/epoch - 998us/step\n",
      "Epoch 94/100\n",
      "1/1 - 0s - loss: 0.1214 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "1/1 - 0s - loss: 0.1199 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "1/1 - 0s - loss: 0.1184 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "1/1 - 0s - loss: 0.1170 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "1/1 - 0s - loss: 0.1156 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "1/1 - 0s - loss: 0.1142 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "1/1 - 0s - loss: 0.1128 - acc: 1.0000 - 2ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26dab75c0a0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 값이 word2vec_model에서 확인했던 것과 동일한 것을 확인할 수 있습니다. \n",
    "# 단어 집합에 있는 다른 단어들에 대해서도 확인해보세요.\n",
    "# 이제 Embedding에 사전 훈련된 embedding_matrix를 입력으로 넣어주고 모델을 학습시켜보겠습니다.\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten, Input\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(max_len,), dtype='int32'))\n",
    "e = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_len, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.fit(X_train, y_train, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8261f81a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
