{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e578c9a",
   "metadata": {},
   "source": [
    "# 03-05 Perplexity, PPL (펄플렉서티)\n",
    "\n",
    "출처:https://wikidocs.net/21697 \n",
    "\n",
    "두 개의 모델 A, B가 있을 때 이 모델의 성능은 어떻게 비교할 수 있을까? \n",
    "\n",
    "두 모델을 오타 교정, 기계 번역 등의 평가에 투입 - 성능을 비교하면 됨. \n",
    "\n",
    "-> 그런데 이는 공수가 너무 많이 드는 작업.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* ->> 조금은 부정확할 수 있어도. 테스트 데이터에 대해서 빠르게 식으로 계산되는\n",
    "      방법이 있음. 바로 모델 내에서 자신의 성능을 수치화하여 결과를 내놓는\n",
    "      \n",
    "    ### 펄플렉서티(perplexity)\n",
    "\n",
    "\n",
    "## 1. 언어 모델의 평가 방법(Evaluation metric) : PPL\n",
    "\n",
    "펄플렉서티(perplexity)는 언어 모델을 평가하기 위한 평가 지표입니다. 보통 줄여서 PPL이 라고 표현\n",
    "\n",
    "'perplexed'는 '헷갈리는'과 유사한 의미를 가집니다. 그러니까 여기서 PPL은 '헷갈리는 정도'로 이해\n",
    "\n",
    "* PPL은 수치가 높으면 좋은 성능을 의미하는 것이 아니라, '낮을수록' 언어 모델의 성능이 좋다는 것을 의미\n",
    "\n",
    "PPL은 문장의 길이로 정규화된 문장 확률의 역수입니다. 문장의 길이가 이라고 하였을 때의 PPL은 다음과 같습니다.\n",
    "\n",
    "관련 수식은 아래와 같다. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d49e10",
   "metadata": {},
   "source": [
    "![PPL 그림이미지](image/Perplexity.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7377fc",
   "metadata": {},
   "source": [
    "## 2. 분기 계수(Branching factor)\n",
    "\n",
    "\n",
    "* PPL은 선택할 수 있는 가능한 경우의 수를 의미하는 분기계수(branching factor)입니다. PPL은 이 언어 모델이 특정 시점에서 평균적으로 몇 개의 선택지를 가지고 고민하고 있는지를 의미\n",
    "\n",
    "측정했더니 10.\n",
    "\n",
    "-> 그렇다면 해당 언어 모델은 테스트 데이터에 대해서 다음 단어를 예측하는 모든 시점(time step)마다 평균 10개의 단어를 가지고 어떤 것이 정답인지 고민하고 있다고 볼 수 있습니다. \n",
    "\n",
    "\n",
    "### 단, 평가 방법에 있어서 주의할 점은 PPL의 값이 낮다는 것은 테스트 데이터 상에서 높은 정확도를 보인다는 것이지, 사람이 직접 느끼기에 좋은 언어 모델이라는 것을 반드시 의미하진 않는다는 점\n",
    "\n",
    "###  PPL은 테스트 데이터에 의존하므로 두 개 이상의 언어 모델을 비교할 때는 정량적으로 양이 많고, 또한 도메인에 알맞은 동일한 테스트 데이터를 사용해야 신뢰도가 높다\n",
    "\n",
    "\n",
    "\n",
    "## 3. 기존 언어 모델 Vs. 인공 신경망을 이용한 언어 모델.\n",
    "\n",
    "링크 : https://engineering.fb.com/2016/10/25/ml-applications/building-an-efficient-neural-language-model-over-a-billion-words/\n",
    "\n",
    "표에서 맨 위의 줄의 언어 모델이 n-gram을 이용한 언어 모델이며 PPL이 67.6으로 측정되었습니다. 5-gram을 사용하였으며, 5-gram 앞에 Interpolated Kneser-Ney라는 이름이 붙었는데 이 책에서는 별도 설명을 생략하겠다고 했던 일반화(generalization) 방법이 사용된 모델입니다. 반면, 그 아래의 모델들은 인공 신경망을 이용한 언어 모델들로 페이스북 AI 연구팀이 자신들의 언어 모델을 다른 언어 모델과 비교하고자 하는 목적으로 기록하였습니다. 아직 RNN과 LSTM 등이 무엇인지 배우지는 않았지만, 인공 신경망을 이용한 언어 모델들은 대부분 n-gram을 이용한 언어 모델보다 더 좋은 성능 평가를 받았음을 확인할 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8372ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee37717a",
   "metadata": {},
   "source": [
    "![PPL test](image/ppl_test.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8700fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4296ea90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
