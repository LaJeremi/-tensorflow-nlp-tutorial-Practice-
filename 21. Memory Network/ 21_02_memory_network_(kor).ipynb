{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1j0wZIrsoxf3QU1BCD0jvcOo6Dky6x0GF",
      "authorship_tag": "ABX9TyPgwyp1KLVj5P/bgpEw6GcT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaJeremi/Tensorflow-nlp-tutorial-Practice-/blob/main/21.%20Memory%20Network/%2021_02_memory_network_(kor).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 21-02 MemN으로 한국어 QA 해보기\n",
        "\n",
        "출처: https://wikidocs.net/85470\n",
        "\n",
        "# 1. 커스터마이즈드 KoNLPy 사용하기\n",
        "\n",
        "# 2. 한국어 Babi 데이터셋 로드와 전처리\n"
      ],
      "metadata": {
        "id": "AOUWhuQiVFzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "GnD1nFvCWwJz",
        "outputId": "e25e9885-662a-4be1-f875-5f7560cd19e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.utils import get_file\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import tarfile\n",
        "from nltk import FreqDist\n",
        "from functools import reduce\n",
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "K2lugV6CWwxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "path = get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/'\n",
        "                'babi_tasks_1-20_v1-2.tar.gz')\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvA96zIoWw6I",
        "outputId": "95a17ab8-b8f1-47a7-d924-7c070a37af83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\n",
            "11745123/11745123 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tarfile.open(path) as tar:\n",
        " tar.extractall()\n",
        " tar.close()\n",
        "\n",
        "DATA_DIR = 'tasks_1-20_v1-2/en-10k'\n",
        "TRAIN_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_train.txt\")\n",
        "TEST_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_test.txt\")"
      ],
      "metadata": {
        "id": "LTTi5RfVWw9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "lines = open(TRAIN_FILE , \"rb\")\n",
        "for line in lines:\n",
        "    line = line.decode(\"utf-8\").strip()\n",
        "    # lno, text = line.split(\" \", 1) # ID와 TEXT 분리\n",
        "    i = i + 1\n",
        "    print(line)\n",
        "    if i == 20:\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42rM8-bDWxAC",
        "outputId": "b56fcb00-8cbd-417e-86fe-bc6cf3b0e030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Mary moved to the bathroom.\n",
            "2 John went to the hallway.\n",
            "3 Where is Mary? \tbathroom\t1\n",
            "4 Daniel went back to the hallway.\n",
            "5 Sandra moved to the garden.\n",
            "6 Where is Daniel? \thallway\t4\n",
            "7 John moved to the office.\n",
            "8 Sandra journeyed to the bathroom.\n",
            "9 Where is Daniel? \thallway\t4\n",
            "10 Mary moved to the hallway.\n",
            "11 Daniel travelled to the office.\n",
            "12 Where is Daniel? \toffice\t11\n",
            "13 John went back to the garden.\n",
            "14 John moved to the bedroom.\n",
            "15 Where is Sandra? \tbathroom\t8\n",
            "1 Sandra travelled to the office.\n",
            "2 Sandra went to the bathroom.\n",
            "3 Where is Sandra? \tbathroom\t2\n",
            "4 Mary went to the bedroom.\n",
            "5 Daniel moved to the hallway.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def read_data(dir):\n",
        "    stories, questions, answers = [], [], [] # 각각 스토리, 질문, 답변을 저장할 예정\n",
        "    story_temp = [] # 현재 시점의 스토리 임시 저장\n",
        "    lines = open(dir, \"rb\")\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.decode(\"utf-8\") # b' 제거\n",
        "        line = line.strip() # '\\n' 제거\n",
        "        idx, text = line.split(\" \", 1) # 맨 앞에 있는 id number 분리\n",
        "        # 여기까지는 모든 줄에 적용되는 전처리\n",
        "\n",
        "        if int(idx) == 1:\n",
        "            story_temp = []\n",
        "\n",
        "        if \"\\t\" in text: # 현재 읽는 줄이 질문 (tab) 답변 (tab)인 경우\n",
        "            question, answer, _ = text.split(\"\\t\") # 질문과 답변을 각각 저장\n",
        "            stories.append([x for x in story_temp if x]) # 지금까지의 누적 스토리를 스토리에 저장\n",
        "            questions.append(question)\n",
        "            answers.append(answer)\n",
        "\n",
        "        else: # 현재 읽는 줄이 스토리인 경우\n",
        "            story_temp.append(text) # 임시 저장\n",
        "\n",
        "    lines.close()\n",
        "    return stories, questions, answers"
      ],
      "metadata": {
        "id": "8b7S8cQ6WxCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data = read_data(TRAIN_FILE)\n",
        "test_data = read_data(TEST_FILE)"
      ],
      "metadata": {
        "id": "9335IHkZWxFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_stories, train_questions, train_answers = read_data(TRAIN_FILE)\n",
        "test_stories, test_questions, test_answers = read_data(TEST_FILE)"
      ],
      "metadata": {
        "id": "kWjT9Ij4WxIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련용 스토리의 개수 :', len(train_stories))\n",
        "print('훈련용 질문의 개수 :',len(train_questions))\n",
        "print('훈련용 답변의 개수 :',len(train_answers))\n",
        "print('테스트용 스토리의 개수 :',len(test_stories))\n",
        "print('테스트용 질문의 개수 :',len(test_questions))\n",
        "print('테스트용 답변의 개수 :',len(test_answers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rj93OfmQWxLc",
        "outputId": "eaf5417f-6740-44f2-d13d-75c22dd6d4c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련용 스토리의 개수 : 10000\n",
            "훈련용 질문의 개수 : 10000\n",
            "훈련용 답변의 개수 : 10000\n",
            "테스트용 스토리의 개수 : 1000\n",
            "테스트용 질문의 개수 : 1000\n",
            "테스트용 답변의 개수 : 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_stories[3576]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8wZPQ_QWxOU",
        "outputId": "4f3e47f8-4cc9-4a11-8ebc-d7617d9281c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John went back to the garden.',\n",
              " 'Mary went to the kitchen.',\n",
              " 'Sandra went back to the bedroom.',\n",
              " 'John travelled to the bedroom.']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_questions[3576]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-4DHwnW5WxRL",
        "outputId": "bf0084f2-242b-4980-96af-21388d178828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Where is John? '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_answers[3576]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zxuSWcLqWxT9",
        "outputId": "ba6ab4f1-b604-47fc-dda2-beabc3936d5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bedroom'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sent):\n",
        "    return [ x.strip() for x in re.split('(\\W+)', sent) if x and x.strip()]"
      ],
      "metadata": {
        "id": "X0V5VOb3WxW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess_data(train_data, test_data):\n",
        "    counter = FreqDist()\n",
        "\n",
        "    # 두 문장의 story를 하나의 문장으로 통합하는 함수\n",
        "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
        "\n",
        "    # 각 샘플의 길이를 저장하는 리스트\n",
        "    story_len = []\n",
        "    question_len = []\n",
        "\n",
        "    for stories, questions, answers in [train_data, test_data]:\n",
        "        for story in stories:\n",
        "            stories = tokenize(flatten(story)) # 스토리의 문장들을 펼친 후 토큰화\n",
        "            story_len.append(len(stories)) # 각 story의 길이 저장\n",
        "            for word in stories: # 단어 집합에 단어 추가\n",
        "                counter[word] += 1\n",
        "        for question in questions:\n",
        "            question = tokenize(question)\n",
        "            question_len.append(len(question))\n",
        "            for word in question:\n",
        "                counter[word] += 1\n",
        "        for answer in answers:\n",
        "            answer = tokenize(answer)\n",
        "            for word in answer:\n",
        "                counter[word] += 1\n",
        "\n",
        "    # 단어 집합 생성\n",
        "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
        "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
        "\n",
        "    # 가장 긴 샘플의 길이\n",
        "    story_max_len = np.max(story_len)\n",
        "    question_max_len = np.max(question_len)\n",
        "\n",
        "    return word2idx, idx2word, story_max_len, question_max_len"
      ],
      "metadata": {
        "id": "lw0t52HFWxZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)\n"
      ],
      "metadata": {
        "id": "d1i_6FE9Wxcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E-x4g3EYWxfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nkP5hW0NWxiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p9LPfHidWxlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jlgD1DhxWxoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ciaMsZ81Wxqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_fMBRE1ryxBZ",
        "outputId": "d087e75e-f0c2-4593-f815-9ad4d54ac153"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install customized_konlpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGHE_sFGy8oz",
        "outputId": "247dc080-51de-496c-a3f9-70ced97b8a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: customized_konlpy in /usr/local/lib/python3.8/dist-packages (0.0.64)\n",
            "Requirement already satisfied: konlpy>=0.4.4 in /usr/local/lib/python3.8/dist-packages (from customized_konlpy) (0.6.0)\n",
            "Requirement already satisfied: Jpype1>=0.6.1 in /usr/local/lib/python3.8/dist-packages (from customized_konlpy) (1.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from Jpype1>=0.6.1->customized_konlpy) (23.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from konlpy>=0.4.4->customized_konlpy) (4.9.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from konlpy>=0.4.4->customized_konlpy) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ckonlpy.tag import Twitter\n"
      ],
      "metadata": {
        "id": "w_noYB7vzBR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "twitter = Twitter()\n",
        "twitter.morphs('은경이는 사무실로 갔습니다.')\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-Rr8sqmzCSp",
        "outputId": "575b0a73-0344-42bb-c851-0ec7f8443cec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/konlpy/tag/_okt.py:17: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
            "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['은', '경이', '는', '사무실', '로', '갔습니다', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "twitter.add_dictionary('은경이', 'Noun')\n",
        "twitter.morphs('은경이는 사무실로 갔습니다.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hymlax3yzKV5",
        "outputId": "acf945b7-f7f6-4db3-c851-8a708c032664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['은경이', '는', '사무실', '로', '갔습니다', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from ckonlpy.tag import Twitter\n",
        "from tensorflow.keras.utils import get_file\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import tarfile\n",
        "from nltk import FreqDist\n",
        "from functools import reduce\n",
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "BfMUCYBszLHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "F2Jrxmmazua4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "TRAIN_FILE = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/qa1_single-supporting-fact_train_kor.txt\")\n",
        "TEST_FILE = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/qa1_single-supporting-fact_test_kor.txt\")"
      ],
      "metadata": {
        "id": "FYVog8BSzMjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 새 섹션"
      ],
      "metadata": {
        "id": "U5jTOc6DV8uW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# TRAIN_FILE = os.path.join(\"qa1_single-supporting-fact_train_kor.txt\")\n",
        "# TEST_FILE = os.path.join(\"qa1_single-supporting-fact_test_kor.txt\")"
      ],
      "metadata": {
        "id": "2RTmX__u3dVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "lines = open(TRAIN_FILE , \"rb\")\n",
        "for line in lines:\n",
        "    line = line.decode(\"utf-8\").strip()\n",
        "    i = i + 1\n",
        "    print(line)\n",
        "    if i == 20:\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qggW7lUjzNcg",
        "outputId": "9349c813-a19d-4dc2-fbb4-201740086d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 필웅이는 화장실로 갔습니다.\n",
            "2 은경이는 복도로 이동했습니다.\n",
            "3 필웅이는 어디야? \t화장실\t1\n",
            "4 수종이는 복도로 복귀했습니다.\n",
            "5 경임이는 정원으로 갔습니다.\n",
            "6 수종이는 어디야? \t복도\t4\n",
            "7 은경이는 사무실로 갔습니다.\n",
            "8 경임이는 화장실로 뛰어갔습니다.\n",
            "9 수종이는 어디야? \t복도\t4\n",
            "10 필웅이는 복도로 갔습니다.\n",
            "11 수종이는 사무실로 가버렸습니다.\n",
            "12 수종이는 어디야? \t사무실\t11\n",
            "13 은경이는 정원으로 복귀했습니다.\n",
            "14 은경이는 침실로 갔습니다.\n",
            "15 경임이는 어디야? \t화장실\t8\n",
            "1 경임이는 사무실로 가버렸습니다.\n",
            "2 경임이는 화장실로 이동했습니다.\n",
            "3 경임이는 어디야? \t화장실\t2\n",
            "4 필웅이는 침실로 이동했습니다.\n",
            "5 수종이는 복도로 갔습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(dir):\n",
        "    stories, questions, answers = [], [], [] # 각각 스토리, 질문, 답변을 저장할 예정\n",
        "    story_temp = [] # 현재 시점의 스토리 임시 저장\n",
        "    lines = open(dir, \"rb\")\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.decode(\"utf-8\") # b' 제거\n",
        "        line = line.strip() # '\\n' 제거\n",
        "        idx, text = line.split(\" \", 1) # 맨 앞에 있는 id number 분리\n",
        "        # 여기까지는 모든 줄에 적용되는 전처리\n",
        "\n",
        "        if int(idx) == 1:\n",
        "            story_temp = []\n",
        "\n",
        "        if \"\\t\" in text: # 현재 읽는 줄이 질문 (tab) 답변 (tab)인 경우\n",
        "            question, answer, _ = text.split(\"\\t\") # 질문과 답변을 각각 저장\n",
        "            stories.append([x for x in story_temp if x]) # 지금까지의 누적 스토리를 스토리에 저장\n",
        "            questions.append(question)\n",
        "            answers.append(answer)\n",
        "\n",
        "        else: # 현재 읽는 줄이 스토리인 경우\n",
        "            story_temp.append(text) # 임시 저장\n",
        "\n",
        "    lines.close()\n",
        "    return stories, questions, answers"
      ],
      "metadata": {
        "id": "KGjkL1e4zOgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data = read_data(TRAIN_FILE)\n",
        "test_data = read_data(TEST_FILE)"
      ],
      "metadata": {
        "id": "hMukVt3e0CmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_stories, train_questions, train_answers = read_data(TRAIN_FILE)\n",
        "test_stories, test_questions, test_answers = read_data(TEST_FILE)"
      ],
      "metadata": {
        "id": "fYCkZY0W0ESg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련용 스토리의 개수 :', len(train_stories))\n",
        "print('훈련용 질문의 개수 :',len(train_questions))\n",
        "print('훈련용 답변의 개수 :',len(train_answers))\n",
        "print('테스트용 스토리의 개수 :',len(test_stories))\n",
        "print('테스트용 질문의 개수 :',len(test_questions))\n",
        "print('테스트용 답변의 개수 :',len(test_answers))\n",
        "     "
      ],
      "metadata": {
        "id": "YqFAUXod0FCo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b8ba6de-7e02-4d99-e401-7a1ffaace0a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련용 스토리의 개수 : 10000\n",
            "훈련용 질문의 개수 : 10000\n",
            "훈련용 답변의 개수 : 10000\n",
            "테스트용 스토리의 개수 : 1000\n",
            "테스트용 질문의 개수 : 1000\n",
            "테스트용 답변의 개수 : 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_stories[3572]\n"
      ],
      "metadata": {
        "id": "ad3TC0Fa0F7g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7ced689-ee71-4a23-a2a9-c3eb5acfdea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['은경이는 부엌으로 가버렸습니다.',\n",
              " '필웅이는 사무실로 가버렸습니다.',\n",
              " '수종이는 복도로 뛰어갔습니다.',\n",
              " '은경이는 사무실로 복귀했습니다.',\n",
              " '경임이는 사무실로 이동했습니다.',\n",
              " '경임이는 침실로 갔습니다.']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_questions[3572]\n"
      ],
      "metadata": {
        "id": "317rmHFl0Gvg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0f132675-6063-4d4d-9045-9cc36f42fbdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'은경이는 어디야? '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_answers[3572]\n"
      ],
      "metadata": {
        "id": "DvC5NDUi0H6g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a14653ae-2f93-41b6-b97a-4d9bfb89c530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'사무실'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def tokenize(sent):\n",
        "  return [ x.strip() for x in re.split('(\\W+)', sent) if x and x.strip()]"
      ],
      "metadata": {
        "id": "CC8IGbpp0Iug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(train_data, test_data):\n",
        "    counter = FreqDist()\n",
        "\n",
        "    # 두 문장의 story를 하나의 문장으로 통합하는 함수\n",
        "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
        "\n",
        "    # 각 샘플의 길이를 저장하는 리스트\n",
        "    story_len = []\n",
        "    question_len = []\n",
        "\n",
        "    for stories, questions, answers in [train_data, test_data]:\n",
        "        for story in stories:\n",
        "            stories = tokenize(flatten(story)) # 스토리의 문장들을 펼친 후 토큰화\n",
        "            story_len.append(len(stories)) # 각 story의 길이 저장\n",
        "            for word in stories: # 단어 집합에 단어 추가\n",
        "                counter[word] += 1\n",
        "        for question in questions:\n",
        "            question = tokenize(question)\n",
        "            question_len.append(len(question))\n",
        "            for word in question:\n",
        "                counter[word] += 1\n",
        "        for answer in answers:\n",
        "            answer = tokenize(answer)\n",
        "            for word in answer:\n",
        "                counter[word] += 1\n",
        "\n",
        "    # 단어 집합 생성\n",
        "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
        "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
        "\n",
        "    # 가장 긴 샘플의 길이\n",
        "    story_max_len = np.max(story_len)\n",
        "    question_max_len = np.max(question_len)\n",
        "\n",
        "    return word2idx, idx2word, story_max_len, question_max_len"
      ],
      "metadata": {
        "id": "JNjR9wFx0-xT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)\n"
      ],
      "metadata": {
        "id": "LY5HfQot1Zie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word2idx)\n"
      ],
      "metadata": {
        "id": "9L79T2Ej1AgI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b375f0e-8e9d-4319-c7c4-158ad03dd060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'.': 1, '경임이는': 2, '은경이는': 3, '수종이는': 4, '필웅이는': 5, '이동했습니다': 6, '가버렸습니다': 7, '뛰어갔습니다': 8, '복귀했습니다': 9, '갔습니다': 10, '화장실로': 11, '정원으로': 12, '복도로': 13, '어디야': 14, '?': 15, '부엌으로': 16, '사무실로': 17, '침실로': 18, '화장실': 19, '정원': 20, '사무실': 21, '침실': 22, '복도': 23, '부엌': 24}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(word2idx) + 1\n"
      ],
      "metadata": {
        "id": "UG8cUEdW1CcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('스토리의 최대 길이 :',story_max_len)\n",
        "print('질문의 최대 길이 :',question_max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJud-l5HZ49v",
        "outputId": "de475f26-bdcf-489f-8320-4acaddfe8633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "스토리의 최대 길이 : 40\n",
            "질문의 최대 길이 : 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
        "    Xs, Xq, Y = [], [], []\n",
        "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
        "\n",
        "    stories, questions, answers = data\n",
        "    for story, question, answer in zip(stories, questions, answers):\n",
        "        xs = [word2idx[w] for w in tokenize(flatten(story))]\n",
        "        xq = [word2idx[w] for w in tokenize(question)]\n",
        "        Xs.append(xs)\n",
        "        Xq.append(xq)\n",
        "        Y.append(word2idx[answer])\n",
        "\n",
        "        # 스토리와 질문은 각각의 최대 길이로 패딩\n",
        "        # 정답은 원-핫 인코딩\n",
        "    return pad_sequences(Xs, maxlen=story_maxlen),\\\n",
        "           pad_sequences(Xq, maxlen=question_maxlen),\\\n",
        "           to_categorical(Y, num_classes=len(word2idx) + 1)"
      ],
      "metadata": {
        "id": "2QLrEubnZ54Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xstrain, Xqtrain, Ytrain = vectorize(train_data, word2idx, story_max_len, question_max_len)\n",
        "Xstest, Xqtest, Ytest = vectorize(test_data, word2idx, story_max_len, question_max_len)"
      ],
      "metadata": {
        "id": "E-fxihyEZ7I5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Xstrain.shape, Xqtrain.shape, Ytrain.shape, Xstest.shape, Xqtest.shape, Ytest.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3k3tY86Z8aw",
        "outputId": "e6145ff1-0bc4-466e-a971-f90c747284e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 40) (10000, 3) (10000, 25) (1000, 40) (1000, 3) (1000, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 메모리 네트워크로 QA 태스크 풀기\n"
      ],
      "metadata": {
        "id": "GLgEe9RmVqIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xstrain[3576]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xGEADScZ9No",
        "outputId": "804c375a-a373-4c8e-cef1-fd035481757e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  3, 12,  9,  1,  5, 16,  6,  1,  2, 18,\n",
              "        9,  1,  3, 18,  7,  1], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xqtrain[3576]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGTRO4v9Z-Bo",
        "outputId": "c059fcc8-68ab-4149-e5d4-42ff36d2c81e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3, 14, 15], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ytrain[3576]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtd9S1F9Z_G5",
        "outputId": "043a0af2-5f33-4d84-f346-f916796930f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Permute, dot, add, concatenate\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Activation"
      ],
      "metadata": {
        "id": "XlP86oiiaAQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 에포크 횟수\n",
        "train_epochs = 120\n",
        "# 배치 크기\n",
        "batch_size = 32\n",
        "# 임베딩 크기\n",
        "embed_size = 50\n",
        "# LSTM의 크기\n",
        "lstm_size = 64\n",
        "# 과적합 방지 기법인 드롭아웃 적용 비율\n",
        "dropout_rate = 0.30"
      ],
      "metadata": {
        "id": "ds1lxv5Bal8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 플레이스 홀더. 입력을 담는 변수\n",
        "input_sequence = Input((story_max_len,))\n",
        "question = Input((question_max_len,))\n",
        "\n",
        "print('Stories :', input_sequence)\n",
        "print('Question:', question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcNwgaAFamxA",
        "outputId": "fd7f8293-f9c8-4f26-9aea-866aabf92447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stories : KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
            "Question: KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 스토리를 위한 첫번째 임베딩. 그림에서의 Embedding A\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
        "                              output_dim=embed_size))\n",
        "input_encoder_m.add(Dropout(dropout_rate))\n",
        "# 결과 : (samples, story_max_len, embedding_dim) / 샘플의 수, 문장의 최대 길이, 임베딩 벡터의 차원\n",
        "\n",
        "# 스토리를 위한 두번째 임베딩. 그림에서의 Embedding C\n",
        "# 임베딩 벡터의 차원을 question_max_len(질문의 최대 길이)로 한다.\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
        "                              output_dim=question_max_len))\n",
        "input_encoder_c.add(Dropout(dropout_rate))\n",
        "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이(임베딩 벡터의 차원)"
      ],
      "metadata": {
        "id": "zdpXIE39an3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 질문을 위한 임베딩. 그림에서의 Embedding B\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=embed_size,\n",
        "                               input_length=question_max_len))\n",
        "question_encoder.add(Dropout(dropout_rate))\n",
        "# 결과 : (samples, question_max_len, embedding_dim) / 샘플의 수, 질문의 최대 길이, 임베딩 벡터의 차원"
      ],
      "metadata": {
        "id": "iDZqB8cFapHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 실질적인 임베딩 과정\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)\n",
        "\n",
        "print('Input encoded m', input_encoded_m)\n",
        "print('Input encoded c', input_encoded_c)\n",
        "print('Question encoded', question_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaQhzC38aqLR",
        "outputId": "21133f6d-e010-4b2c-cd22-13af96d917d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input encoded m KerasTensor(type_spec=TensorSpec(shape=(None, 40, 50), dtype=tf.float32, name=None), name='sequential/dropout/Identity:0', description=\"created by layer 'sequential'\")\n",
            "Input encoded c KerasTensor(type_spec=TensorSpec(shape=(None, 40, 3), dtype=tf.float32, name=None), name='sequential_1/dropout_1/Identity:0', description=\"created by layer 'sequential_1'\")\n",
            "Question encoded KerasTensor(type_spec=TensorSpec(shape=(None, 3, 50), dtype=tf.float32, name=None), name='sequential_2/dropout_2/Identity:0', description=\"created by layer 'sequential_2'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 스토리 단어들과 질문 단어들 간의 유사도를 구하는 과정\n",
        "# 유사도는 내적을 사용한다.\n",
        "match = dot([input_encoded_m, question_encoded], axes=-1, normalize=False)\n",
        "match = Activation('softmax')(match)\n",
        "print('Match shape', match)\n",
        "# 결과 : (samples, story_maxlen, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGp6rfnSarMA",
        "outputId": "edace756-b158-4fb5-b60a-7dc1d8485dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Match shape KerasTensor(type_spec=TensorSpec(shape=(None, 40, 3), dtype=tf.float32, name=None), name='activation/Softmax:0', description=\"created by layer 'activation'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 유사도가 반영된 어텐션 분포 행렬과 임베딩 C를 거친 스토리 행렬을 더한다.\n",
        "# 두 행렬 모두 크기는 (68, 4)이다.\n",
        "# 이로부터 얻은 행렬은 어텐션 값 행렬(Attention Value Matrix)이다.\n",
        "response = add([match, input_encoded_c])"
      ],
      "metadata": {
        "id": "QBN_VxEqau1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 질문 행렬은 (4, 50)의 크기를 가진다.\n",
        "# 하지만 어텐션 값 행렬의 크기는 (68, 4)이다.\n",
        "# 이 두 개를 연결시켜주기 위해서 어텐션 값 행렬의 크기를 (4, 68)로 변환해준다.\n",
        "response = Permute((2, 1))(response)  # (samples, question_max_len, story_max_len)\n",
        "print('Response shape', response)\n",
        "\n",
        "# 질문 행렬과 어텐션 값 행렬을 연결한다.\n",
        "# (4, 118)의 크기를 가진다.\n",
        "answer = concatenate([response, question_encoded])\n",
        "print('Answer shape', answer)\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4B_T5vWav1Y",
        "outputId": "3c0fae78-f984-42b3-bd11-253ab4d24878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response shape KerasTensor(type_spec=TensorSpec(shape=(None, 3, 40), dtype=tf.float32, name=None), name='permute/transpose:0', description=\"created by layer 'permute'\")\n",
            "Answer shape KerasTensor(type_spec=TensorSpec(shape=(None, 3, 90), dtype=tf.float32, name=None), name='concatenate/concat:0', description=\"created by layer 'concatenate'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "answer = LSTM(lstm_size)(answer)\n",
        "answer = Dropout(dropout_rate)(answer)\n",
        "answer = Dense(vocab_size)(answer)\n",
        "answer = Activation('softmax')(answer)"
      ],
      "metadata": {
        "id": "fR8SCBsjawwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# start training the model\n",
        "history = model.fit([Xstrain, Xqtrain],\n",
        "         Ytrain, batch_size, train_epochs,\n",
        "         validation_data=([Xstest, Xqtest], Ytest))\n",
        "\n",
        "# save model\n",
        "model.save('model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DspwH9t4axng",
        "outputId": "9df1dbc4-8ac2-4aca-d471-b6581e33b00c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 40)]         0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 3)]          0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, None, 50)     1250        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " sequential_2 (Sequential)      (None, 3, 50)        1250        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 40, 3)        0           ['sequential[0][0]',             \n",
            "                                                                  'sequential_2[0][0]']           \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 40, 3)        0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, None, 3)      75          ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 40, 3)        0           ['activation[0][0]',             \n",
            "                                                                  'sequential_1[0][0]']           \n",
            "                                                                                                  \n",
            " permute (Permute)              (None, 3, 40)        0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 3, 90)        0           ['permute[0][0]',                \n",
            "                                                                  'sequential_2[0][0]']           \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 64)           39680       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 64)           0           ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 25)           1625        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 25)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 43,880\n",
            "Trainable params: 43,880\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/120\n",
            "313/313 [==============================] - 15s 18ms/step - loss: 1.9024 - acc: 0.1685 - val_loss: 1.7768 - val_acc: 0.2400\n",
            "Epoch 2/120\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 1.7017 - acc: 0.2535 - val_loss: 1.5987 - val_acc: 0.3750\n",
            "Epoch 3/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 1.5515 - acc: 0.3629 - val_loss: 1.5095 - val_acc: 0.3690\n",
            "Epoch 4/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.5049 - acc: 0.3792 - val_loss: 1.4792 - val_acc: 0.3940\n",
            "Epoch 5/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.4885 - acc: 0.3962 - val_loss: 1.4889 - val_acc: 0.3850\n",
            "Epoch 6/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.4817 - acc: 0.4074 - val_loss: 1.4510 - val_acc: 0.4200\n",
            "Epoch 7/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.4559 - acc: 0.4254 - val_loss: 1.4076 - val_acc: 0.4540\n",
            "Epoch 8/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.4006 - acc: 0.4635 - val_loss: 1.3355 - val_acc: 0.5030\n",
            "Epoch 9/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.3626 - acc: 0.4761 - val_loss: 1.2966 - val_acc: 0.5090\n",
            "Epoch 10/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.3266 - acc: 0.4912 - val_loss: 1.2808 - val_acc: 0.5090\n",
            "Epoch 11/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.3069 - acc: 0.4980 - val_loss: 1.2743 - val_acc: 0.4960\n",
            "Epoch 12/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.2910 - acc: 0.4982 - val_loss: 1.2582 - val_acc: 0.5130\n",
            "Epoch 13/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.2799 - acc: 0.5023 - val_loss: 1.2302 - val_acc: 0.5260\n",
            "Epoch 14/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.2632 - acc: 0.5059 - val_loss: 1.2445 - val_acc: 0.5050\n",
            "Epoch 15/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.2588 - acc: 0.5089 - val_loss: 1.2213 - val_acc: 0.5200\n",
            "Epoch 16/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.2436 - acc: 0.5156 - val_loss: 1.2046 - val_acc: 0.5230\n",
            "Epoch 17/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.2340 - acc: 0.5150 - val_loss: 1.2048 - val_acc: 0.5270\n",
            "Epoch 18/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 1.2367 - acc: 0.5124 - val_loss: 1.2121 - val_acc: 0.5090\n",
            "Epoch 19/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.2171 - acc: 0.5142 - val_loss: 1.2042 - val_acc: 0.5080\n",
            "Epoch 20/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.2104 - acc: 0.5168 - val_loss: 1.1923 - val_acc: 0.5160\n",
            "Epoch 21/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.1989 - acc: 0.5224 - val_loss: 1.1893 - val_acc: 0.5320\n",
            "Epoch 22/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.1944 - acc: 0.5267 - val_loss: 1.1776 - val_acc: 0.5450\n",
            "Epoch 23/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1753 - acc: 0.5340 - val_loss: 1.1675 - val_acc: 0.5470\n",
            "Epoch 24/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.1448 - acc: 0.5610 - val_loss: 1.1070 - val_acc: 0.5920\n",
            "Epoch 25/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.0920 - acc: 0.5922 - val_loss: 1.0290 - val_acc: 0.6530\n",
            "Epoch 26/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.0043 - acc: 0.6361 - val_loss: 0.9226 - val_acc: 0.6910\n",
            "Epoch 27/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.9217 - acc: 0.6769 - val_loss: 0.8352 - val_acc: 0.7260\n",
            "Epoch 28/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.8400 - acc: 0.7083 - val_loss: 0.7719 - val_acc: 0.7380\n",
            "Epoch 29/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.7716 - acc: 0.7312 - val_loss: 0.7467 - val_acc: 0.7400\n",
            "Epoch 30/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.7254 - acc: 0.7506 - val_loss: 0.6744 - val_acc: 0.7620\n",
            "Epoch 31/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6731 - acc: 0.7614 - val_loss: 0.6533 - val_acc: 0.7710\n",
            "Epoch 32/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6295 - acc: 0.7788 - val_loss: 0.6082 - val_acc: 0.7810\n",
            "Epoch 33/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.5817 - acc: 0.7949 - val_loss: 0.5895 - val_acc: 0.7840\n",
            "Epoch 34/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.5470 - acc: 0.8067 - val_loss: 0.5747 - val_acc: 0.7870\n",
            "Epoch 35/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.5191 - acc: 0.8148 - val_loss: 0.5306 - val_acc: 0.8120\n",
            "Epoch 36/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.4817 - acc: 0.8271 - val_loss: 0.5009 - val_acc: 0.8250\n",
            "Epoch 37/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.4535 - acc: 0.8390 - val_loss: 0.4867 - val_acc: 0.8340\n",
            "Epoch 38/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.4273 - acc: 0.8436 - val_loss: 0.4677 - val_acc: 0.8350\n",
            "Epoch 39/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.4069 - acc: 0.8565 - val_loss: 0.4395 - val_acc: 0.8350\n",
            "Epoch 40/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3941 - acc: 0.8545 - val_loss: 0.4294 - val_acc: 0.8490\n",
            "Epoch 41/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3725 - acc: 0.8616 - val_loss: 0.4379 - val_acc: 0.8460\n",
            "Epoch 42/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3617 - acc: 0.8681 - val_loss: 0.3936 - val_acc: 0.8570\n",
            "Epoch 43/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3534 - acc: 0.8657 - val_loss: 0.4099 - val_acc: 0.8460\n",
            "Epoch 44/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3431 - acc: 0.8726 - val_loss: 0.3896 - val_acc: 0.8600\n",
            "Epoch 45/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3329 - acc: 0.8741 - val_loss: 0.3892 - val_acc: 0.8580\n",
            "Epoch 46/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3235 - acc: 0.8802 - val_loss: 0.3743 - val_acc: 0.8670\n",
            "Epoch 47/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3230 - acc: 0.8810 - val_loss: 0.3653 - val_acc: 0.8630\n",
            "Epoch 48/120\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.3111 - acc: 0.8838 - val_loss: 0.3801 - val_acc: 0.8620\n",
            "Epoch 49/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3048 - acc: 0.8840 - val_loss: 0.3695 - val_acc: 0.8690\n",
            "Epoch 50/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2984 - acc: 0.8892 - val_loss: 0.3558 - val_acc: 0.8700\n",
            "Epoch 51/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2925 - acc: 0.8921 - val_loss: 0.3599 - val_acc: 0.8690\n",
            "Epoch 52/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2903 - acc: 0.8909 - val_loss: 0.3600 - val_acc: 0.8690\n",
            "Epoch 53/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.2799 - acc: 0.8964 - val_loss: 0.3478 - val_acc: 0.8750\n",
            "Epoch 54/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2683 - acc: 0.9020 - val_loss: 0.3528 - val_acc: 0.8720\n",
            "Epoch 55/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2638 - acc: 0.9025 - val_loss: 0.3521 - val_acc: 0.8820\n",
            "Epoch 56/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2529 - acc: 0.9083 - val_loss: 0.3427 - val_acc: 0.8830\n",
            "Epoch 57/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2496 - acc: 0.9084 - val_loss: 0.3377 - val_acc: 0.8840\n",
            "Epoch 58/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2418 - acc: 0.9114 - val_loss: 0.3222 - val_acc: 0.8920\n",
            "Epoch 59/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2334 - acc: 0.9150 - val_loss: 0.3269 - val_acc: 0.8880\n",
            "Epoch 60/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2293 - acc: 0.9175 - val_loss: 0.3079 - val_acc: 0.8990\n",
            "Epoch 61/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2203 - acc: 0.9197 - val_loss: 0.3280 - val_acc: 0.8920\n",
            "Epoch 62/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2225 - acc: 0.9203 - val_loss: 0.3131 - val_acc: 0.8950\n",
            "Epoch 63/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2047 - acc: 0.9255 - val_loss: 0.2972 - val_acc: 0.9030\n",
            "Epoch 64/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1989 - acc: 0.9291 - val_loss: 0.3002 - val_acc: 0.9040\n",
            "Epoch 65/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1946 - acc: 0.9317 - val_loss: 0.2901 - val_acc: 0.9110\n",
            "Epoch 66/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1895 - acc: 0.9365 - val_loss: 0.2801 - val_acc: 0.9120\n",
            "Epoch 67/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1796 - acc: 0.9384 - val_loss: 0.2862 - val_acc: 0.9110\n",
            "Epoch 68/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1807 - acc: 0.9350 - val_loss: 0.2688 - val_acc: 0.9150\n",
            "Epoch 69/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1713 - acc: 0.9415 - val_loss: 0.2726 - val_acc: 0.9130\n",
            "Epoch 70/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1586 - acc: 0.9421 - val_loss: 0.2607 - val_acc: 0.9140\n",
            "Epoch 71/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1632 - acc: 0.9433 - val_loss: 0.2552 - val_acc: 0.9220\n",
            "Epoch 72/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1462 - acc: 0.9502 - val_loss: 0.2508 - val_acc: 0.9230\n",
            "Epoch 73/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.1525 - acc: 0.9465 - val_loss: 0.2589 - val_acc: 0.9190\n",
            "Epoch 74/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1382 - acc: 0.9508 - val_loss: 0.2415 - val_acc: 0.9260\n",
            "Epoch 75/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1371 - acc: 0.9541 - val_loss: 0.2477 - val_acc: 0.9250\n",
            "Epoch 76/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1338 - acc: 0.9541 - val_loss: 0.2483 - val_acc: 0.9170\n",
            "Epoch 77/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1321 - acc: 0.9540 - val_loss: 0.2351 - val_acc: 0.9290\n",
            "Epoch 78/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1191 - acc: 0.9577 - val_loss: 0.2497 - val_acc: 0.9290\n",
            "Epoch 79/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.1213 - acc: 0.9589 - val_loss: 0.2280 - val_acc: 0.9270\n",
            "Epoch 80/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1153 - acc: 0.9621 - val_loss: 0.2165 - val_acc: 0.9330\n",
            "Epoch 81/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1176 - acc: 0.9581 - val_loss: 0.2185 - val_acc: 0.9370\n",
            "Epoch 82/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1061 - acc: 0.9636 - val_loss: 0.2233 - val_acc: 0.9360\n",
            "Epoch 83/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1090 - acc: 0.9618 - val_loss: 0.2207 - val_acc: 0.9320\n",
            "Epoch 84/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1029 - acc: 0.9652 - val_loss: 0.2206 - val_acc: 0.9340\n",
            "Epoch 85/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.1084 - acc: 0.9639 - val_loss: 0.2208 - val_acc: 0.9320\n",
            "Epoch 86/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1030 - acc: 0.9643 - val_loss: 0.2190 - val_acc: 0.9320\n",
            "Epoch 87/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0935 - acc: 0.9721 - val_loss: 0.2326 - val_acc: 0.9330\n",
            "Epoch 88/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0965 - acc: 0.9677 - val_loss: 0.2313 - val_acc: 0.9370\n",
            "Epoch 89/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0968 - acc: 0.9674 - val_loss: 0.2185 - val_acc: 0.9410\n",
            "Epoch 90/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0884 - acc: 0.9688 - val_loss: 0.2243 - val_acc: 0.9340\n",
            "Epoch 91/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0911 - acc: 0.9679 - val_loss: 0.2261 - val_acc: 0.9380\n",
            "Epoch 92/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0781 - acc: 0.9744 - val_loss: 0.2359 - val_acc: 0.9360\n",
            "Epoch 93/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0891 - acc: 0.9684 - val_loss: 0.2219 - val_acc: 0.9310\n",
            "Epoch 94/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0835 - acc: 0.9728 - val_loss: 0.2146 - val_acc: 0.9400\n",
            "Epoch 95/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0790 - acc: 0.9734 - val_loss: 0.2328 - val_acc: 0.9360\n",
            "Epoch 96/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0719 - acc: 0.9767 - val_loss: 0.2028 - val_acc: 0.9400\n",
            "Epoch 97/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0752 - acc: 0.9753 - val_loss: 0.2165 - val_acc: 0.9350\n",
            "Epoch 98/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0733 - acc: 0.9759 - val_loss: 0.2441 - val_acc: 0.9280\n",
            "Epoch 99/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0667 - acc: 0.9775 - val_loss: 0.2153 - val_acc: 0.9410\n",
            "Epoch 100/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0645 - acc: 0.9794 - val_loss: 0.2099 - val_acc: 0.9420\n",
            "Epoch 101/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0635 - acc: 0.9791 - val_loss: 0.2087 - val_acc: 0.9410\n",
            "Epoch 102/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0663 - acc: 0.9775 - val_loss: 0.2150 - val_acc: 0.9370\n",
            "Epoch 103/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0577 - acc: 0.9800 - val_loss: 0.2316 - val_acc: 0.9400\n",
            "Epoch 104/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0668 - acc: 0.9765 - val_loss: 0.2098 - val_acc: 0.9370\n",
            "Epoch 105/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0624 - acc: 0.9783 - val_loss: 0.2122 - val_acc: 0.9410\n",
            "Epoch 106/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0679 - acc: 0.9784 - val_loss: 0.2278 - val_acc: 0.9390\n",
            "Epoch 107/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0580 - acc: 0.9803 - val_loss: 0.2107 - val_acc: 0.9380\n",
            "Epoch 108/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0584 - acc: 0.9795 - val_loss: 0.2108 - val_acc: 0.9460\n",
            "Epoch 109/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0556 - acc: 0.9815 - val_loss: 0.2202 - val_acc: 0.9390\n",
            "Epoch 110/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0511 - acc: 0.9852 - val_loss: 0.1982 - val_acc: 0.9460\n",
            "Epoch 111/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0543 - acc: 0.9819 - val_loss: 0.2377 - val_acc: 0.9420\n",
            "Epoch 112/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0551 - acc: 0.9816 - val_loss: 0.2183 - val_acc: 0.9420\n",
            "Epoch 113/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0519 - acc: 0.9828 - val_loss: 0.2061 - val_acc: 0.9540\n",
            "Epoch 114/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0478 - acc: 0.9835 - val_loss: 0.2137 - val_acc: 0.9490\n",
            "Epoch 115/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0493 - acc: 0.9844 - val_loss: 0.2159 - val_acc: 0.9420\n",
            "Epoch 116/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0477 - acc: 0.9859 - val_loss: 0.1998 - val_acc: 0.9460\n",
            "Epoch 117/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0510 - acc: 0.9837 - val_loss: 0.2070 - val_acc: 0.9430\n",
            "Epoch 118/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0473 - acc: 0.9847 - val_loss: 0.2125 - val_acc: 0.9490\n",
            "Epoch 119/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0446 - acc: 0.9864 - val_loss: 0.2019 - val_acc: 0.9480\n",
            "Epoch 120/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0423 - acc: 0.9855 - val_loss: 0.2049 - val_acc: 0.9460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate([Xstest, Xqtest], Ytest)[1]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-6Rep5layoH",
        "outputId": "640d95c0-64e8-46fd-fae4-36d0d5682c14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 5ms/step - loss: 0.2049 - acc: 0.9460\n",
            "\n",
            " 테스트 정확도: 0.9460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# plot accuracy and loss plot\n",
        "plt.subplot(211)\n",
        "plt.title(\"Accuracy\")\n",
        "plt.plot(history.history[\"acc\"], color=\"g\", label=\"train\")\n",
        "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
        "plt.legend(loc=\"best\")\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.title(\"Loss\")\n",
        "plt.plot(history.history[\"loss\"], color=\"g\", label=\"train\")\n",
        "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
        "plt.legend(loc=\"best\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# labels\n",
        "ytest = np.argmax(Ytest, axis=1)\n",
        "\n",
        "# get predictions\n",
        "Ytest_ = model.predict([Xstest, Xqtest])\n",
        "ytest_ = np.argmax(Ytest_, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "rmu16TVGa0jA",
        "outputId": "14aa7b2b-1c7d-4811-fe96-f5474071f198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 1s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "okbC9-3pa1lA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}