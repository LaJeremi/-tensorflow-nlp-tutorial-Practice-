{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDPhKOyn5ktAgS5opT4fTu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaJeremi/Tensorflow-nlp-tutorial-Practice-/blob/main/21.%20Memory%20Network/%2021_01_Memory_Network%2C_MemN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 21-01 메모리 네트워크(Memory Network, MemN)를 이용한 QA\n",
        "\n",
        "출처: https://wikidocs.net/82475\n",
        "\n",
        "## 1. Babi 데이터셋\n",
        "\n",
        "## 2. 메모리 네트워크 구조\n",
        "\n",
        "## 3. Babi 데이터셋 전처리하기\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MoHqO8c-Uu2j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mbSKiLvSw9rj",
        "outputId": "da2f177d-4870-420e-afd1-edc6729efdb1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.11.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.utils import get_file\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import tarfile\n",
        "from nltk import FreqDist\n",
        "from functools import reduce\n",
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "fpiB5fTkw_Q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "path = get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/'\n",
        "                'babi_tasks_1-20_v1-2.tar.gz')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydU-x2YwxPmp",
        "outputId": "dd97facb-4a41-4b51-be14-8b1da3e7b46a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\n",
            "11745123/11745123 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tarfile.open(path) as tar:\n",
        " tar.extractall()\n",
        " tar.close()\n",
        "\n",
        "DATA_DIR = 'tasks_1-20_v1-2/en-10k'\n",
        "TRAIN_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_train.txt\")\n",
        "TEST_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_test.txt\")"
      ],
      "metadata": {
        "id": "KGVkqYs8xQjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "i = 0\n",
        "lines = open(TRAIN_FILE , \"rb\")\n",
        "for line in lines:\n",
        "    line = line.decode(\"utf-8\").strip()\n",
        "    # lno, text = line.split(\" \", 1) # ID와 TEXT 분리\n",
        "    i = i + 1\n",
        "    print(line)\n",
        "    if i == 20:\n",
        "      break\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1g7cm51VxRpI",
        "outputId": "d522a982-f502-4c76-a5c7-36cbcf27ed84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Mary moved to the bathroom.\n",
            "2 John went to the hallway.\n",
            "3 Where is Mary? \tbathroom\t1\n",
            "4 Daniel went back to the hallway.\n",
            "5 Sandra moved to the garden.\n",
            "6 Where is Daniel? \thallway\t4\n",
            "7 John moved to the office.\n",
            "8 Sandra journeyed to the bathroom.\n",
            "9 Where is Daniel? \thallway\t4\n",
            "10 Mary moved to the hallway.\n",
            "11 Daniel travelled to the office.\n",
            "12 Where is Daniel? \toffice\t11\n",
            "13 John went back to the garden.\n",
            "14 John moved to the bedroom.\n",
            "15 Where is Sandra? \tbathroom\t8\n",
            "1 Sandra travelled to the office.\n",
            "2 Sandra went to the bathroom.\n",
            "3 Where is Sandra? \tbathroom\t2\n",
            "4 Mary went to the bedroom.\n",
            "5 Daniel moved to the hallway.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def read_data(dir):\n",
        "    stories, questions, answers = [], [], [] # 각각 스토리, 질문, 답변을 저장할 예정\n",
        "    story_temp = [] # 현재 시점의 스토리 임시 저장\n",
        "    lines = open(dir, \"rb\")\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.decode(\"utf-8\") # b' 제거\n",
        "        line = line.strip() # '\\n' 제거\n",
        "        idx, text = line.split(\" \", 1) # 맨 앞에 있는 id number 분리\n",
        "        # 여기까지는 모든 줄에 적용되는 전처리\n",
        "\n",
        "        if int(idx) == 1:\n",
        "            story_temp = []\n",
        "\n",
        "        if \"\\t\" in text: # 현재 읽는 줄이 질문 (tab) 답변 (tab)인 경우\n",
        "            question, answer, _ = text.split(\"\\t\") # 질문과 답변을 각각 저장\n",
        "            stories.append([x for x in story_temp if x]) # 지금까지의 누적 스토리를 스토리에 저장\n",
        "            questions.append(question)\n",
        "            answers.append(answer)\n",
        "\n",
        "        else: # 현재 읽는 줄이 스토리인 경우\n",
        "            story_temp.append(text) # 임시 저장\n",
        "\n",
        "    lines.close()\n",
        "    return stories, questions, answers"
      ],
      "metadata": {
        "id": "NWzy4rLZxSgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data = read_data(TRAIN_FILE)\n",
        "test_data = read_data(TEST_FILE)"
      ],
      "metadata": {
        "id": "sAXhBOibxT25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_stories, train_questions, train_answers = read_data(TRAIN_FILE)\n",
        "test_stories, test_questions, test_answers = read_data(TEST_FILE)"
      ],
      "metadata": {
        "id": "W15l9iDZxVPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('훈련용 스토리의 개수 :', len(train_stories))\n",
        "print('훈련용 질문의 개수 :',len(train_questions))\n",
        "print('훈련용 답변의 개수 :',len(train_answers))\n",
        "print('테스트용 스토리의 개수 :',len(test_stories))\n",
        "print('테스트용 질문의 개수 :',len(test_questions))\n",
        "print('테스트용 답변의 개수 :',len(test_answers))\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSu6zFWIxWKx",
        "outputId": "093cd42e-ad2f-4fe1-8347-877a520714d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련용 스토리의 개수 : 10000\n",
            "훈련용 질문의 개수 : 10000\n",
            "훈련용 답변의 개수 : 10000\n",
            "테스트용 스토리의 개수 : 1000\n",
            "테스트용 질문의 개수 : 1000\n",
            "테스트용 답변의 개수 : 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_stories[3576]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7xqJn0SxYDR",
        "outputId": "b79ea8fe-3e0d-47b3-8b9f-0fe8895cceea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John went back to the garden.',\n",
              " 'Mary went to the kitchen.',\n",
              " 'Sandra went back to the bedroom.',\n",
              " 'John travelled to the bedroom.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_questions[3576]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3TsYQ6KyxZP6",
        "outputId": "eecddc4f-6ec8-4189-bae4-604c8c34df79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Where is John? '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_answers[3576]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9Ag3-cx2xaKJ",
        "outputId": "34a4dc35-68c3-4fb8-818c-df4e5494fbef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bedroom'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def tokenize(sent):\n",
        "    return [ x.strip() for x in re.split('(\\W+)', sent) if x and x.strip()]"
      ],
      "metadata": {
        "id": "DOkpnRiSxbEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(train_data, test_data):\n",
        "    counter = FreqDist()\n",
        "\n",
        "    # 두 문장의 story를 하나의 문장으로 통합하는 함수\n",
        "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
        "\n",
        "    # 각 샘플의 길이를 저장하는 리스트\n",
        "    story_len = []\n",
        "    question_len = []\n",
        "\n",
        "    for stories, questions, answers in [train_data, test_data]:\n",
        "        for story in stories:\n",
        "            stories = tokenize(flatten(story)) # 스토리의 문장들을 펼친 후 토큰화\n",
        "            story_len.append(len(stories)) # 각 story의 길이 저장\n",
        "            for word in stories: # 단어 집합에 단어 추가\n",
        "                counter[word] += 1\n",
        "        for question in questions:\n",
        "            question = tokenize(question)\n",
        "            question_len.append(len(question))\n",
        "            for word in question:\n",
        "                counter[word] += 1\n",
        "        for answer in answers:\n",
        "            answer = tokenize(answer)\n",
        "            for word in answer:\n",
        "                counter[word] += 1\n",
        "\n",
        "    # 단어 집합 생성\n",
        "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
        "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
        "\n",
        "    # 가장 긴 샘플의 길이\n",
        "    story_max_len = np.max(story_len)\n",
        "    question_max_len = np.max(question_len)\n",
        "\n",
        "    return word2idx, idx2word, story_max_len, question_max_len"
      ],
      "metadata": {
        "id": "55F0-rc_xcu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)\n"
      ],
      "metadata": {
        "id": "Nb4bqKfoxd_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word2idx)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPeHgfQ3xfCZ",
        "outputId": "2009e330-ffd6-4a2a-c571-16a16e3786f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'to': 1, 'the': 2, '.': 3, 'went': 4, 'Sandra': 5, 'John': 6, 'Daniel': 7, 'Mary': 8, 'travelled': 9, 'journeyed': 10, 'back': 11, 'bathroom': 12, 'garden': 13, 'hallway': 14, 'moved': 15, 'office': 16, 'kitchen': 17, 'bedroom': 18, 'Where': 19, 'is': 20, '?': 21}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(word2idx) + 1\n"
      ],
      "metadata": {
        "id": "wY6zZssjxfzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('스토리의 최대 길이 :',story_max_len)\n",
        "print('질문의 최대 길이 :',question_max_len)\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx8nDUkZxguB",
        "outputId": "ed850257-5835-4393-f312-4ee6d1a71486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "스토리의 최대 길이 : 68\n",
            "질문의 최대 길이 : 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
        "    Xs, Xq, Y = [], [], []\n",
        "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
        "\n",
        "    stories, questions, answers = data\n",
        "    for story, question, answer in zip(stories, questions, answers):\n",
        "        xs = [word2idx[w] for w in tokenize(flatten(story))]\n",
        "        xq = [word2idx[w] for w in tokenize(question)]\n",
        "        Xs.append(xs)\n",
        "        Xq.append(xq)\n",
        "        Y.append(word2idx[answer])\n",
        "\n",
        "        # 스토리와 질문은 각각의 최대 길이로 패딩\n",
        "        # 정답은 원-핫 인코딩\n",
        "    return pad_sequences(Xs, maxlen=story_maxlen),\\\n",
        "           pad_sequences(Xq, maxlen=question_maxlen),\\\n",
        "           to_categorical(Y, num_classes=len(word2idx) + 1)"
      ],
      "metadata": {
        "id": "x2EkTexjxiIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xstrain, Xqtrain, Ytrain = vectorize(train_data, word2idx, story_max_len, question_max_len)\n",
        "Xstest, Xqtest, Ytest = vectorize(test_data, word2idx, story_max_len, question_max_len)\n",
        "     "
      ],
      "metadata": {
        "id": "fu_PE7fZxjUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Xstrain.shape, Xqtrain.shape, Ytrain.shape, Xstest.shape, Xqtest.shape, Ytest.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmWAKZsdxkQZ",
        "outputId": "fb9ef08a-7e6a-4b01-805d-d39fee7f27c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 68) (10000, 4) (10000, 22) (1000, 68) (1000, 4) (1000, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xstrain[3576]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vk7WSlRxk9Z",
        "outputId": "be13b0c6-72bd-42a8-a3e1-dfe4d42885eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  6,  4, 11,  1,  2, 13,  3,  8,  4,\n",
              "        1,  2, 17,  3,  5,  4, 11,  1,  2, 18,  3,  6,  9,  1,  2, 18,  3],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xqtrain[3576]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvc2cpFOxmEA",
        "outputId": "fe1bb5df-b503-427b-8596-3e7049362386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([19, 20,  6, 21], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ytrain[3576]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFc3NwOMxm9Y",
        "outputId": "1cad4eb1-c1e7-44ab-a362-322e16f8de74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 메모리 네트워크로 QA 태스크 풀기\n"
      ],
      "metadata": {
        "id": "VRKdThGtVArw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Permute, dot, add, concatenate\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Activation"
      ],
      "metadata": {
        "id": "oEtFC0WbxnzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 에포크 횟수\n",
        "train_epochs = 120\n",
        "# 배치 크기\n",
        "batch_size = 32\n",
        "# 임베딩 크기\n",
        "embed_size = 50\n",
        "# LSTM의 크기\n",
        "lstm_size = 64\n",
        "# 과적합 방지 기법인 드롭아웃 적용 비율\n",
        "dropout_rate = 0.30"
      ],
      "metadata": {
        "id": "feRPVq0yxpGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 플레이스 홀더. 입력을 담는 변수\n",
        "input_sequence = Input((story_max_len,))\n",
        "question = Input((question_max_len,))\n",
        "\n",
        "print('Stories :', input_sequence)\n",
        "print('Question:', question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbwQ09dzxqAZ",
        "outputId": "deb4ee8c-42f1-4087-905e-e5c4a28e2775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stories : KerasTensor(type_spec=TensorSpec(shape=(None, 68), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
            "Question: KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 스토리를 위한 첫번째 임베딩. 그림에서의 Embedding A\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
        "                              output_dim=embed_size))\n",
        "input_encoder_m.add(Dropout(dropout_rate))\n",
        "# 결과 : (samples, story_max_len, embedding_dim) / 샘플의 수, 문장의 최대 길이, 임베딩 벡터의 차원\n",
        "\n",
        "# 스토리를 위한 두번째 임베딩. 그림에서의 Embedding C\n",
        "# 임베딩 벡터의 차원을 question_max_len(질문의 최대 길이)로 한다.\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
        "                              output_dim=question_max_len))\n",
        "input_encoder_c.add(Dropout(dropout_rate))\n",
        "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이(임베딩 벡터의 차원)\n",
        " "
      ],
      "metadata": {
        "id": "a2T8Hc2qxq_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 질문을 위한 임베딩. 그림에서의 Embedding B\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=embed_size,\n",
        "                               input_length=question_max_len))\n",
        "question_encoder.add(Dropout(dropout_rate))\n",
        "# 결과 : (samples, question_max_len, embedding_dim) / 샘플의 수, 질문의 최대 길이, 임베딩 벡터의 차원"
      ],
      "metadata": {
        "id": "tq2Sxec3xsXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 실질적인 임베딩 과정\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)\n",
        "\n",
        "print('Input encoded m', input_encoded_m)\n",
        "print('Input encoded c', input_encoded_c)\n",
        "print('Question encoded', question_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y-oz0zmxuI5",
        "outputId": "c0da9015-8a83-40dd-bfcf-22b528c11783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input encoded m KerasTensor(type_spec=TensorSpec(shape=(None, 68, 50), dtype=tf.float32, name=None), name='sequential/dropout/Identity:0', description=\"created by layer 'sequential'\")\n",
            "Input encoded c KerasTensor(type_spec=TensorSpec(shape=(None, 68, 4), dtype=tf.float32, name=None), name='sequential_1/dropout_1/Identity:0', description=\"created by layer 'sequential_1'\")\n",
            "Question encoded KerasTensor(type_spec=TensorSpec(shape=(None, 4, 50), dtype=tf.float32, name=None), name='sequential_2/dropout_2/Identity:0', description=\"created by layer 'sequential_2'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 스토리 단어들과 질문 단어들 간의 유사도를 구하는 과정\n",
        "# 유사도는 내적을 사용한다.\n",
        "match = dot([input_encoded_m, question_encoded], axes=-1, normalize=False)\n",
        "match = Activation('softmax')(match)\n",
        "print('Match shape', match)\n",
        "# 결과 : (samples, story_maxlen, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEHL6NmRxvEB",
        "outputId": "6928853f-0eff-4ff1-8cb4-dc9a37f787f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Match shape KerasTensor(type_spec=TensorSpec(shape=(None, 68, 4), dtype=tf.float32, name=None), name='activation/Softmax:0', description=\"created by layer 'activation'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 유사도가 반영된 어텐션 분포 행렬과 임베딩 C를 거친 스토리 행렬을 더한다.\n",
        "# 두 행렬 모두 크기는 (68, 4)이다.\n",
        "# 이로부터 얻은 행렬은 어텐션 값 행렬(Attention Value Matrix)이다.\n",
        "response = add([match, input_encoded_c])\n",
        "     "
      ],
      "metadata": {
        "id": "3RJBGEWWxwid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 질문 행렬은 (4, 50)의 크기를 가진다.\n",
        "# 하지만 어텐션 값 행렬의 크기는 (68, 4)이다.\n",
        "# 이 두 개를 연결시켜주기 위해서 어텐션 값 행렬의 크기를 (4, 68)로 변환해준다.\n",
        "response = Permute((2, 1))(response)  # (samples, question_max_len, story_max_len)\n",
        "print('Response shape', response)\n",
        "\n",
        "# 질문 행렬과 어텐션 값 행렬을 연결한다.\n",
        "# (4, 118)의 크기를 가진다.\n",
        "answer = concatenate([response, question_encoded])\n",
        "print('Answer shape', answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlJdDqvcxxaM",
        "outputId": "aeaf0630-8267-4e48-dbb6-18d005524d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response shape KerasTensor(type_spec=TensorSpec(shape=(None, 4, 68), dtype=tf.float32, name=None), name='permute/transpose:0', description=\"created by layer 'permute'\")\n",
            "Answer shape KerasTensor(type_spec=TensorSpec(shape=(None, 4, 118), dtype=tf.float32, name=None), name='concatenate/concat:0', description=\"created by layer 'concatenate'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "answer = LSTM(lstm_size)(answer)\n",
        "answer = Dropout(dropout_rate)(answer)\n",
        "answer = Dense(vocab_size)(answer)\n",
        "answer = Activation('softmax')(answer)"
      ],
      "metadata": {
        "id": "BZiOrP42xyUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# start training the model\n",
        "history = model.fit([Xstrain, Xqtrain],\n",
        "         Ytrain, batch_size, train_epochs,\n",
        "         validation_data=([Xstest, Xqtest], Ytest))\n",
        "\n",
        "# save model\n",
        "model.save('model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EG81McWgxzt9",
        "outputId": "848a5f49-ac22-4f04-e66a-bb48057facc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 68)]         0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, None, 50)     1100        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " sequential_2 (Sequential)      (None, 4, 50)        1100        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 68, 4)        0           ['sequential[0][0]',             \n",
            "                                                                  'sequential_2[0][0]']           \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 68, 4)        0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, None, 4)      88          ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 68, 4)        0           ['activation[0][0]',             \n",
            "                                                                  'sequential_1[0][0]']           \n",
            "                                                                                                  \n",
            " permute (Permute)              (None, 4, 68)        0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 4, 118)       0           ['permute[0][0]',                \n",
            "                                                                  'sequential_2[0][0]']           \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 64)           46848       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 64)           0           ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 22)           1430        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 22)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 50,566\n",
            "Trainable params: 50,566\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/120\n",
            "313/313 [==============================] - 11s 9ms/step - loss: 1.8887 - acc: 0.1673 - val_loss: 1.8020 - val_acc: 0.1540\n",
            "Epoch 2/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 1.7331 - acc: 0.2347 - val_loss: 1.6580 - val_acc: 0.3060\n",
            "Epoch 3/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.6171 - acc: 0.3423 - val_loss: 1.5620 - val_acc: 0.3840\n",
            "Epoch 4/120\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 1.5194 - acc: 0.4014 - val_loss: 1.5317 - val_acc: 0.3940\n",
            "Epoch 5/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.4979 - acc: 0.4182 - val_loss: 1.5159 - val_acc: 0.3970\n",
            "Epoch 6/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.4721 - acc: 0.4383 - val_loss: 1.4612 - val_acc: 0.4490\n",
            "Epoch 7/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.4203 - acc: 0.4690 - val_loss: 1.3799 - val_acc: 0.4840\n",
            "Epoch 8/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.3727 - acc: 0.4859 - val_loss: 1.3321 - val_acc: 0.5010\n",
            "Epoch 9/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.3355 - acc: 0.4930 - val_loss: 1.3124 - val_acc: 0.5090\n",
            "Epoch 10/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.3152 - acc: 0.4987 - val_loss: 1.2769 - val_acc: 0.5100\n",
            "Epoch 11/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.2968 - acc: 0.5106 - val_loss: 1.2723 - val_acc: 0.5190\n",
            "Epoch 12/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.2851 - acc: 0.5037 - val_loss: 1.2704 - val_acc: 0.5230\n",
            "Epoch 13/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.2596 - acc: 0.5177 - val_loss: 1.2392 - val_acc: 0.5210\n",
            "Epoch 14/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.2524 - acc: 0.5139 - val_loss: 1.2246 - val_acc: 0.5260\n",
            "Epoch 15/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.2387 - acc: 0.5200 - val_loss: 1.2126 - val_acc: 0.5210\n",
            "Epoch 16/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.2266 - acc: 0.5159 - val_loss: 1.2096 - val_acc: 0.5140\n",
            "Epoch 17/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 1.2180 - acc: 0.5152 - val_loss: 1.2039 - val_acc: 0.5170\n",
            "Epoch 18/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.2067 - acc: 0.5184 - val_loss: 1.2237 - val_acc: 0.5190\n",
            "Epoch 19/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.1983 - acc: 0.5237 - val_loss: 1.2059 - val_acc: 0.5030\n",
            "Epoch 20/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.1815 - acc: 0.5311 - val_loss: 1.2196 - val_acc: 0.4970\n",
            "Epoch 21/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.1732 - acc: 0.5260 - val_loss: 1.1881 - val_acc: 0.5070\n",
            "Epoch 22/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.1722 - acc: 0.5240 - val_loss: 1.1867 - val_acc: 0.5180\n",
            "Epoch 23/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 1.1620 - acc: 0.5255 - val_loss: 1.1989 - val_acc: 0.5160\n",
            "Epoch 24/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.1482 - acc: 0.5297 - val_loss: 1.1705 - val_acc: 0.5150\n",
            "Epoch 25/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.1383 - acc: 0.5323 - val_loss: 1.1622 - val_acc: 0.5260\n",
            "Epoch 26/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.1317 - acc: 0.5335 - val_loss: 1.1695 - val_acc: 0.5220\n",
            "Epoch 27/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.1197 - acc: 0.5348 - val_loss: 1.1729 - val_acc: 0.5280\n",
            "Epoch 28/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.1186 - acc: 0.5294 - val_loss: 1.1562 - val_acc: 0.5100\n",
            "Epoch 29/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.1146 - acc: 0.5337 - val_loss: 1.1759 - val_acc: 0.5170\n",
            "Epoch 30/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.0969 - acc: 0.5404 - val_loss: 1.1597 - val_acc: 0.5190\n",
            "Epoch 31/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.0891 - acc: 0.5388 - val_loss: 1.1490 - val_acc: 0.5230\n",
            "Epoch 32/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.0877 - acc: 0.5394 - val_loss: 1.1546 - val_acc: 0.5060\n",
            "Epoch 33/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.0850 - acc: 0.5453 - val_loss: 1.1473 - val_acc: 0.5120\n",
            "Epoch 34/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.0698 - acc: 0.5459 - val_loss: 1.1615 - val_acc: 0.5110\n",
            "Epoch 35/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.0638 - acc: 0.5523 - val_loss: 1.1536 - val_acc: 0.5130\n",
            "Epoch 36/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.0560 - acc: 0.5514 - val_loss: 1.1955 - val_acc: 0.5130\n",
            "Epoch 37/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.0459 - acc: 0.5611 - val_loss: 1.1489 - val_acc: 0.5330\n",
            "Epoch 38/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.0306 - acc: 0.5673 - val_loss: 1.1248 - val_acc: 0.5610\n",
            "Epoch 39/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.9737 - acc: 0.6091 - val_loss: 1.0095 - val_acc: 0.6300\n",
            "Epoch 40/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.8238 - acc: 0.6916 - val_loss: 0.7977 - val_acc: 0.7260\n",
            "Epoch 41/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.6884 - acc: 0.7549 - val_loss: 0.7075 - val_acc: 0.7480\n",
            "Epoch 42/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6195 - acc: 0.7732 - val_loss: 0.7032 - val_acc: 0.7390\n",
            "Epoch 43/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.5693 - acc: 0.7909 - val_loss: 0.6013 - val_acc: 0.7740\n",
            "Epoch 44/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.5109 - acc: 0.8160 - val_loss: 0.5251 - val_acc: 0.8060\n",
            "Epoch 45/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.4516 - acc: 0.8381 - val_loss: 0.4431 - val_acc: 0.8410\n",
            "Epoch 46/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3971 - acc: 0.8569 - val_loss: 0.4068 - val_acc: 0.8510\n",
            "Epoch 47/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.3733 - acc: 0.8613 - val_loss: 0.4009 - val_acc: 0.8530\n",
            "Epoch 48/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3483 - acc: 0.8735 - val_loss: 0.3863 - val_acc: 0.8590\n",
            "Epoch 49/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3245 - acc: 0.8795 - val_loss: 0.3474 - val_acc: 0.8640\n",
            "Epoch 50/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3202 - acc: 0.8832 - val_loss: 0.3840 - val_acc: 0.8600\n",
            "Epoch 51/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2935 - acc: 0.8912 - val_loss: 0.3844 - val_acc: 0.8580\n",
            "Epoch 52/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2908 - acc: 0.8935 - val_loss: 0.3295 - val_acc: 0.8800\n",
            "Epoch 53/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2722 - acc: 0.8963 - val_loss: 0.3333 - val_acc: 0.8760\n",
            "Epoch 54/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2560 - acc: 0.9060 - val_loss: 0.2846 - val_acc: 0.8930\n",
            "Epoch 55/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2405 - acc: 0.9117 - val_loss: 0.2921 - val_acc: 0.8910\n",
            "Epoch 56/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2266 - acc: 0.9188 - val_loss: 0.2599 - val_acc: 0.9120\n",
            "Epoch 57/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2144 - acc: 0.9223 - val_loss: 0.2397 - val_acc: 0.9140\n",
            "Epoch 58/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2022 - acc: 0.9290 - val_loss: 0.2248 - val_acc: 0.9260\n",
            "Epoch 59/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1854 - acc: 0.9370 - val_loss: 0.2067 - val_acc: 0.9270\n",
            "Epoch 60/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1756 - acc: 0.9388 - val_loss: 0.1878 - val_acc: 0.9390\n",
            "Epoch 61/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1550 - acc: 0.9471 - val_loss: 0.1804 - val_acc: 0.9390\n",
            "Epoch 62/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1538 - acc: 0.9488 - val_loss: 0.1707 - val_acc: 0.9420\n",
            "Epoch 63/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1458 - acc: 0.9507 - val_loss: 0.1737 - val_acc: 0.9450\n",
            "Epoch 64/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.1394 - acc: 0.9520 - val_loss: 0.1571 - val_acc: 0.9500\n",
            "Epoch 65/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1317 - acc: 0.9548 - val_loss: 0.1761 - val_acc: 0.9410\n",
            "Epoch 66/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1254 - acc: 0.9585 - val_loss: 0.1655 - val_acc: 0.9440\n",
            "Epoch 67/120\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1140 - acc: 0.9625 - val_loss: 0.1454 - val_acc: 0.9480\n",
            "Epoch 68/120\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1182 - acc: 0.9614 - val_loss: 0.1598 - val_acc: 0.9470\n",
            "Epoch 69/120\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1123 - acc: 0.9635 - val_loss: 0.1431 - val_acc: 0.9540\n",
            "Epoch 70/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1018 - acc: 0.9640 - val_loss: 0.1597 - val_acc: 0.9480\n",
            "Epoch 71/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0979 - acc: 0.9646 - val_loss: 0.1432 - val_acc: 0.9560\n",
            "Epoch 72/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0905 - acc: 0.9712 - val_loss: 0.1474 - val_acc: 0.9550\n",
            "Epoch 73/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0894 - acc: 0.9712 - val_loss: 0.1340 - val_acc: 0.9580\n",
            "Epoch 74/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0795 - acc: 0.9730 - val_loss: 0.1321 - val_acc: 0.9590\n",
            "Epoch 75/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0800 - acc: 0.9743 - val_loss: 0.1476 - val_acc: 0.9580\n",
            "Epoch 76/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0768 - acc: 0.9743 - val_loss: 0.1358 - val_acc: 0.9590\n",
            "Epoch 77/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0710 - acc: 0.9759 - val_loss: 0.1284 - val_acc: 0.9570\n",
            "Epoch 78/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0754 - acc: 0.9754 - val_loss: 0.1205 - val_acc: 0.9620\n",
            "Epoch 79/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0694 - acc: 0.9780 - val_loss: 0.1252 - val_acc: 0.9620\n",
            "Epoch 80/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0670 - acc: 0.9783 - val_loss: 0.1632 - val_acc: 0.9450\n",
            "Epoch 81/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0650 - acc: 0.9781 - val_loss: 0.1125 - val_acc: 0.9680\n",
            "Epoch 82/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0638 - acc: 0.9803 - val_loss: 0.1259 - val_acc: 0.9610\n",
            "Epoch 83/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0611 - acc: 0.9790 - val_loss: 0.1166 - val_acc: 0.9660\n",
            "Epoch 84/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0534 - acc: 0.9805 - val_loss: 0.1153 - val_acc: 0.9660\n",
            "Epoch 85/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0592 - acc: 0.9820 - val_loss: 0.1252 - val_acc: 0.9670\n",
            "Epoch 86/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0542 - acc: 0.9828 - val_loss: 0.1160 - val_acc: 0.9690\n",
            "Epoch 87/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0494 - acc: 0.9859 - val_loss: 0.1003 - val_acc: 0.9750\n",
            "Epoch 88/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0467 - acc: 0.9861 - val_loss: 0.1165 - val_acc: 0.9670\n",
            "Epoch 89/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0471 - acc: 0.9858 - val_loss: 0.1099 - val_acc: 0.9690\n",
            "Epoch 90/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0416 - acc: 0.9852 - val_loss: 0.1174 - val_acc: 0.9650\n",
            "Epoch 91/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0505 - acc: 0.9833 - val_loss: 0.1053 - val_acc: 0.9710\n",
            "Epoch 92/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0426 - acc: 0.9857 - val_loss: 0.1060 - val_acc: 0.9720\n",
            "Epoch 93/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0446 - acc: 0.9872 - val_loss: 0.1167 - val_acc: 0.9700\n",
            "Epoch 94/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0493 - acc: 0.9864 - val_loss: 0.0961 - val_acc: 0.9730\n",
            "Epoch 95/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0421 - acc: 0.9854 - val_loss: 0.1133 - val_acc: 0.9700\n",
            "Epoch 96/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0453 - acc: 0.9871 - val_loss: 0.0822 - val_acc: 0.9760\n",
            "Epoch 97/120\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.0436 - acc: 0.9873 - val_loss: 0.0969 - val_acc: 0.9750\n",
            "Epoch 98/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0345 - acc: 0.9899 - val_loss: 0.1220 - val_acc: 0.9670\n",
            "Epoch 99/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0344 - acc: 0.9888 - val_loss: 0.0921 - val_acc: 0.9790\n",
            "Epoch 100/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0344 - acc: 0.9892 - val_loss: 0.0962 - val_acc: 0.9740\n",
            "Epoch 101/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0385 - acc: 0.9885 - val_loss: 0.0924 - val_acc: 0.9750\n",
            "Epoch 102/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0372 - acc: 0.9909 - val_loss: 0.0926 - val_acc: 0.9730\n",
            "Epoch 103/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0350 - acc: 0.9903 - val_loss: 0.0887 - val_acc: 0.9760\n",
            "Epoch 104/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0296 - acc: 0.9911 - val_loss: 0.0914 - val_acc: 0.9750\n",
            "Epoch 105/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0286 - acc: 0.9919 - val_loss: 0.0836 - val_acc: 0.9790\n",
            "Epoch 106/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0303 - acc: 0.9908 - val_loss: 0.1061 - val_acc: 0.9720\n",
            "Epoch 107/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0292 - acc: 0.9925 - val_loss: 0.1003 - val_acc: 0.9770\n",
            "Epoch 108/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0307 - acc: 0.9929 - val_loss: 0.1210 - val_acc: 0.9690\n",
            "Epoch 109/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0288 - acc: 0.9922 - val_loss: 0.0995 - val_acc: 0.9770\n",
            "Epoch 110/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0288 - acc: 0.9922 - val_loss: 0.1073 - val_acc: 0.9720\n",
            "Epoch 111/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0303 - acc: 0.9911 - val_loss: 0.1008 - val_acc: 0.9730\n",
            "Epoch 112/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0276 - acc: 0.9916 - val_loss: 0.1104 - val_acc: 0.9750\n",
            "Epoch 113/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0360 - acc: 0.9895 - val_loss: 0.0827 - val_acc: 0.9800\n",
            "Epoch 114/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0322 - acc: 0.9904 - val_loss: 0.0993 - val_acc: 0.9740\n",
            "Epoch 115/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0280 - acc: 0.9923 - val_loss: 0.0900 - val_acc: 0.9770\n",
            "Epoch 116/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0253 - acc: 0.9927 - val_loss: 0.1039 - val_acc: 0.9760\n",
            "Epoch 117/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0260 - acc: 0.9929 - val_loss: 0.0727 - val_acc: 0.9770\n",
            "Epoch 118/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0292 - acc: 0.9913 - val_loss: 0.0930 - val_acc: 0.9780\n",
            "Epoch 119/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0262 - acc: 0.9931 - val_loss: 0.0830 - val_acc: 0.9770\n",
            "Epoch 120/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0249 - acc: 0.9933 - val_loss: 0.0974 - val_acc: 0.9770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate([Xstest, Xqtest], Ytest)[1]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3iqMR2qx0mE",
        "outputId": "3b280d92-2cd4-4f41-a2c7-97f34d9f2683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0974 - acc: 0.9770\n",
            "\n",
            " 테스트 정확도: 0.9770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# plot accuracy and loss plot\n",
        "plt.subplot(211)\n",
        "plt.title(\"Accuracy\")\n",
        "plt.plot(history.history[\"acc\"], color=\"g\", label=\"train\")\n",
        "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
        "plt.legend(loc=\"best\")\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.title(\"Loss\")\n",
        "plt.plot(history.history[\"loss\"], color=\"g\", label=\"train\")\n",
        "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
        "plt.legend(loc=\"best\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# labels\n",
        "ytest = np.argmax(Ytest, axis=1)\n",
        "\n",
        "# get predictions\n",
        "Ytest_ = model.predict([Xstest, Xqtest])\n",
        "ytest_ = np.argmax(Ytest_, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "YlWhG4jhx2s9",
        "outputId": "ddf6fc77-5878-4dbb-d388-f7ecfa8ce958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 1s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YKbr3YlQx30W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}