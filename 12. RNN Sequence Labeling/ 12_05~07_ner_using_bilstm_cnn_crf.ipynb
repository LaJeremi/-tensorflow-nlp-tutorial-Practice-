{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgEz89uXyRAgzPjNQyjzZ5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaJeremi/Tensorflow-nlp-tutorial-Practice-/blob/main/12.%20RNN%20Sequence%20Labeling/%2012_05~07_ner_using_bilstm_cnn_crf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "순서\n",
        "\n",
        "# 12-05\n",
        "출처: https://wikidocs.net/147219\n",
        "1. 개체명 인식 데이터에 대한 이해와 전처리\n",
        "\n",
        "# 12-07\n",
        "1. 문자 임베딩(Char Embedding)을 위한 전처리\n",
        "\n",
        "char 정보를 사용하기 위한 추가 전처리\n",
        "\n",
        "\n",
        "# 12-05\n",
        "2. 양방향 LSTM을 이용한 개체명 인식\n",
        "3. F1-score - 스킵\n",
        "4. F1-score로 성능 측정하기\n",
        "\n",
        "#12-06 \n",
        "1.2.3. BiLSTM-CRF를 이용한 개체명 인식\n",
        "\n",
        "# 12-07\n",
        "2. BiLSTM-CNN을 이용한 개체명 인식\n",
        "3. BiLSTM-CNN-CRF\n",
        "4. BiLSTM-BiLSTM-CRF\n",
        "\n",
        "\n",
        "-------\n",
        "\n",
        "### '양방향 LSTM에 문자 임베딩을 사용한 모델' OR 양방향 LSTM에 CRF 층을 추가적으로 사용한 모델이 \n",
        "\n",
        "### 단순 '양방향 LSTM만을 사용한 모델' 보다는 성능이 더 좋은 것을 확인"
      ],
      "metadata": {
        "id": "11180HjjtNjB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12-05 BiLSTM을 이용한 개체명 인식(Named Entity Recognition, NER)\n",
        "\n",
        "출처: https://wikidocs.net/147219"
      ],
      "metadata": {
        "id": "B4lLvrR3TVap"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6p2TCWuIxZan",
        "outputId": "01e52f13-c5ce-4c5e-961a-70eb131e3229"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.11.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-crf==0.3.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaXwvWsKxaOG",
        "outputId": "e074c0b1-085a-43c1-8f7e-cb4435f5dc18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-crf==0.3.0\n",
            "  Downloading keras_crf-0.3.0-py3-none-any.whl (8.3 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (from keras-crf==0.3.0) (2.11.0)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf==0.3.0) (2.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf==0.3.0) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf==0.3.0) (4.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf==0.3.0) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf==0.3.0) (1.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf==0.3.0) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf==0.3.0) (1.51.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf==0.3.0) (3.1.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf==0.3.0) (15.0.6.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf==0.3.0) (1.21.6)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf==0.3.0) (23.1.21)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf==0.3.0) (0.30.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf==0.3.0) (2.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf==0.3.0) (23.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf==0.3.0) (3.19.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf==0.3.0) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf==0.3.0) (1.14.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf==0.3.0) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf==0.3.0) (2.11.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf==0.3.0) (2.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf==0.3.0) (0.4.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->keras-crf==0.3.0) (2.7.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow->keras-crf==0.3.0) (0.38.4)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-crf==0.3.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-crf==0.3.0) (2.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-crf==0.3.0) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-crf==0.3.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-crf==0.3.0) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-crf==0.3.0) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-crf==0.3.0) (2.25.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-crf==0.3.0) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-crf==0.3.0) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-crf==0.3.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-crf==0.3.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-crf==0.3.0) (6.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-crf==0.3.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-crf==0.3.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-crf==0.3.0) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-crf==0.3.0) (4.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-crf==0.3.0) (3.12.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-crf==0.3.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-crf==0.3.0) (3.2.2)\n",
            "Installing collected packages: tensorflow-addons, keras-crf\n",
            "Successfully installed keras-crf-0.3.0 tensorflow-addons-0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "!pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSkgD7Hyxbb2",
        "outputId": "cab9f4ab-45d9-48df-93cf-f221b7631a4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from seqeval) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=e58f8d71e266896eaac0d36831f235509ed4b1d97984c7c04ff11031608c2511\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep keras-crf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UGJRBokxchm",
        "outputId": "5a017b72-0fa9-4578-d358-4dc3a73364d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keras-crf                     0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8x1dQtvo8uv",
        "outputId": "b92a7ba5-8daf-44ed-edd7-2209d5508bcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12-05 BiLSTM을 이용한 개체명 인식(Named Entity Recognition, NER)\n",
        "# 1. 개체명 인식 데이터에 대한 이해와 전처리\n",
        "\n",
        "출처: https://wikidocs.net/147219\n"
      ],
      "metadata": {
        "id": "D9lBrj5RgQrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "     "
      ],
      "metadata": {
        "id": "DFJ-xSmJxdQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/12.%20Sequence%20Labeling/dataset/ner_dataset.csv\", filename=\"ner_dataset.csv\")\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/ner_dataset.csv\", encoding=\"latin1\")\n"
      ],
      "metadata": {
        "id": "8byiWOUOx5W4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/ner_dataset.csv\", encoding=\"latin1\")\n"
      ],
      "metadata": {
        "id": "q5W41TuyxeHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[:5]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "c6gk2P6Gxe52",
        "outputId": "8f22ad6e-33ce-48a7-e4b9-d59569b5d3b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1          NaN             of   IN   O\n",
              "2          NaN  demonstrators  NNS   O\n",
              "3          NaN           have  VBP   O\n",
              "4          NaN        marched  VBN   O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a17ca200-7ebf-474a-9f39-609b3c13bbe2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a17ca200-7ebf-474a-9f39-609b3c13bbe2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a17ca200-7ebf-474a-9f39-609b3c13bbe2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a17ca200-7ebf-474a-9f39-609b3c13bbe2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 첫번째 열 'Sentence :#'은 다음과 같은 패턴을 가지고 있습니다. Sentence: 1이 등장하고 Null 값이 이어지다가 다시 Sentence: 2가 등장하고 다시 Null 값이 이어지다가 Sentence: 3이 등장하고 다시 Null 값이 이어지다가를 반복합니다. 사실 이는 하나의 문장을 여러 행으로 나눠놓은 것입니다. 숫자값을 t라고 합시다. 첫번째 Sentence: t부터 Null 값이 나오다가 Sentence: t+1이 나오기 전까지의 모든 행은 기존에 하나의 문장이었습니다. t번째 문장을 단어 토큰화 후 각 행으로 나눠놓은 데이터이기 때문입니다. 뒤에서 Pandas의 fillna를 통해 하나로 묶는 작업을 해줍니다."
      ],
      "metadata": {
        "id": "22LA8U7qg7oT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('데이터프레임 행의 개수 : {}'.format(len(data)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZnYzJolxgM-",
        "outputId": "4225a797-185a-46f6-b2c7-c94c741567b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터프레임 행의 개수 : 1048575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('데이터에 Null 값이 있는지 유무 : ' + str(data.isnull().values.any()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kKw6Iz_xg_m",
        "outputId": "53979d2a-e0d6-4ba2-e6f2-97fe2e6b086a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터에 Null 값이 있는지 유무 : True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('어떤 열에 Null값이 있는지 출력')\n",
        "print('==============================')\n",
        "data.isnull().sum()\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXXIVfA4xiHW",
        "outputId": "49824d6d-b0a2-480a-aff7-2c3f1fac2065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어떤 열에 Null값이 있는지 출력\n",
            "==============================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence #    1000616\n",
              "Word                0\n",
              "POS                 0\n",
              "Tag                 0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 전체 데이터에서 중복을 허용하지 않고 유일한 값의 개수를 셀 수 있게 해주는 nunique()를 사용"
      ],
      "metadata": {
        "id": "dp4bun0xhGQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('sentence # 열의 중복을 제거한 값의 개수 : {}'.format(data['Sentence #'].nunique()))\n",
        "print('Word 열의 중복을 제거한 값의 개수 : {}'.format(data.Word.nunique()))\n",
        "print('Tag 열의 중복을 제거한 값의 개수 : {}'.format(data.Tag.nunique()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gdEs0rSxjH_",
        "outputId": "91027178-0090-4e59-92ef-c04e2c399896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence # 열의 중복을 제거한 값의 개수 : 47959\n",
            "Word 열의 중복을 제거한 값의 개수 : 35178\n",
            "Tag 열의 중복을 제거한 값의 개수 : 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 이 데이터에는 47,959개의 문장이 있으며 문장들은 35,178개의 단어를 가지고 17개 종류의 개체명 태깅을 가집니다. \n",
        "\n",
        "* 17개의 개체명 태깅이 전체 데이터에서 몇 개가 있는지, 개체명 태깅 개수의 분포를 확인"
      ],
      "metadata": {
        "id": "BbBAkJmihJ1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('Tag 열의 각각의 값의 개수 카운트')\n",
        "print('================================')\n",
        "print(data.groupby('Tag').size().reset_index(name='count'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlRfsdfOxkGf",
        "outputId": "c9adc27f-adf2-4c35-cb80-e68471366054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tag 열의 각각의 값의 개수 카운트\n",
            "================================\n",
            "      Tag   count\n",
            "0   B-art     402\n",
            "1   B-eve     308\n",
            "2   B-geo   37644\n",
            "3   B-gpe   15870\n",
            "4   B-nat     201\n",
            "5   B-org   20143\n",
            "6   B-per   16990\n",
            "7   B-tim   20333\n",
            "8   I-art     297\n",
            "9   I-eve     253\n",
            "10  I-geo    7414\n",
            "11  I-gpe     198\n",
            "12  I-nat      51\n",
            "13  I-org   16784\n",
            "14  I-per   17251\n",
            "15  I-tim    6528\n",
            "16      O  887908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 데이터를 원하는 형태로 가공해보겠습니다. 우선 Null 값을 제거합니다. Pandas의 fillna(method='ffill')는 Null 값을 가진 행의 바로 앞의 행의 값으로 Null 값을 채우는 작업을 수행합니다. t번째 문장에 속하면서 Null 값을 가진 샘플들은 전부 첫번째 열에 Sentence: t의 값이 들어갑니다. 이번에는 뒤의 5개의 샘플을 출력해서 정상적으로 수행되었는지 확인"
      ],
      "metadata": {
        "id": "nEWPUqKFhYNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.fillna(method=\"ffill\")\n"
      ],
      "metadata": {
        "id": "2LacCeS8xlNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.tail())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhAedVqKxmbv",
        "outputId": "e1d61694-09ce-4295-d44f-7269c0f07a03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Sentence #       Word  POS Tag\n",
            "1048570  Sentence: 47959       they  PRP   O\n",
            "1048571  Sentence: 47959  responded  VBD   O\n",
            "1048572  Sentence: 47959         to   TO   O\n",
            "1048573  Sentence: 47959        the   DT   O\n",
            "1048574  Sentence: 47959     attack   NN   O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('데이터에 Null 값이 있는지 유무 : ' + str(data.isnull().values.any()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymPKTV2vxnIW",
        "outputId": "bed04830-de9f-4789-c944-6e977b85f2a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터에 Null 값이 있는지 유무 : False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모든 단어를 소문자화하여 단어의 개수를 줄여보겠습니다."
      ],
      "metadata": {
        "id": "yudJf31BhdMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data['Word'] = data['Word'].str.lower()\n",
        "print('Word 열의 중복을 제거한 값의 개수 : {}'.format(data.Word.nunique()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVMsQaxpxn9O",
        "outputId": "8d2a8ec2-6f07-4be7-f844-6b61a2a4c6a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word 열의 중복을 제거한 값의 개수 : 31817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXZhfu-5xozG",
        "outputId": "c6023be9-2961-4679-d8fe-fa7643ca241c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Sentence #           Word  POS Tag\n",
            "0  Sentence: 1      thousands  NNS   O\n",
            "1  Sentence: 1             of   IN   O\n",
            "2  Sentence: 1  demonstrators  NNS   O\n",
            "3  Sentence: 1           have  VBP   O\n",
            "4  Sentence: 1        marched  VBN   O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 하나의 문장에 등장한 단어와 개체명 태깅 정보끼리 쌍(pair)으로 묶는 작업을 수행합니다."
      ],
      "metadata": {
        "id": "qUYzok-LhjA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "func = lambda temp: [(w, t) for w, t in zip(temp[\"Word\"].values.tolist(), temp[\"Tag\"].values.tolist())]\n",
        "tagged_sentences=[t for t in data.groupby(\"Sentence #\").apply(func)]\n",
        "print(\"전체 샘플 개수: {}\".format(len(tagged_sentences)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6MbsF1ixpmP",
        "outputId": "6edccec3-ce1e-48aa-adb4-3ab2d167cb3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 개수: 47959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1,000,616개의 행의 개수가 각 문장당 하나의 샘플로 묶이면서 47,959개의 샘플이 되었습니다. 정상적으로 수행되었는지 첫번째 샘플을 출력"
      ],
      "metadata": {
        "id": "UJ0F355AhxUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tagged_sentences[0]) # 첫번째 샘플 출력\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzY_2u_ExrDn",
        "outputId": "170730f8-4050-4dd7-b3fb-5ba0b83f7ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'), ('marched', 'O'), ('through', 'O'), ('london', 'B-geo'), ('to', 'O'), ('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'), ('iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), ('withdrawal', 'O'), ('of', 'O'), ('british', 'B-gpe'), ('troops', 'O'), ('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그런데 훈련을 시키려면 훈련 데이터에서 단어에 해당되는 부분과 개체명 태깅 정보에 해당되는 부분을 분리\n",
        "\n",
        "즉, [('thousands', 'O'), ('of', 'O')]와 같은 문장 샘플이 있다면 thousands와 of는 같이 저장하고, O와 O를 같이 저장할 필요가 있습니다. 동일한 개수를 가지는 시퀀스 자료형에서 각 순서에 등장하는 원소들끼리 묶어주는 역할을 하는 zip()을 사용하여 단어와 개체명 태깅 정보를 분리"
      ],
      "metadata": {
        "id": "yFCtgJHzh2j0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sentences, ner_tags = [], [] \n",
        "for tagged_sentence in tagged_sentences: # 47,959개의 문장 샘플을 1개씩 불러온다.\n",
        "    sentence, tag_info = zip(*tagged_sentence) # 각 샘플에서 단어들은 sentence에 개체명 태깅 정보들은 tag_info에 저장.\n",
        "    sentences.append(list(sentence)) # 각 샘플에서 단어 정보만 저장한다.\n",
        "    ner_tags.append(list(tag_info)) # 각 샘플에서 개체명 태깅 정보만 저장한다."
      ],
      "metadata": {
        "id": "E5iorlt8paxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences[0])\n",
        "print(ner_tags[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znYyYKLspbxP",
        "outputId": "0cab6f87-c155-49cb-cd2f-950cacbed82c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(sentences[98])\n",
        "print(ner_tags[98])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkU_4_Wmpcu_",
        "outputId": "8cf5a9fd-e413-414e-c35a-1a10d5652cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['she', 'had', 'once', 'received', 'a', 'kidney', 'transplant', '.']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('샘플의 최대 길이 : %d' % max(len(l) for l in sentences))\n",
        "print('샘플의 평균 길이 : %f' % (sum(map(len, sentences))/len(sentences)))\n",
        "plt.hist([len(s) for s in sentences], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "TPyCFx0bpd_P",
        "outputId": "1fd606aa-431b-48a1-e14a-436db750eced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이 : 104\n",
            "샘플의 평균 길이 : 21.863988\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 위의 그래프는 샘플들의 길이가 대체적으로 0~40의 길이를 가지는 것을 보여줍니다. 길이가 가장 긴 샘플의 길이는 104입니다. \n",
        "\n",
        "## 케라스 토크나이저를 통해서 정수 인코딩을 진행합니다. 이번에는 문장 데이터에 있는 모든 단어를 사용하겠습니다."
      ],
      "metadata": {
        "id": "R-A2Ij53iHTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_tokenizer = Tokenizer(oov_token='OOV') # 모든 단어를 사용하지만 인덱스 1에는 단어 'OOV'를 할당한다.\n",
        "src_tokenizer.fit_on_texts(sentences)\n",
        "tar_tokenizer = Tokenizer(lower=False) # 태깅 정보들은 내부적으로 대문자를 유지한채로 저장\n",
        "tar_tokenizer.fit_on_texts(ner_tags)"
      ],
      "metadata": {
        "id": "lG5PAgo_pfNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문장 데이터에 대해서는 src_tokenizer\n",
        "\n",
        "### 레이블에 해당되는 개체명 태깅 정보에 대해서는 tar_tokenizer를 사용"
      ],
      "metadata": {
        "id": "Ei-w9D5YiPCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(src_tokenizer.word_index) + 1\n",
        "tag_size = len(tar_tokenizer.word_index) + 1\n",
        "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
        "print('개체명 태깅 정보 집합의 크기 : {}'.format(tag_size))\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKCDjk2SpgE_",
        "outputId": "3aeb8db9-e1e1-42e3-9a68-ca976e8a6bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 31819\n",
            "개체명 태깅 정보 집합의 크기 : 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "앞서 src_tokenizer를 만들때 Tokenizer의 인자로 oov_token='OOV'를 선택했습니다. 인덱스1에 단어 'OOV'가 할당*"
      ],
      "metadata": {
        "id": "lG6hv5k1iW2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 OOV의 인덱스 : {}'.format(src_tokenizer.word_index['OOV']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29Fb87d_phGY",
        "outputId": "df7b60db-fa82-4c11-b19b-6b9e6db96a59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 OOV의 인덱스 : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 정수 인코딩을 수행"
      ],
      "metadata": {
        "id": "kNqZtJPLiaU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_data = src_tokenizer.texts_to_sequences(sentences)\n",
        "y_data = tar_tokenizer.texts_to_sequences(ner_tags)"
      ],
      "metadata": {
        "id": "Md2CkjFXpiFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_data[0])\n",
        "print(y_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkaNF8HzpjfQ",
        "outputId": "370b7316-e311-4ec4-cae8-23ee11947d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[254, 6, 967, 16, 1795, 238, 468, 7, 523, 2, 129, 5, 61, 9, 571, 2, 833, 6, 186, 90, 22, 15, 56, 3]\n",
            "[1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 훈련 후 결과 확인을 위해 인덱스로부터 단어를 리턴하는 index_to_word\n",
        "\n",
        "### 인덱스로부터 개체명 태깅 정보를 리턴하는 index_to_ner\n",
        "\n",
        " 인덱스 0은 'PAD'란 단어를 할당\n",
        "\n",
        "  index_to_ner은 개수가 적으니 출력"
      ],
      "metadata": {
        "id": "Yd-mU8hFiijZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = src_tokenizer.word_index\n",
        "index_to_word = src_tokenizer.index_word\n",
        "ner_to_index = tar_tokenizer.word_index\n",
        "index_to_ner = tar_tokenizer.index_word\n",
        "index_to_ner[0] = 'PAD'"
      ],
      "metadata": {
        "id": "1KsygHmrpkog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(index_to_ner)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV8MKiFRplpv",
        "outputId": "c5d6e011-0e6b-40af-e986-4cdee5fd4603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'O', 2: 'B-geo', 3: 'B-tim', 4: 'B-org', 5: 'I-per', 6: 'B-per', 7: 'I-org', 8: 'B-gpe', 9: 'I-geo', 10: 'I-tim', 11: 'B-art', 12: 'B-eve', 13: 'I-art', 14: 'I-eve', 15: 'B-nat', 16: 'I-gpe', 17: 'I-nat', 0: 'PAD'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### index_to_word를 통해 첫번째 샘플의 정수 시퀀스를 텍스트 시퀀스로 변환하는 디코딩 작업을 해보겠습니다."
      ],
      "metadata": {
        "id": "nUVAR9AZiuQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoded = []\n",
        "for index in X_data[0] : # 첫번째 샘플 안의 인덱스들에 대해서\n",
        "    decoded.append(index_to_word[index]) # 다시 단어로 변환\n",
        "\n",
        "print('기존의 문장 : {}'.format(sentences[0]))\n",
        "print('디코딩 문장 : {}'.format(decoded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTBJqp_wpmqo",
        "outputId": "3b28616e-b6e3-47cf-a918-661b9c91e320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "기존의 문장 : ['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n",
            "디코딩 문장 : ['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 데이터의 길이는 40~60에 분포되어져 있습니다. 그러므로 가장 긴 샘플의 길이인 104가 아니라 70정도로 max_len을 정해보겠습니다\n",
        "\n",
        "### 2. 훈련 데이터와 테스트 데이터를 8:2의 비율로 분리"
      ],
      "metadata": {
        "id": "Ck1hmREmiycz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "max_len = 70\n",
        "X_data = pad_sequences(X_data, padding='post', maxlen=max_len)\n",
        "y_data = pad_sequences(y_data, padding='post', maxlen=max_len)"
      ],
      "metadata": {
        "id": "-IgFy2G1pnkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_data.shape)\n",
        "print(y_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LiEJhH_pomI",
        "outputId": "42a93fd1-9fae-4e70-b273-6a36c50b1a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(47959, 70)\n",
            "(47959, 70)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train_int, y_test_int = train_test_split(X_data, y_data, test_size=.2, random_state=777)\n"
      ],
      "metadata": {
        "id": "JXN5sZPrppuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 원-핫 인코딩을 수행"
      ],
      "metadata": {
        "id": "826blLBii7wZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_train = to_categorical(y_train_int, num_classes=tag_size)\n",
        "y_test = to_categorical(y_test_int, num_classes=tag_size)"
      ],
      "metadata": {
        "id": "50UHg4Qvpqs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
        "print('훈련 샘플 레이블(정수 인코딩)의 크기 : {}'.format(y_train_int.shape))\n",
        "print('훈련 샘플 레이블(원-핫 인코딩)의 크기 : {}'.format(y_train.shape))\n",
        "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
        "print('테스트 샘플 레이블(정수 인코딩)의 크기 : {}'.format(y_test_int.shape))\n",
        "print('테스트 샘플 레이블(원-핫 인코딩)의 크기 : {}'.format(y_test.shape))\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSlkhsfFprfg",
        "outputId": "f203d262-37cc-47a6-c2d5-359bfe6e9c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 샘플 문장의 크기 : (38367, 70)\n",
            "훈련 샘플 레이블(정수 인코딩)의 크기 : (38367, 70)\n",
            "훈련 샘플 레이블(원-핫 인코딩)의 크기 : (38367, 70, 18)\n",
            "테스트 샘플 문장의 크기 : (9592, 70)\n",
            "테스트 샘플 레이블(정수 인코딩)의 크기 : (9592, 70)\n",
            "테스트 샘플 레이블(원-핫 인코딩)의 크기 : (9592, 70, 18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12-07 문자 임베딩(Character Embedding) 활용하기\n",
        "\n",
        "# 1. 문자 임베딩(Char Embedding)을 위한 전처리\n",
        "\n",
        "\n",
        "# char 정보를 사용하기 위한 추가 전처리\n",
        "\n",
        "출처 : https://wikidocs.net/147299\n",
        "\n",
        "문자 임베딩을 위해서 하고자 하는 전처리는 문자 단위 정수 인코딩\n",
        "\n",
        "가령 단어 'book'이 있고, b가 21번 o가 7번, k가 11번이라고 한다면 단어 'book'을 [21 7 7 11]로 인코딩\n",
        "\n",
        "'good book'이란 문장이 있고, g가 12번, d가 17번이라고 한다면 이 문장을 문자 단위 정수 인코딩 후에는 다음과 같은 결과를 얻을 수 있습니다.\n",
        "\n",
        "'good book의 정수 인코딩 결과'\n",
        "\n",
        "[[12 7 7 17]\n",
        "\n",
        "[21 7 7 11]]\n",
        "\n",
        "이 각 문자와 맵핑된 정수를 각각 임베딩 층(Embedding layer)을 거치도록 하여, 문자 단위 임베딩\n",
        "\n",
        "문자에 대한 정수 인코딩을 진행\n",
        "\n",
        ". 우선 전체 데이터의 모든 단어를 문자 레벨로 분해하여, 문자 집합\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LJXQG3MgpwMB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# char_vocab 만들기\n"
      ],
      "metadata": {
        "id": "ulN-CFK5puRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# char_vocab 만들기\n",
        "words = list(set(data[\"Word\"].values))\n",
        "chars = set([w_i for w in words for w_i in w])\n",
        "chars = sorted(list(chars))\n",
        "print(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaCUtWzEpzjf",
        "outputId": "fb14af50-276c-443c-e69c-d4587751b2c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~', '\\x85', '\\x91', '\\x92', '\\x93', '\\x94', '\\x96', '\\x97', '\\xa0', '°', 'é', 'ë', 'ö', 'ü']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이렇게 얻은 문자 집합으로부터 문자를 정수로 변환할 수 있는 딕셔너리인 \n",
        "\n",
        "# char_to_index와 반대로 정수로부터 문자를 얻을 수 있는 \n",
        "\n",
        "# 딕셔너리인 index_to_char를 만듭니다."
      ],
      "metadata": {
        "id": "o8q3pXy6kjSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "char_to_index = {c: i + 2 for i, c in enumerate(chars)}\n",
        "char_to_index[\"OOV\"] = 1\n",
        "char_to_index[\"PAD\"] = 0"
      ],
      "metadata": {
        "id": "kfbPnbOfp1qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_char = {}\n",
        "for key, value in char_to_index.items():\n",
        "    index_to_char[value] = key\n",
        "     "
      ],
      "metadata": {
        "id": "QekGgyVnp2yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "단어를 표현하는 문자 시퀀스의 최대 길이는 15로 제한 후 패딩"
      ],
      "metadata": {
        "id": "KzFWNns-ko-g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4lPa-15dku-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CofJczuLp4C3",
        "outputId": "85c4c05f-6bbd-4ee1-8637-428a73b1a08a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "max_len_char = 15\n",
        "\n",
        "def padding_char_indice(char_indice, max_len_char):\n",
        "  return pad_sequences(\n",
        "        char_indice, maxlen=max_len_char, padding='post', value = 0)\n",
        "\n",
        "def integer_coding(sentences):\n",
        "  char_data = []\n",
        "  for ts in sentences:\n",
        "    word_indice = [word_to_index[t] for t in ts]\n",
        "    char_indice = [[char_to_index[char] for char in t]  \n",
        "                                          for t in ts]\n",
        "    char_indice = padding_char_indice(char_indice, max_len_char)\n",
        "\n",
        "    for chars_of_token in char_indice:\n",
        "      if len(chars_of_token) > max_len_char:\n",
        "        continue\n",
        "    char_data.append(char_indice)\n",
        "  return char_data"
      ],
      "metadata": {
        "id": "1wSklndkp5G3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_char_data = integer_coding(sentences)\n"
      ],
      "metadata": {
        "id": "GkzUv5sap6TX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "동일한 문장에 대해서 단어 단위 정수 인코딩과 문자 단위 정수 인코딩의 차이를 확인해봅시다. 첫번째 샘플은 다음과 같습니다."
      ],
      "metadata": {
        "id": "EDq2Mu1FkxNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 정수 인코딩 이전의 기존 문장\n",
        "print(sentences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSwjsNcUp7TH",
        "outputId": "2b0b9058-b771-45aa-d426-060ea4edbb73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 문장을 정수 인코딩 및 패딩한 결과는 다음과 같습니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "o0bDdi94k8U0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_data[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYt9VH9fp8YX",
        "outputId": "bf65ff51-9106-417d-f347-0febe2579def"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 254    6  967   16 1795  238  468    7  523    2  129    5   61    9\n",
            "  571    2  833    6  186   90   22   15   56    3    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 254는 기존의 thousands, 6은 기존의 of에 해당됩니다. 해당 샘플을 문자 단위 정수 인코딩한 결과는 다음과 같습니다."
      ],
      "metadata": {
        "id": "WiLj-d-vlAEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_char_data[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq1cW6nLp9kX",
        "outputId": "101374c9-1afb-4e7c-ce30-bf6d5c808565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[53 41 48 54 52 34 47 37 52  0  0  0  0  0  0]\n",
            " [48 39  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [37 38 46 48 47 52 53 51 34 53 48 51 52  0  0]\n",
            " [41 34 55 38  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [46 34 51 36 41 38 37  0  0  0  0  0  0  0  0]\n",
            " [53 41 51 48 54 40 41  0  0  0  0  0  0  0  0]\n",
            " [45 48 47 37 48 47  0  0  0  0  0  0  0  0  0]\n",
            " [53 48  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [49 51 48 53 38 52 53  0  0  0  0  0  0  0  0]\n",
            " [53 41 38  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [56 34 51  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [42 47  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [42 51 34 50  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [34 47 37  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [37 38 46 34 47 37  0  0  0  0  0  0  0  0  0]\n",
            " [53 41 38  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [56 42 53 41 37 51 34 56 34 45  0  0  0  0  0]\n",
            " [48 39  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [35 51 42 53 42 52 41  0  0  0  0  0  0  0  0]\n",
            " [53 51 48 48 49 52  0  0  0  0  0  0  0  0  0]\n",
            " [39 51 48 46  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [53 41 34 53  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [36 48 54 47 53 51 58  0  0  0  0  0  0  0  0]\n",
            " [14  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 위 출력 결과에서 각 행은 각 단어를 의미합니다. 가령, thousands는 첫번째 행 [53 41 48 54 52 34 47 37 52 0 0 0 0 0 0]에 해당됩니다. 단어의 최대 길이를 15(max_len_char)로 제한하였으므로, 길이가 15보다 짧은 단어는 뒤에 0으로 패딩됩니다.\n",
        "\n",
        "# 53은 t, 41은 h, 48은 o, 54는 u에 각각 해당됩니다. X_data는 뒤에 0으로 패딩되어 길이가 70인 것에 비해 X_char_data는 현재 0번 단어는 무시되어 길이가 70이 아닙니다. 다시 말해 위 출력 결과에서 행의 개수가 70이 아닌 상태입니다. 길이 70으로 맞춰주기 위해서 문장 길이 방향으로도 패딩"
      ],
      "metadata": {
        "id": "YK9rrNkulLhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_char_data = pad_sequences(X_char_data, maxlen=max_len, padding='post', value = 0)\n"
      ],
      "metadata": {
        "id": "yBC3SWKzp-av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 단어 단위 정수 인코딩 결과는 이미 X_train, y_train, X_test, y_test로 훈련 데이터와 테스트 데이터가 분리된 상태입니다. 문자 단위 정수 인코딩 결과에 대해서도 마찬가지로 X_char_train, X_char_test로 나누어줍니"
      ],
      "metadata": {
        "id": "vyKnTeUFlSwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_char_train, X_char_test, _, _ = train_test_split(X_char_data, y_data, test_size=.2, random_state=777)\n"
      ],
      "metadata": {
        "id": "mXDqWWPQp_of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_char_train = np.array(X_char_train)\n",
        "X_char_test = np.array(X_char_test)"
      ],
      "metadata": {
        "id": "HPKlDCdqqAs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldhENqtuqBi2",
        "outputId": "cf729f93-3bf2-4e85-a28b-eb250cf33193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 150  928  361   17 2624    9 4131 3567    9    8 2893 1250  880  107\n",
            "    3    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "첫번째 훈련 샘플의 첫번째 단어인 150번"
      ],
      "metadata": {
        "id": "jtV7C_hBlXVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(index_to_word[150])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWgiUQGlqCdm",
        "outputId": "8c03ef56-fe01-47f9-d441-d07af73f6240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "soldiers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그렇다면 X_char_train의 첫번째 훈련 샘플의 첫번째 단어의 문자 정수 인코딩 결과로부터 soldiers라는 단어와 일치하는지 확인\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sHyImFOUlb-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_char_train[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkCu__hnqDVm",
        "outputId": "1c71213e-7215-4770-d155-3dd828291ef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[52 48 45 ...  0  0  0]\n",
            " [51 38 53 ...  0  0  0]\n",
            " [39 42 51 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_char_train[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vDjpccQqEde",
        "outputId": "9e9c76ba-ecb5-43a7-fce8-c96f20d4a84d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[52 48 45 37 42 38 51 52  0  0  0  0  0  0  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(' '.join([index_to_char[index] for index in X_char_train[0][0]]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJSGgcSvqFcH",
        "outputId": "44761d72-04cc-46df-d404-9dc6539de14e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s o l d i e r s PAD PAD PAD PAD PAD PAD PAD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
        "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
        "print('훈련 샘플 char 데이터의 크기 : {}'.format(X_char_train.shape))\n",
        "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
        "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ3erCb6qGff",
        "outputId": "da4ed839-21ec-4fc5-f195-0f78531fce3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 샘플 문장의 크기 : (38367, 70)\n",
            "훈련 샘플 레이블의 크기 : (38367, 70, 18)\n",
            "훈련 샘플 char 데이터의 크기 : (38367, 70, 15)\n",
            "테스트 샘플 문장의 크기 : (9592, 70)\n",
            "테스트 샘플 레이블의 크기 : (9592, 70, 18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BiLSTM을 이용한 개체명 인식\n",
        "\n",
        "# 12-05 BiLSTM을 이용한 개체명 인식(Named Entity Recognition, NER)\n",
        "\n",
        "# 2. 양방향 LSTM을 이용한 개체명 인식\n",
        "\n",
        "출처: https://wikidocs.net/147219\n",
        "\n",
        "# 모델링\n",
        "\n",
        "하이퍼파라미터인 임베딩 벡터의 차원은 128, 은닉 상태의 크기는 256\n",
        "\n",
        "모델: 다 대 다 구조의 양방향 LSTM을 사용\n",
        "\n",
        " LSTM의 return_sequences의 인자값은 True\n",
        "\n",
        " . 이번 실습과 같이 각 데이터의 길이가 달라서 패딩을 하느라 숫자 0이 많아질 경우에는 Embedding()에 mask_zero=True를 설정하여 숫자 0은 연산에서 제외시킨다는 옵션을 줄 수 있습니다. 출력층에 TimeDistributed()를 사용했는데, TimeDistributed()는 LSTM을 다 대 다 구조로 사용하여 LSTM의 모든 시점에 대해서 출력층을 사용할 필요가 있을 때 사용합니다.\n",
        "\n",
        "다중 클래스 분류 문제\n",
        "\n",
        "출력층에 소프트맥스 회귀를 사용해야 하므로 활성화 함수로는 소프트맥스 함수를 사용하고, 손실 함수로 크로스 엔트로피 함수를 사용\n",
        "\n",
        "하이퍼파라미터인 배치 크기는 128이며, 6 에포크를 수행\n",
        "\n",
        ". validation_split=0.1을 사용하여 훈련 데이터의 10%를 검증 데이터로 분리해서 사용"
      ],
      "metadata": {
        "id": "TlbpjrqHqJck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "4LyZhmqpqHiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "hidden_units = 256\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, mask_zero=True))\n",
        "model.add(Bidirectional(LSTM(hidden_units, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(tag_size, activation=('softmax'))))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "U4Jwf-FEqNTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NLh712EqmNQ",
        "outputId": "639682b2-aba6-4fb1-b895-66527ecff295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 128)         4072832   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, None, 512)        788480    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, None, 18)         9234      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,870,546\n",
            "Trainable params: 4,870,546\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, batch_size=128, epochs=6, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7QB0jd2qnYo",
        "outputId": "263748ef-d78b-4143-cd16-0bdf980138ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "270/270 [==============================] - 40s 98ms/step - loss: 0.5480 - accuracy: 0.8790 - val_loss: 0.2406 - val_accuracy: 0.9339\n",
            "Epoch 2/6\n",
            "270/270 [==============================] - 9s 35ms/step - loss: 0.1724 - accuracy: 0.9505 - val_loss: 0.1554 - val_accuracy: 0.9540\n",
            "Epoch 3/6\n",
            "270/270 [==============================] - 7s 26ms/step - loss: 0.1196 - accuracy: 0.9644 - val_loss: 0.1395 - val_accuracy: 0.9575\n",
            "Epoch 4/6\n",
            "270/270 [==============================] - 5s 20ms/step - loss: 0.0975 - accuracy: 0.9700 - val_loss: 0.1391 - val_accuracy: 0.9584\n",
            "Epoch 5/6\n",
            "270/270 [==============================] - 5s 17ms/step - loss: 0.0844 - accuracy: 0.9733 - val_loss: 0.1397 - val_accuracy: 0.9591\n",
            "Epoch 6/6\n",
            "270/270 [==============================] - 5s 17ms/step - loss: 0.0746 - accuracy: 0.9760 - val_loss: 0.1451 - val_accuracy: 0.9574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('bilstm.h5')\n"
      ],
      "metadata": {
        "id": "r9Gp5muWqo0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 13 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
        "y_predicted = model.predict(np.array([X_test[i]])) # 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
        "y_predicted = np.argmax(y_predicted, axis=-1) # 확률 벡터를 정수 인코딩으로 변경함.\n",
        "true = np.argmax(y_test[i], -1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\n",
        "\n",
        "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
        "print(35 * \"-\")\n",
        "\n",
        "for word, tag, pred in zip(X_test[i], true, y_predicted[0]):\n",
        "    if word != 0: # PAD값은 제외함.\n",
        "        print(\"{:17}: {:7} {}\".format(index_to_word[word], index_to_ner[tag], index_to_ner[pred]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMCqOquCqp2g",
        "outputId": "2e7ab750-85f5-4d2d-e3f0-0fd3a91ef6a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "단어             |실제값  |예측값\n",
            "-----------------------------------\n",
            "the              : O       O\n",
            "statement        : O       O\n",
            "came             : O       O\n",
            "as               : O       O\n",
            "u.n.             : B-org   B-org\n",
            "secretary-general: I-org   I-org\n",
            "kofi             : B-per   B-per\n",
            "annan            : I-per   I-per\n",
            "met              : O       O\n",
            "with             : O       O\n",
            "officials        : O       O\n",
            "in               : O       O\n",
            "amman            : B-geo   B-geo\n",
            "to               : O       O\n",
            "discuss          : O       O\n",
            "wednesday        : B-tim   B-tim\n",
            "'s               : O       O\n",
            "attacks          : O       O\n",
            ".                : O       O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = range(1, len(history.history['val_loss']) + 1)\n",
        "plt.plot(epochs, history.history['loss'])\n",
        "plt.plot(epochs, history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "xc0DUTPzqq4f",
        "outputId": "0a6a1d94-59ca-44fd-9615-b3eee4978df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12-05 BiLSTM을 이용한 개체명 인식(Named Entity Recognition, NER)\n",
        "\n",
        "# 4. F1-score로 성능 측정하기\n",
        "\n",
        "# 출처: https://wikidocs.net/147219\n",
        "\n",
        "F1-score를 계산하기 위해서 개체명 태깅의 확률 벡터 또는 원-핫 벡터로부터 태깅 정보 시퀀스로 변환하는 함수인 sequences_to_tag를 만듭니다. \n",
        "\n",
        "해당 함수를 통해 모델의 예측값인 y_predicted와 실제값에 해당하는 y_test를 태깅 정보 시퀀스로 변환합니다. 그리고 두 개를 비교하여 f1-score를 계산"
      ],
      "metadata": {
        "id": "HPf-lCp8m1f6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import f1_score, classification_report\n"
      ],
      "metadata": {
        "id": "kaGuhPIEqsPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def sequences_to_tag(sequences): # 예측값을 index_to_ner를 사용하여 태깅 정보로 변경하는 함수.\n",
        "    result = []\n",
        "    for sequence in sequences: # 전체 시퀀스로부터 시퀀스를 하나씩 꺼낸다.\n",
        "        temp = []\n",
        "        for pred in sequence: # 시퀀스로부터 예측값을 하나씩 꺼낸다.\n",
        "            pred_index = np.argmax(pred) # 예를 들어 [0, 0, 1, 0 ,0]라면 1의 인덱스인 2를 리턴한다.\n",
        "            temp.append(index_to_ner[pred_index].replace(\"PAD\", \"O\")) # 'PAD'는 'O'로 변경\n",
        "        result.append(temp)\n",
        "    return result"
      ],
      "metadata": {
        "id": "i4T6vH8iqtTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q2YZ0Q7tsEbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_predicted = model.predict([X_test])\n",
        "pred_tags = sequences_to_tag(y_predicted)\n",
        "test_tags = sequences_to_tag(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8cumTQhquEo",
        "outputId": "5b8b78c8-b711-4dd6-aaf3-dda737b0239e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300/300 [==============================] - 4s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_tags, pred_tags))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFyVU-GzqvGf",
        "outputId": "0ad2e841-06b9-4582-8ad2-5f8916499497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.18      0.05      0.07        63\n",
            "         eve       0.54      0.27      0.36        52\n",
            "         geo       0.86      0.80      0.83      7620\n",
            "         gpe       0.95      0.94      0.94      3145\n",
            "         nat       0.45      0.27      0.34        37\n",
            "         org       0.54      0.61      0.57      4033\n",
            "         per       0.72      0.73      0.73      3545\n",
            "         tim       0.85      0.84      0.85      4067\n",
            "\n",
            "   micro avg       0.78      0.78      0.78     22562\n",
            "   macro avg       0.64      0.56      0.59     22562\n",
            "weighted avg       0.79      0.78      0.78     22562\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0t5tXFbq103",
        "outputId": "1b9b7f69-26fe-44ad-c590-0641e9c24d47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 78.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "어서 CRF 층을 추가하여 성능을 높여봅시다."
      ],
      "metadata": {
        "id": "u-DXikWJnO5c"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QsinNMh-t1QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12-06 BiLSTM-CRF를 이용한 개체명 인식\n",
        "# 3. BiLSTM-CRF를 이용한 개체명 인식\n",
        "\n",
        "\n",
        "# BiLSTM-CRF를 이용한 개체명인식\n",
        "# 모델링\n",
        "\n",
        "출처: https://wikidocs.net/147234\n",
        "\n",
        "이전과 동일한 데이터에 대해서 모델을 학습해봅시다. \n",
        "\n",
        "## 마지막 층에 CRF 층을 추가하기 위하여 함수형 API를 사용합니다. \n",
        "\n",
        "하이퍼파라미터인 임베딩 벡터의 차원은 128, \n",
        "은닉 상태의 크기는 64\n",
        "모델은 다 대 다 구조의 양방향 LSTM을 사용합니다. \n",
        "\n",
        "이 경우 LSTM의 return_sequences의 인자값은 True\n",
        "출력층에 TimeDistributed()를 사용, \n",
        "TimeDistributed()는 LSTM을 다 대 다 구조로 사용하여 LSTM의 모든 시점에 대해서 출력층을 사용할 필요가 있을 때 사용합니다.\n",
        "\n",
        "-----\n",
        "\n",
        "해당 모델은 모든 시점에 대해서 개체명 레이블 개수만큼의 선택지 중 하나를 예측하는 다중 클래스 분류 문제를 수행하는 모델입니다. 여기서는 최종 출력층이 CRF 층으로 CRF 층에 분류해야 하는 선택지 개수를 의미하는 tag_size를 전달해줍니다."
      ],
      "metadata": {
        "id": "NmSZzXF4t22I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input, Bidirectional, TimeDistributed, Embedding, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras_crf import CRFModel\n",
        "from seqeval.metrics import f1_score, classification_report"
      ],
      "metadata": {
        "id": "jdhxBDLst5XA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "hidden_units = 64\n",
        "dropout_ratio = 0.3\n",
        "\n",
        "sequence_input = Input(shape=(max_len,),dtype=tf.int32, name='sequence_input')\n",
        "\n",
        "model_embedding = Embedding(input_dim=vocab_size,\n",
        "                            output_dim=embedding_dim,\n",
        "                            input_length=max_len)(sequence_input)\n",
        "\n",
        "model_bilstm = Bidirectional(LSTM(units=hidden_units, return_sequences=True))(model_embedding)\n",
        "\n",
        "model_dropout = TimeDistributed(Dropout(dropout_ratio))(model_bilstm)\n",
        "\n",
        "model_dense = TimeDistributed(Dense(tag_size, activation='relu'))(model_dropout)\n",
        "\n",
        "base = Model(inputs=sequence_input, outputs=model_dense)\n",
        "model = CRFModel(base, tag_size)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001), metrics='accuracy')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84w0OlpluCBI",
        "outputId": "0837ecde-653d-4850-e3ef-deba83004853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"crf_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " sequence_input (InputLayer)    [(None, 70)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 70, 128)      4072832     ['sequence_input[0][0]']         \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, 70, 128)     98816       ['embedding_1[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " time_distributed_1 (TimeDistri  (None, 70, 128)     0           ['bidirectional_1[0][0]']        \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " time_distributed_2 (TimeDistri  (None, 70, 18)      2322        ['time_distributed_1[0][0]']     \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " crf (CRF)                      [(None, 70),         702         ['time_distributed_2[0][0]']     \n",
            "                                 (None, 70, 18),                                                  \n",
            "                                 (None,),                                                         \n",
            "                                 (18, 18)]                                                        \n",
            "                                                                                                  \n",
            " decode_sequence (Lambda)       (None, 70)           0           ['crf[0][0]']                    \n",
            "                                                                                                  \n",
            " potentials (Lambda)            (None, 70, 18)       0           ['crf[0][1]']                    \n",
            "                                                                                                  \n",
            " sequence_length (Lambda)       (None,)              0           ['crf[0][2]']                    \n",
            "                                                                                                  \n",
            " kernel (Lambda)                (18, 18)             0           ['crf[0][3]']                    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,174,672\n",
            "Trainable params: 4,174,672\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('bilstm_crf/cp.ckpt', monitor='val_decode_sequence_accuracy', mode='max', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "     "
      ],
      "metadata": {
        "id": "5e7kZgKRuUf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼파라미터인 배치 크기는 128이며, 15 에포크를 수행\n",
        "\n",
        "validation_split=0.1을 사용하여 훈련 데이터의 10%를 검증 데이터로 분리해서 사용\n",
        "\n",
        "검증 데이터를 통해서 훈련이 적절히 되고 있는지 확인\n",
        "\n",
        ". 조기 종료를 사용하기 위해서 콜백을 정의\n",
        "\n",
        "## . keras-crf가 원-핫 인코딩 된 레이블은 지원하지 않으므로 y_train이 아니라 y_train_int를 사용함을 주의합니다."
      ],
      "metadata": {
        "id": "SRFzSCpAsp3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train_int, batch_size=128, epochs=15, validation_split=0.1, callbacks=[mc, es])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boyUkSTCuWVI",
        "outputId": "389ed393-6dd4-4d4b-dd2b-e8984ec655ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9154 - loss: 28.4227\n",
            "Epoch 1: val_decode_sequence_accuracy improved from -inf to 0.96095, saving model to bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 48s 151ms/step - decode_sequence_accuracy: 0.9154 - loss: 28.3522 - val_decode_sequence_accuracy: 0.9610 - val_loss: 8.9030\n",
            "Epoch 2/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9716 - loss: 6.4258\n",
            "Epoch 2: val_decode_sequence_accuracy improved from 0.96095 to 0.98080, saving model to bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 29s 108ms/step - decode_sequence_accuracy: 0.9716 - loss: 6.4176 - val_decode_sequence_accuracy: 0.9808 - val_loss: 4.9572\n",
            "Epoch 3/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9831 - loss: 3.7449\n",
            "Epoch 3: val_decode_sequence_accuracy improved from 0.98080 to 0.98388, saving model to bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 28s 102ms/step - decode_sequence_accuracy: 0.9831 - loss: 3.7425 - val_decode_sequence_accuracy: 0.9839 - val_loss: 3.6226\n",
            "Epoch 4/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9864 - loss: 2.7174\n",
            "Epoch 4: val_decode_sequence_accuracy improved from 0.98388 to 0.98489, saving model to bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 27s 98ms/step - decode_sequence_accuracy: 0.9864 - loss: 2.7187 - val_decode_sequence_accuracy: 0.9849 - val_loss: 3.1836\n",
            "Epoch 5/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9882 - loss: 2.1861\n",
            "Epoch 5: val_decode_sequence_accuracy improved from 0.98489 to 0.98514, saving model to bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 27s 99ms/step - decode_sequence_accuracy: 0.9882 - loss: 2.1858 - val_decode_sequence_accuracy: 0.9851 - val_loss: 3.0823\n",
            "Epoch 6/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9893 - loss: 1.8548\n",
            "Epoch 6: val_decode_sequence_accuracy improved from 0.98514 to 0.98551, saving model to bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 26s 97ms/step - decode_sequence_accuracy: 0.9893 - loss: 1.8542 - val_decode_sequence_accuracy: 0.9855 - val_loss: 3.0308\n",
            "Epoch 7/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9902 - loss: 1.6151\n",
            "Epoch 7: val_decode_sequence_accuracy did not improve from 0.98551\n",
            "270/270 [==============================] - 26s 96ms/step - decode_sequence_accuracy: 0.9902 - loss: 1.6143 - val_decode_sequence_accuracy: 0.9851 - val_loss: 3.1880\n",
            "Epoch 8/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9910 - loss: 1.4115\n",
            "Epoch 8: val_decode_sequence_accuracy did not improve from 0.98551\n",
            "270/270 [==============================] - 26s 97ms/step - decode_sequence_accuracy: 0.9910 - loss: 1.4112 - val_decode_sequence_accuracy: 0.9854 - val_loss: 3.2071\n",
            "Epoch 9/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9917 - loss: 1.2562\n",
            "Epoch 9: val_decode_sequence_accuracy did not improve from 0.98551\n",
            "270/270 [==============================] - 27s 100ms/step - decode_sequence_accuracy: 0.9917 - loss: 1.2565 - val_decode_sequence_accuracy: 0.9854 - val_loss: 3.2952\n",
            "Epoch 10/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9922 - loss: 1.1164\n",
            "Epoch 10: val_decode_sequence_accuracy did not improve from 0.98551\n",
            "270/270 [==============================] - 26s 96ms/step - decode_sequence_accuracy: 0.9922 - loss: 1.1161 - val_decode_sequence_accuracy: 0.9850 - val_loss: 3.3785\n",
            "Epoch 10: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "조기 종료로 학습이 끝났다면 검증 데이터에 대해서 정확도가 가장 높았을 당시를 저장해둔 가중치를 불러온 후, 임의로 선정한 테스트 데이터의 13번 인덱스의 샘플에 대해서 예측해봅시다."
      ],
      "metadata": {
        "id": "CFdA8xYzs0ui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('bilstm_crf/cp.ckpt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N2iPFI6uXIY",
        "outputId": "bb199703-45a3-41b0-f218-02d3574511f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f5c7a396d60>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 13 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
        "y_predicted = model.predict(np.array([X_test[i]]))[0] # 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
        "true = np.argmax(y_test[i], -1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\n",
        "\n",
        "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
        "print(35 * \"-\")\n",
        "\n",
        "for word, tag, pred in zip(X_test[i], true, y_predicted[0]):\n",
        "    if word != 0: # PAD값은 제외함.\n",
        "        print(\"{:17}: {:7} {}\".format(index_to_word[word], index_to_ner[tag], index_to_ner[pred]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoUu0TfjuYOQ",
        "outputId": "72a001a0-dfe4-44e8-8298-ed05874e390b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 988ms/step\n",
            "단어             |실제값  |예측값\n",
            "-----------------------------------\n",
            "the              : O       O\n",
            "statement        : O       O\n",
            "came             : O       O\n",
            "as               : O       O\n",
            "u.n.             : B-org   B-org\n",
            "secretary-general: I-org   I-org\n",
            "kofi             : B-per   B-per\n",
            "annan            : I-per   I-per\n",
            "met              : O       O\n",
            "with             : O       O\n",
            "officials        : O       O\n",
            "in               : O       O\n",
            "amman            : B-geo   B-geo\n",
            "to               : O       O\n",
            "discuss          : O       O\n",
            "wednesday        : B-tim   B-tim\n",
            "'s               : O       O\n",
            "attacks          : O       O\n",
            ".                : O       O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "테스트 데이터에 대한 예측 시퀀스인 y_predicted를 얻습니다."
      ],
      "metadata": {
        "id": "VoD4aPYys4wk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted = model.predict(X_test)[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqba_aUuuaT_",
        "outputId": "bf9d17aa-91fa-4077-d930-a4e5656b1278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300/300 [==============================] - 8s 28ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "상위 2개만 출력해봅시다."
      ],
      "metadata": {
        "id": "VsbPta26s4RP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "예측값으로 확률 벡터가 아니라 정수 시퀀스가 출력\n",
        "\n",
        " 경우 이전 실습에서 사용했던 함수인 sequences_to_tag를 사용할 수 없으므로 함수를 수정해야 합니다. 확률 벡터가 아닌 정수 시퀀스를 입력으로 받아서 태깅 정보 시퀀스를 리턴하는 함수로 sequences_to_tag_for_crf를 만듭니다. \n",
        "\n",
        " 해당 함수를 사용하여 예측값과 레이블에 해당하는 y_test를 태깅 정보 시퀀스로 변환하여 F1-score를 계산합니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "0Jo31J6fs-FP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def sequences_to_tag(sequences): # 예측값을 index_to_ner를 사용하여 태깅 정보로 변경하는 함수.\n",
        "    result = []\n",
        "    for sequence in sequences: # 전체 시퀀스로부터 시퀀스를 하나씩 꺼낸다.\n",
        "        temp = []\n",
        "        for pred in sequence: # 시퀀스로부터 예측값을 하나씩 꺼낸다.\n",
        "            pred_index = np.argmax(pred) # 예를 들어 [0, 0, 1, 0 ,0]라면 1의 인덱스인 2를 리턴한다.\n",
        "            temp.append(index_to_ner[pred_index].replace(\"PAD\", \"O\")) # 'PAD'는 'O'로 변경\n",
        "        result.append(temp)\n",
        "    return result"
      ],
      "metadata": {
        "id": "3FUGygofuiXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def sequences_to_tag_for_crf(sequences): # 예측값을 index_to_ner를 사용하여 태깅 정보로 변경하는 함수.\n",
        "    result = []\n",
        "    for sequence in sequences: # 전체 시퀀스로부터 시퀀스를 하나씩 꺼낸다.\n",
        "        temp = []\n",
        "        for pred in sequence: # 시퀀스로부터 예측값을 하나씩 꺼낸다.\n",
        "            # pred_index = np.argmax(pred) # 예를 들어 [0, 0, 1, 0 ,0]라면 1의 인덱스인 2를 리턴한다.\n",
        "            pred_index = pred\n",
        "            temp.append(index_to_ner[pred_index].replace(\"PAD\", \"O\")) # 'PAD'는 'O'로 변경\n",
        "        result.append(temp)\n",
        "    return result"
      ],
      "metadata": {
        "id": "M-l18HvVujOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_tags = sequences_to_tag_for_crf(y_predicted)\n",
        "test_tags = sequences_to_tag(y_test)"
      ],
      "metadata": {
        "id": "2aYjHHTYukVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_tags, pred_tags))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrjsIh6hulX_",
        "outputId": "4a795832-0acb-4990-fd36-6d231c0c2b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        63\n",
            "         eve       0.00      0.00      0.00        52\n",
            "         geo       0.81      0.86      0.84      7620\n",
            "         gpe       0.94      0.93      0.93      3145\n",
            "         nat       0.00      0.00      0.00        37\n",
            "         org       0.67      0.55      0.60      4033\n",
            "         per       0.76      0.70      0.73      3545\n",
            "         tim       0.85      0.83      0.84      4067\n",
            "\n",
            "   micro avg       0.81      0.78      0.79     22562\n",
            "   macro avg       0.50      0.48      0.49     22562\n",
            "weighted avg       0.80      0.78      0.79     22562\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pu4BwHxRumJ3",
        "outputId": "a2cad64c-1fbd-407e-effa-f6dc0782a7ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 79.3%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12-07 문자 임베딩(Character Embedding) 활용하기\n",
        "\n",
        "# 2. BiLSTM-CNN을 이용한 개체명 인식\n",
        "\n",
        "# 모델링\n",
        "\n",
        "우선 문자 임베딩이 활용되는 과정\n",
        "\n",
        "나의 단어는 문자 단위로 토큰화\n",
        "\n",
        "토큰화 된 각 문자는 위의 전처리를 통해 정수로 맵핑된 상태\n",
        "\n",
        "### 정수로 맵핑된 각 문자는 임베딩 층을 통과하면 64차원의 벡터\n",
        "\n",
        "이후 1D 합성곱 층의 입력으로 사용\n",
        "\n",
        "# 1D 합성곱 층의 커널의 크기는 3이며 해당 커널은 총 30개 사용\n",
        "\n",
        "#  1D 합성곱 층의 결과로 하나의 단어에 대한 단어 벡터\n",
        "\n",
        "해당 단어 벡터는 일반적으로 워드 임베딩이라고 부르던 과정을 통해 얻은 단어의 임베딩 벡터와 연결(concatenate)\n",
        "\n",
        "\n",
        "\n",
        "이를 양방향 LSTM의 입력으로 사용하게 되는데, 이후에는 이전 실습들과 같습니다\n",
        "\n",
        "# *LSTM의 은닉 상태의 크기는 256\n",
        "\n",
        "모델은 다 대 다 구조의 양방향 LSTM을 사용\n",
        "\n",
        "이 경우 LSTM의 return_sequences의 인자값은 True\n",
        "\n",
        "* 출력층에 TimeDistributed()를 사용하여 LSTM의 모든 시점에 대해서 출력층을 사용합니다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ehXiFLdLu2P4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MYiu_gPSuwXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.layers import Embedding, Input, TimeDistributed, Dropout, concatenate, Bidirectional, LSTM, Conv1D, Dense, MaxPooling1D, Flatten\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.initializers import RandomUniform\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "from seqeval.metrics import f1_score, classification_report"
      ],
      "metadata": {
        "id": "NTz5K8sdunT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "char_embedding_dim = 64\n",
        "dropout_ratio = 0.5\n",
        "hidden_units = 256\n",
        "num_filters = 30\n",
        "kernel_size = 3\n",
        "\n",
        "# 단어 임베딩\n",
        "words_input = Input(shape=(None,),dtype='int32',name='words_input')\n",
        "words = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(words_input)\n",
        "\n",
        "# char 임베딩\n",
        "character_input = Input(shape=(None, max_len_char,),name='char_input')\n",
        "embed_char_out = TimeDistributed(Embedding(len(char_to_index), char_embedding_dim, embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name='char_embedding')(character_input)\n",
        "dropout = Dropout(dropout_ratio)(embed_char_out)\n",
        "\n",
        "# char 임베딩에 대해서는 Conv1D 수행\n",
        "conv1d_out= TimeDistributed(Conv1D(kernel_size=kernel_size, filters=num_filters, padding='same', activation='tanh', strides=1))(dropout)\n",
        "maxpool_out=TimeDistributed(MaxPooling1D(max_len_char))(conv1d_out)\n",
        "char = TimeDistributed(Flatten())(maxpool_out)\n",
        "char = Dropout(dropout_ratio)(char)\n",
        "\n",
        "# char 임베딩을 Conv1D 수행한 뒤에 단어 임베딩과 연결\n",
        "output = concatenate([words, char])\n",
        "\n",
        "# 연결한 벡터를 가지고 문장의 길이만큼 LSTM을 수행\n",
        "output = Bidirectional(LSTM(hidden_units, return_sequences=True, dropout=dropout_ratio))(output)\n",
        "\n",
        "# 출력층\n",
        "output = TimeDistributed(Dense(tag_size, activation='softmax'))(output)\n",
        "\n",
        "model = Model(inputs=[words_input, character_input], outputs=[output])\n",
        "model.compile(loss='categorical_crossentropy', optimizer='nadam',  metrics=['acc'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUPDhWu-u6GA",
        "outputId": "e748ecc2-dbab-495d-86cd-0f85137aae64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " char_input (InputLayer)        [(None, None, 15)]   0           []                               \n",
            "                                                                                                  \n",
            " char_embedding (TimeDistribute  (None, None, 15, 64  4736       ['char_input[0][0]']             \n",
            " d)                             )                                                                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, None, 15, 64  0           ['char_embedding[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " time_distributed_3 (TimeDistri  (None, None, 15, 30  5790       ['dropout_1[0][0]']              \n",
            " buted)                         )                                                                 \n",
            "                                                                                                  \n",
            " time_distributed_4 (TimeDistri  (None, None, 1, 30)  0          ['time_distributed_3[0][0]']     \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " words_input (InputLayer)       [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " time_distributed_5 (TimeDistri  (None, None, 30)    0           ['time_distributed_4[0][0]']     \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, None, 128)    4072832     ['words_input[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, None, 30)     0           ['time_distributed_5[0][0]']     \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, None, 158)    0           ['embedding_2[0][0]',            \n",
            "                                                                  'dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " bidirectional_2 (Bidirectional  (None, None, 512)   849920      ['concatenate[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " time_distributed_6 (TimeDistri  (None, None, 18)    9234        ['bidirectional_2[0][0]']        \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,942,512\n",
            "Trainable params: 4,942,512\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "조기 종료를 조건으로 콜백을 정의\n",
        "\n",
        "이전 실습과 동일한 조건으로 배치 크기는 128로 하고, 15 에포크를 학습\n",
        "\n",
        "훈련 데이터의 10%를 검증 데이터로 사용"
      ],
      "metadata": {
        "id": "_ut1PIOGoz8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('bilstm_cnn.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "MbyRn0wYvAaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([X_train, X_char_train], y_train, batch_size=128, epochs=15, validation_split=0.1, verbose=1, callbacks=[es, mc])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fJAHsCevB4Y",
        "outputId": "2407feea-9131-4dea-8309-40ff13d9197f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.2041 - acc: 0.9488\n",
            "Epoch 1: val_acc improved from -inf to 0.97759, saving model to bilstm_cnn.h5\n",
            "270/270 [==============================] - 39s 105ms/step - loss: 0.2041 - acc: 0.9488 - val_loss: 0.0809 - val_acc: 0.9776\n",
            "Epoch 2/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0596 - acc: 0.9830\n",
            "Epoch 2: val_acc improved from 0.97759 to 0.98536, saving model to bilstm_cnn.h5\n",
            "270/270 [==============================] - 11s 39ms/step - loss: 0.0596 - acc: 0.9830 - val_loss: 0.0498 - val_acc: 0.9854\n",
            "Epoch 3/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0417 - acc: 0.9878\n",
            "Epoch 3: val_acc improved from 0.98536 to 0.98660, saving model to bilstm_cnn.h5\n",
            "270/270 [==============================] - 9s 34ms/step - loss: 0.0417 - acc: 0.9878 - val_loss: 0.0445 - val_acc: 0.9866\n",
            "Epoch 4/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0348 - acc: 0.9895\n",
            "Epoch 4: val_acc improved from 0.98660 to 0.98717, saving model to bilstm_cnn.h5\n",
            "270/270 [==============================] - 7s 24ms/step - loss: 0.0348 - acc: 0.9895 - val_loss: 0.0422 - val_acc: 0.9872\n",
            "Epoch 5/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0307 - acc: 0.9905\n",
            "Epoch 5: val_acc improved from 0.98717 to 0.98753, saving model to bilstm_cnn.h5\n",
            "270/270 [==============================] - 7s 25ms/step - loss: 0.0307 - acc: 0.9905 - val_loss: 0.0412 - val_acc: 0.9875\n",
            "Epoch 6/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0277 - acc: 0.9913\n",
            "Epoch 6: val_acc improved from 0.98753 to 0.98763, saving model to bilstm_cnn.h5\n",
            "270/270 [==============================] - 6s 22ms/step - loss: 0.0277 - acc: 0.9913 - val_loss: 0.0415 - val_acc: 0.9876\n",
            "Epoch 7/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0255 - acc: 0.9919\n",
            "Epoch 7: val_acc did not improve from 0.98763\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0255 - acc: 0.9919 - val_loss: 0.0424 - val_acc: 0.9876\n",
            "Epoch 8/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0234 - acc: 0.9924\n",
            "Epoch 8: val_acc did not improve from 0.98763\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0234 - acc: 0.9924 - val_loss: 0.0428 - val_acc: 0.9872\n",
            "Epoch 9/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0218 - acc: 0.9930\n",
            "Epoch 9: val_acc did not improve from 0.98763\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0218 - acc: 0.9930 - val_loss: 0.0442 - val_acc: 0.9874\n",
            "Epoch 9: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "조기 종료로 학습이 끝났다면 검증 데이터에 대해서 정확도가 가장 높았을 당시를 저장해둔 가중치를 불러옵니다.\n",
        "\n",
        "해당 모델에 대해서 테스트 데이터의 13번 인덱스의 샘플에 대해서 예측"
      ],
      "metadata": {
        "id": "BypBPOlQo-N8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('bilstm_cnn.h5')\n"
      ],
      "metadata": {
        "id": "tHt_I9HxvDYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 13 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
        "\n",
        "# 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
        "y_predicted = model.predict([np.array([X_test[i]]), np.array([X_char_test[i]])])\n",
        "y_predicted = np.argmax(y_predicted, axis=-1) # 확률 벡터를 정수 인코딩으로 변경함.\n",
        "true = np.argmax(y_test[i], -1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\n",
        "\n",
        "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
        "print(35 * \"-\")\n",
        "\n",
        "for word, tag, pred in zip(X_test[i], true, y_predicted[0]):\n",
        "    if word != 0: # PAD값은 제외함.\n",
        "        print(\"{:17}: {:7} {}\".format(index_to_word[word], index_to_ner[tag], index_to_ner[pred]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyWBhJsSvMlY",
        "outputId": "cbf28c32-915c-4509-9f12-22e12064bb24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 698ms/step\n",
            "단어             |실제값  |예측값\n",
            "-----------------------------------\n",
            "the              : O       O\n",
            "statement        : O       O\n",
            "came             : O       O\n",
            "as               : O       O\n",
            "u.n.             : B-org   B-org\n",
            "secretary-general: I-org   I-org\n",
            "kofi             : B-per   B-per\n",
            "annan            : I-per   I-per\n",
            "met              : O       O\n",
            "with             : O       O\n",
            "officials        : O       O\n",
            "in               : O       O\n",
            "amman            : B-geo   B-geo\n",
            "to               : O       O\n",
            "discuss          : O       O\n",
            "wednesday        : B-tim   B-tim\n",
            "'s               : O       O\n",
            "attacks          : O       O\n",
            ".                : O       O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = range(1, len(history.history['val_loss']) + 1)\n",
        "plt.plot(epochs, history.history['loss'])\n",
        "plt.plot(epochs, history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZRiFz63hvaRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def sequences_to_tag(sequences): # 예측값을 index_to_ner를 사용하여 태깅 정보로 변경하는 함수.\n",
        "    result = []\n",
        "    for sequence in sequences: # 전체 시퀀스로부터 시퀀스를 하나씩 꺼낸다.\n",
        "        temp = []\n",
        "        for pred in sequence: # 시퀀스로부터 예측값을 하나씩 꺼낸다.\n",
        "            pred_index = np.argmax(pred) # 예를 들어 [0, 0, 1, 0 ,0]라면 1의 인덱스인 2를 리턴한다.\n",
        "            temp.append(index_to_ner[pred_index].replace(\"PAD\", \"O\")) # 'PAD'는 'O'로 변경\n",
        "        result.append(temp)\n",
        "    return result"
      ],
      "metadata": {
        "id": "subfoMJ7vcMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "정확하게 잘 예측한 것 같습니다. 테스트 데이터에 대해서 성능을 측정해봅시다. 테스트 데이터에 대한 예측 시퀀스인 y_predicted를 얻습니다. 그리고 예측값과 실제값에 대한 태깅 정보 시퀀스를 얻은 후 F1-score를 계산합니다."
      ],
      "metadata": {
        "id": "sYxiWKqUpWpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted = model.predict([X_test, X_char_test])\n",
        "pred_tags = sequences_to_tag(y_predicted)\n",
        "test_tags = sequences_to_tag(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNyb1B1kvdGn",
        "outputId": "87ab00e1-e43a-4038-893a-8ba870c6b3a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300/300 [==============================] - 1s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_tags, pred_tags))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fIyAhClveHg",
        "outputId": "d20a2d19-ed1c-4d91-cc30-9ca4b3246c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        63\n",
            "         eve       0.79      0.21      0.33        52\n",
            "         geo       0.81      0.86      0.84      7620\n",
            "         gpe       0.95      0.94      0.95      3145\n",
            "         nat       1.00      0.03      0.05        37\n",
            "         org       0.63      0.54      0.58      4033\n",
            "         per       0.73      0.72      0.73      3545\n",
            "         tim       0.85      0.84      0.85      4067\n",
            "\n",
            "   micro avg       0.80      0.78      0.79     22562\n",
            "   macro avg       0.72      0.52      0.54     22562\n",
            "weighted avg       0.79      0.78      0.78     22562\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06kaPnY-vfBo",
        "outputId": "1496eefd-387c-48b0-a7a7-74da1c6ccd56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 79.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12-07 문자 임베딩(Character Embedding) 활용하기\n",
        "\n",
        "# 3. BiLSTM-CNN-CRF\n",
        "\n",
        "\n",
        "# BiLSTM-CNN-CRF를 이용한 개체명인식\n",
        "# 모델링\n",
        "\n",
        "출처: https://wikidocs.net/147299\n",
        " \n",
        "\n",
        "# '양방향 LSTM에 문자 임베딩을 사용한 모델' OR 양방향 LSTM에 CRF 층을 추가적으로 사용한 모델이 \n",
        "\n",
        "# 단순 '양방향 LSTM만을 사용한 모델' 보다는 성능이 더 좋은 것을 확인\n",
        "\n",
        " 이번에는 문자 임베딩을 사용한 위 모델에 CRF 층까지 추가적으로 사용"
      ],
      "metadata": {
        "id": "iZjT9J0pvhIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras_crf import CRFModel"
      ],
      "metadata": {
        "id": "2YuPgSSQvfxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "embedding_dim = 128\n",
        "char_embedding_dim = 64\n",
        "dropout_ratio = 0.5\n",
        "hidden_units = 256\n",
        "num_filters = 30\n",
        "kernel_size = 3\n",
        "\n",
        "# 단어 임베딩\n",
        "words_input = Input(shape=(None,),dtype='int32',name='words_input')\n",
        "words = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(words_input)\n",
        "\n",
        "# char 임베딩\n",
        "character_input = Input(shape=(None, max_len_char,),name='char_input')\n",
        "embed_char_out = TimeDistributed(Embedding(len(char_to_index), char_embedding_dim, embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name='char_embedding')(character_input)\n",
        "dropout = Dropout(dropout_ratio)(embed_char_out)\n",
        "\n",
        "# char 임베딩에 대해서는 Conv1D 수행\n",
        "conv1d_out= TimeDistributed(Conv1D(kernel_size=kernel_size, filters=num_filters, padding='same',activation='tanh', strides=1))(dropout)\n",
        "maxpool_out=TimeDistributed(MaxPooling1D(max_len_char))(conv1d_out)\n",
        "char = TimeDistributed(Flatten())(maxpool_out)\n",
        "char = Dropout(dropout_ratio)(char)\n",
        "\n",
        "# char 임베딩을 Conv1D 수행한 뒤에 단어 임베딩과 연결\n",
        "output = concatenate([words, char])\n",
        "\n",
        "# 연결한 벡터를 가지고 문장의 길이만큼 LSTM을 수행\n",
        "output = Bidirectional(LSTM(hidden_units, return_sequences=True, dropout=dropout_ratio))(output)\n",
        "\n",
        "# 출력층\n",
        "output = TimeDistributed(Dense(tag_size, activation='relu'))(output)\n",
        "\n",
        "base = Model(inputs=[words_input, character_input], outputs=[output])\n",
        "model = CRFModel(base, tag_size)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001), metrics='accuracy')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePBkKDLpvk8w",
        "outputId": "9f90e5dc-0e04-4bdc-cb4f-90c35b3fc313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"crf_model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " char_input (InputLayer)        [(None, None, 15)]   0           []                               \n",
            "                                                                                                  \n",
            " char_embedding (TimeDistribute  (None, None, 15, 64  4736       ['char_input[0][0]']             \n",
            " d)                             )                                                                 \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, None, 15, 64  0           ['char_embedding[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " time_distributed_7 (TimeDistri  (None, None, 15, 30  5790       ['dropout_3[0][0]']              \n",
            " buted)                         )                                                                 \n",
            "                                                                                                  \n",
            " time_distributed_8 (TimeDistri  (None, None, 1, 30)  0          ['time_distributed_7[0][0]']     \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " words_input (InputLayer)       [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " time_distributed_9 (TimeDistri  (None, None, 30)    0           ['time_distributed_8[0][0]']     \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " embedding_4 (Embedding)        (None, None, 128)    4072832     ['words_input[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, None, 30)     0           ['time_distributed_9[0][0]']     \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, None, 158)    0           ['embedding_4[0][0]',            \n",
            "                                                                  'dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " bidirectional_3 (Bidirectional  (None, None, 512)   849920      ['concatenate_1[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " time_distributed_10 (TimeDistr  (None, None, 18)    9234        ['bidirectional_3[0][0]']        \n",
            " ibuted)                                                                                          \n",
            "                                                                                                  \n",
            " crf_1 (CRF)                    [(None, None),       702         ['time_distributed_10[0][0]']    \n",
            "                                 (None, None, 18),                                                \n",
            "                                 (None,),                                                         \n",
            "                                 (18, 18)]                                                        \n",
            "                                                                                                  \n",
            " decode_sequence (Lambda)       (None, None)         0           ['crf_1[0][0]']                  \n",
            "                                                                                                  \n",
            " potentials (Lambda)            (None, None, 18)     0           ['crf_1[0][1]']                  \n",
            "                                                                                                  \n",
            " sequence_length (Lambda)       (None,)              0           ['crf_1[0][2]']                  \n",
            "                                                                                                  \n",
            " kernel (Lambda)                (18, 18)             0           ['crf_1[0][3]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,943,214\n",
            "Trainable params: 4,943,214\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('bilstm_cnn_crf/cp.ckpt', monitor='val_decode_sequence_accuracy', mode='max', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "     \n"
      ],
      "metadata": {
        "id": "IV7VfNCIvmFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CRF 층은 원-핫 인코딩 된 레이블은 지원하지 않으므로 y_train이 아니라 y_train_int를 사용함을 주의합니다."
      ],
      "metadata": {
        "id": "0iwsfyytqoij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([X_train, X_char_train], y_train_int, batch_size=128, epochs=15, validation_split=0.1, callbacks=[mc, es])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "aOGPbGbZvnqY",
        "outputId": "c984f115-3890-4baf-cd93-de0fc5799bc4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d4ac728b613d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_char_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 조기 종료로 학습이 끝났다면 검증 데이터에 대해서 정확도가 가장 높았을 당시를 저장해둔 가중치를 불러온 후, 테스트 데이터의 13번 인덱스의 샘플에 대해서 예측해봅시다."
      ],
      "metadata": {
        "id": "942RW2g8qtOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('bilstm_cnn_crf/cp.ckpt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcphoY9Kvo0P",
        "outputId": "435d79eb-e425-4183-ce98-6832d07cfbc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f5c7a1ebfa0>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 13 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
        "\n",
        "# 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
        "y_predicted = model.predict([np.array([X_test[i]]), np.array([X_char_test[i]])])[0] \n",
        "true = np.argmax(y_test[i], -1) # 원-핫 벡터를 정수 인코딩으로 변경.\n",
        "\n",
        "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
        "print(35 * \"-\")\n",
        "\n",
        "for word, tag, pred in zip(X_test[i], true, y_predicted[0]):\n",
        "    if word != 0: # PAD값은 제외함.\n",
        "        print(\"{:17}: {:7} {}\".format(index_to_word[word], index_to_ner[tag], index_to_ner[pred]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efnAPB7Ivp7g",
        "outputId": "319a4094-13c8-49dd-b182-a7d3c15257c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 977ms/step\n",
            "단어             |실제값  |예측값\n",
            "-----------------------------------\n",
            "the              : O       O\n",
            "statement        : O       O\n",
            "came             : O       O\n",
            "as               : O       O\n",
            "u.n.             : B-org   B-org\n",
            "secretary-general: I-org   I-org\n",
            "kofi             : B-per   B-per\n",
            "annan            : I-per   I-per\n",
            "met              : O       O\n",
            "with             : O       O\n",
            "officials        : O       O\n",
            "in               : O       O\n",
            "amman            : B-geo   B-geo\n",
            "to               : O       O\n",
            "discuss          : O       O\n",
            "wednesday        : B-tim   B-tim\n",
            "'s               : O       O\n",
            "attacks          : O       O\n",
            ".                : O       O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 정확하게 잘 예측한 것 같습니다. 테스트 데이터에 대해서 성능을 측정해봅시다. 테스트 데이터에 대한 예측 시퀀스인 y_predicted를 얻습니다. 예측값과 실제값에 대한 태깅 정보 시퀀스를 얻은 후 F1-score를 계산합니다"
      ],
      "metadata": {
        "id": "6fBIGxgXq0Hs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epochs = range(1, len(history.history['val_loss']) + 1)\n",
        "plt.plot(epochs, history.history['loss'])\n",
        "plt.plot(epochs, history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ZWjT8tG6vrmQ",
        "outputId": "8a876422-7009-4730-930f-921e63d21b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_predicted = model.predict([X_test, X_char_test])[0]\n",
        "pred_tags = sequences_to_tag_for_crf(y_predicted)\n",
        "test_tags = sequences_to_tag(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73GmHd27vtHn",
        "outputId": "56329138-d598-4f82-c5c0-3b571187aef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300/300 [==============================] - 9s 29ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_tags, pred_tags))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3bHRbdpvuJh",
        "outputId": "bfedbd94-5b27-4afc-b824-f8d8e3ac1fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        63\n",
            "         eve       0.82      0.17      0.29        52\n",
            "         geo       0.84      0.85      0.84      7620\n",
            "         gpe       0.95      0.94      0.94      3145\n",
            "         nat       0.00      0.00      0.00        37\n",
            "         org       0.67      0.58      0.62      4033\n",
            "         per       0.77      0.74      0.75      3545\n",
            "         tim       0.89      0.83      0.86      4067\n",
            "\n",
            "   micro avg       0.83      0.79      0.81     22562\n",
            "   macro avg       0.62      0.51      0.54     22562\n",
            "weighted avg       0.82      0.79      0.80     22562\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFhDdhNXvu_g",
        "outputId": "a97738eb-e374-4916-f9a3-06a373bc7a33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 80.6%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12-07 문자 임베딩(Character Embedding) 활용하기\n",
        "\n",
        "# 4. BiLSTM-BiLSTM-CRF\n",
        "\n",
        "출처: https://wikidocs.net/147299\n",
        "\n",
        "\n",
        "# BiLSTM-BiLSTM-CRF을 이용한 개체명 인식\n",
        "모델링\n",
        "\n",
        "문자 임베딩이 활용되는 과정\n",
        "\n",
        "하나의 단어는 문자 단위로 토큰화되었고, 토큰화 된 각 문자는 위의 전처리를 통해 정수로 맵핑된 상태\n",
        "\n",
        "정수로 맵핑된 각 문자는 임베딩 층을 통과하면 64차원의 벡터\n",
        "\n",
        "이후 양방향 LSTM 입력으로 사용되는데, 이때 사용되는 LSTM의 은닉 상태의 크기는 64\n",
        "\n",
        "해당 LSTM은 다 대 일(many-to-one)구조로 순방향 LSTM의 은닉 상태와 역방향 LSTM의 은닉 상태가 연결(concatenate)된 값이 양방향 LSTM의 출력\n",
        "\n",
        "해당 출력을 하나의 단어에 대한 단어 벡터로 간주\n",
        "\n",
        "해당 단어 벡터는 일반적으로 워드 임베딩이라고 부르던 과정을 통해 얻은 단어의 임베딩 벡터와 연결(concatenate)됩니다.\n",
        "\n",
        ". 이를 개체명 인식을 위한 양방향 LSTM의 입력으로 사용하게 되는데, 이후에는 이전 실습들과 같습니다. CRF 층은 원-핫 인코딩 된 레이블은 지원하지 않으므로 y_train_int를 사용합니다"
      ],
      "metadata": {
        "id": "ZTmj0q7ZvyO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "embedding_dim = 128\n",
        "char_embedding_dim = 64\n",
        "dropout_ratio = 0.3\n",
        "hidden_units = 64\n",
        "\n",
        "word_ids = Input(batch_shape=(None, None), dtype='int32', name='word_input')\n",
        "word_embeddings = Embedding(input_dim=vocab_size,\n",
        "                                        output_dim=embedding_dim,\n",
        "                                        name='word_embedding')(word_ids)\n",
        "\n",
        "char_ids = Input(batch_shape=(None, None, None), dtype='int32', name='char_input')\n",
        "char_embeddings = Embedding(input_dim=(len(char_to_index)),\n",
        "                                        output_dim=char_embedding_dim,\n",
        "                                        embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5),\n",
        "                                        name='char_embedding')(char_ids)\n",
        "\n",
        "char_embeddings = TimeDistributed(Bidirectional(LSTM(hidden_units)))(char_embeddings)\n",
        "word_embeddings = concatenate([word_embeddings, char_embeddings])\n",
        "\n",
        "word_embeddings = Dropout(dropout_ratio)(word_embeddings)\n",
        "output = Bidirectional(LSTM(units=hidden_units, return_sequences=True))(word_embeddings)\n",
        "output = TimeDistributed(Dense(tag_size, activation='relu'))(output)\n",
        "\n",
        "base = Model(inputs=[word_ids, char_ids], outputs=[output])\n",
        "model = CRFModel(base, tag_size)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001), metrics='accuracy')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZR_LDtNvwH3",
        "outputId": "4e9dae7b-f41c-4b41-8c17-1739b6bfd4ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"crf_model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " char_input (InputLayer)        [(None, None, None)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " word_input (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " char_embedding (Embedding)     (None, None, None,   4736        ['char_input[0][0]']             \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " word_embedding (Embedding)     (None, None, 128)    4072832     ['word_input[0][0]']             \n",
            "                                                                                                  \n",
            " time_distributed_11 (TimeDistr  (None, None, 128)   66048       ['char_embedding[0][0]']         \n",
            " ibuted)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, None, 256)    0           ['word_embedding[0][0]',         \n",
            "                                                                  'time_distributed_11[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, None, 256)    0           ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " bidirectional_5 (Bidirectional  (None, None, 128)   164352      ['dropout_5[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " time_distributed_12 (TimeDistr  (None, None, 18)    2322        ['bidirectional_5[0][0]']        \n",
            " ibuted)                                                                                          \n",
            "                                                                                                  \n",
            " crf_2 (CRF)                    [(None, None),       702         ['time_distributed_12[0][0]']    \n",
            "                                 (None, None, 18),                                                \n",
            "                                 (None,),                                                         \n",
            "                                 (18, 18)]                                                        \n",
            "                                                                                                  \n",
            " decode_sequence (Lambda)       (None, None)         0           ['crf_2[0][0]']                  \n",
            "                                                                                                  \n",
            " potentials (Lambda)            (None, None, 18)     0           ['crf_2[0][1]']                  \n",
            "                                                                                                  \n",
            " sequence_length (Lambda)       (None,)              0           ['crf_2[0][2]']                  \n",
            "                                                                                                  \n",
            " kernel (Lambda)                (18, 18)             0           ['crf_2[0][3]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,310,992\n",
            "Trainable params: 4,310,992\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('bilstm_bilstm_crf/cp.ckpt', monitor='val_decode_sequence_accuracy', mode='max', verbose=1, save_best_only=True, save_weights_only=True)\n"
      ],
      "metadata": {
        "id": "r09Z41jov1TY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([X_train, X_char_train], y_train_int, batch_size=128, epochs=15, validation_split=0.1, callbacks=[mc, es])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKchkmS-v20w",
        "outputId": "5d173539-fd84-4406-b359-03ac31bc80f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9230 - loss: 20.5625\n",
            "Epoch 1: val_decode_sequence_accuracy improved from -inf to 0.96869, saving model to bilstm_bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 53s 163ms/step - decode_sequence_accuracy: 0.9230 - loss: 20.5146 - val_decode_sequence_accuracy: 0.9687 - val_loss: 7.9423\n",
            "Epoch 2/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9766 - loss: 5.4261\n",
            "Epoch 2: val_decode_sequence_accuracy improved from 0.96869 to 0.98309, saving model to bilstm_bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 32s 120ms/step - decode_sequence_accuracy: 0.9766 - loss: 5.4216 - val_decode_sequence_accuracy: 0.9831 - val_loss: 4.0972\n",
            "Epoch 3/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9859 - loss: 3.1328\n",
            "Epoch 3: val_decode_sequence_accuracy improved from 0.98309 to 0.98598, saving model to bilstm_bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 30s 112ms/step - decode_sequence_accuracy: 0.9859 - loss: 3.1367 - val_decode_sequence_accuracy: 0.9860 - val_loss: 3.0367\n",
            "Epoch 4/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9884 - loss: 2.3677\n",
            "Epoch 4: val_decode_sequence_accuracy improved from 0.98598 to 0.98641, saving model to bilstm_bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 29s 108ms/step - decode_sequence_accuracy: 0.9884 - loss: 2.3661 - val_decode_sequence_accuracy: 0.9864 - val_loss: 2.7239\n",
            "Epoch 5/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9897 - loss: 1.9953\n",
            "Epoch 5: val_decode_sequence_accuracy improved from 0.98641 to 0.98694, saving model to bilstm_bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 29s 109ms/step - decode_sequence_accuracy: 0.9897 - loss: 1.9969 - val_decode_sequence_accuracy: 0.9869 - val_loss: 2.6622\n",
            "Epoch 6/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9907 - loss: 1.7320\n",
            "Epoch 6: val_decode_sequence_accuracy improved from 0.98694 to 0.98714, saving model to bilstm_bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 29s 106ms/step - decode_sequence_accuracy: 0.9907 - loss: 1.7327 - val_decode_sequence_accuracy: 0.9871 - val_loss: 2.5577\n",
            "Epoch 7/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9913 - loss: 1.5490\n",
            "Epoch 7: val_decode_sequence_accuracy improved from 0.98714 to 0.98722, saving model to bilstm_bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 29s 108ms/step - decode_sequence_accuracy: 0.9913 - loss: 1.5508 - val_decode_sequence_accuracy: 0.9872 - val_loss: 2.6392\n",
            "Epoch 8/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9919 - loss: 1.3866\n",
            "Epoch 8: val_decode_sequence_accuracy did not improve from 0.98722\n",
            "270/270 [==============================] - 29s 107ms/step - decode_sequence_accuracy: 0.9919 - loss: 1.3864 - val_decode_sequence_accuracy: 0.9867 - val_loss: 2.5788\n",
            "Epoch 9/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9924 - loss: 1.2472\n",
            "Epoch 9: val_decode_sequence_accuracy did not improve from 0.98722\n",
            "270/270 [==============================] - 29s 106ms/step - decode_sequence_accuracy: 0.9924 - loss: 1.2476 - val_decode_sequence_accuracy: 0.9867 - val_loss: 2.6509\n",
            "Epoch 10/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9928 - loss: 1.1346\n",
            "Epoch 10: val_decode_sequence_accuracy did not improve from 0.98722\n",
            "270/270 [==============================] - 29s 106ms/step - decode_sequence_accuracy: 0.9928 - loss: 1.1341 - val_decode_sequence_accuracy: 0.9864 - val_loss: 2.6619\n",
            "Epoch 10: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "조기 종료로 학습이 끝났다면 검증 데이터에 대해서 정확도가 가장 높았을 당시를 저장해둔 가중치를 불러온 후, 테스트 데이터의 13번 인덱스의 샘플에 대해서 예측합니다."
      ],
      "metadata": {
        "id": "TrocSGz6rkVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('bilstm_bilstm_crf/cp.ckpt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TKUmZ37v3kI",
        "outputId": "845c534c-77ad-4e32-a453-acab03256dbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f5da03a47f0>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "정확하게 잘 예측한 것 같습니다. 테스트 데이터에 대해서 성능을 측정해봅시다. 테스트 데이터에 대한 예측 시퀀스인 y_predicted를 얻습니다. 예측값과 실제값에 대한 태깅 정보 시퀀스를 얻은 후 F1-score를 계산합니다."
      ],
      "metadata": {
        "id": "en1hlvUUrwEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "i = 13 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
        "\n",
        "# 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
        "y_predicted = model.predict([np.array([X_test[i]]), np.array([X_char_test[i]])])[0]\n",
        "true = np.argmax(y_test[i], -1) # 원-핫 벡터를 정수 인코딩으로 변경.\n",
        "\n",
        "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
        "print(35 * \"-\")\n",
        "\n",
        "for word, tag, pred in zip(X_test[i], true, y_predicted[0]):\n",
        "    if word != 0: # PAD값은 제외함.\n",
        "        print(\"{:17}: {:7} {}\".format(index_to_word[word], index_to_ner[tag], index_to_ner[pred]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umo-SoMhv46A",
        "outputId": "495312be-5ea6-4921-b5b1-953bdd9b813f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "단어             |실제값  |예측값\n",
            "-----------------------------------\n",
            "the              : O       O\n",
            "statement        : O       O\n",
            "came             : O       O\n",
            "as               : O       O\n",
            "u.n.             : B-org   B-org\n",
            "secretary-general: I-org   I-org\n",
            "kofi             : B-per   B-per\n",
            "annan            : I-per   I-per\n",
            "met              : O       O\n",
            "with             : O       O\n",
            "officials        : O       O\n",
            "in               : O       O\n",
            "amman            : B-geo   B-geo\n",
            "to               : O       O\n",
            "discuss          : O       O\n",
            "wednesday        : B-tim   B-tim\n",
            "'s               : O       O\n",
            "attacks          : O       O\n",
            ".                : O       O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = range(1, len(history.history['val_loss']) + 1)\n",
        "plt.plot(epochs, history.history['loss'])\n",
        "plt.plot(epochs, history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "jsDO6Ffav56g",
        "outputId": "7eeb13a3-f120-4bf0-9afc-7ab5c8615916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_predicted = model.predict([X_test, X_char_test])[0]\n",
        "pred_tags = sequences_to_tag_for_crf(y_predicted)\n",
        "test_tags = sequences_to_tag(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovvdlZtBv7CH",
        "outputId": "a765fbf2-c295-457a-9d99-e677e20afa99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300/300 [==============================] - 9s 30ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_tags, pred_tags))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AC3dY2YBv7_w",
        "outputId": "a38c0387-2762-4bc0-cf0c-24582e532f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        63\n",
            "         eve       0.78      0.13      0.23        52\n",
            "         geo       0.83      0.86      0.84      7620\n",
            "         gpe       0.96      0.94      0.95      3145\n",
            "         nat       0.00      0.00      0.00        37\n",
            "         org       0.69      0.55      0.62      4033\n",
            "         per       0.78      0.76      0.77      3545\n",
            "         tim       0.87      0.85      0.86      4067\n",
            "\n",
            "   micro avg       0.83      0.79      0.81     22562\n",
            "   macro avg       0.61      0.51      0.53     22562\n",
            "weighted avg       0.82      0.79      0.80     22562\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 성능\n",
        "\n",
        "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl8DQE34v88n",
        "outputId": "14d2cffd-0d8b-4e44-c722-39f4730f4a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 81.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "36-4Hbpxv_CA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}